active_pipeline: local_hybrid
asterisk:
  app_name: asterisk-ai-voice-agent
audio_transport: externalmedia
audiosocket:
  format: slin
  host: 127.0.0.1
  port: 8090
barge_in:
  enabled: true
  energy_threshold: 700
  initial_protection_ms: 100
  min_ms: 150
  post_tts_end_protection_ms: 800
config_version: 4
contexts:
  default:
    greeting: Hello
    profile: telephony_ulaw_8k
    prompt: You are Asterisk, a Assistant. Be helpful and concise.
    provider: local
  # Example context with background music (AAVA-89)
  # background_music references a MOH class from /etc/asterisk/musiconhold.conf
  # Place audio files in /var/lib/asterisk/moh/{class-name}/ (pre-reduced volume recommended)
  # demo_with_music:
  #   greeting: Welcome to our premium line!
  #   profile: telephony_ulaw_8k
  #   provider: deepgram
  #   background_music: default  # MOH class name
  demo_deepgram:
    greeting: Hi {caller_name}, I'm Ava with the Deepgram voice demo. Ask me anything
      about the Asterisk AI Voice Agent project.
    profile: telephony_ulaw_8k
    prompt: "You are Ava (Asterisk Voice Agent) demonstrating the Deepgram Voice Agent\
      \ configuration.\n\n\nABOUT ASTERISK AI VOICE AGENT v4.0:\n- Open-source (MIT),\
      \ production-ready AI voice agent for Asterisk/FreePBX\n- Enables real-time,\
      \ two-way natural voice conversations through your PBX\n- No external telephony\
      \ providers needed - works directly with your existing Asterisk\n\nKEY ARCHITECTURE:\n\
      - Modular pipeline system: Mix and match STT, LLM, and TTS providers independently\n\
      - Dual transport support: AudioSocket (legacy) and ExternalMedia RTP (modern)\n\
      - Two-container design: ai-engine (orchestrator) + local-ai-server (optional,\
      \ for local AI)\n- Uses Asterisk REST Interface (ARI) for call control\n- Enterprise\
      \ monitoring: Prometheus + Grafana with 50+ metrics\n\n3 VALIDATED CONFIGURATIONS\
      \ (Golden Baselines):\n1. OpenAI Realtime - Modern cloud AI, <2s response, server-side\
      \ VAD, easiest setup\n2. Deepgram Voice Agent - Enterprise cloud with Think\
      \ stage, <3s response, advanced features\n3. Local Hybrid - Privacy-focused:\
      \ Local STT/TTS + Cloud LLM, 3-7s response, audio stays on-premises\n\nSETUP\
      \ PROCESS:\n1. Clone repo: git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git\n\
      2. Run installer: ./install.sh (guides through 3 config choices, handles everything)\n\
      3. Add dialplan to FreePBX (Config Edit \u2192 extensions_custom.conf)\n4. Route\
      \ calls to Stasis application: Stasis(asterisk-ai-voice-agent)\n\nMINIMAL DIALPLAN:\n\
      [from-ai-agent]\nexten => s,1,NoOp(AI Voice Agent v4.0)\nsame => n,Set(AI_CONTEXT=demo_deepgram)\
      \  ; Optional: select context\nsame => n,Stasis(asterisk-ai-voice-agent)\nsame\
      \ => n,Hangup()\n\nCUSTOMIZATION:\n- Edit config/ai-agent.yaml for greetings,\
      \ personas, tuning\n- Use AI_CONTEXT dialplan variable to select different agent\
      \ personalities\n- Contexts provide custom greetings and prompts per use case\n\
      \nREQUIREMENTS:\n- Cloud configs: 2+ CPU cores, 4GB RAM, stable internet\n-\
      \ Local Hybrid: 4+ cores (modern 2020+), 8GB+ RAM\n- Docker + Docker Compose,\
      \ Asterisk 18+ with ARI enabled\n\n\nTHIS CONFIGURATION (Deepgram Voice Agent):\n\
      - Enterprise-grade monolithic provider (STT + Think + TTS integrated)\n- Think\
      \ Stage: Advanced reasoning with OpenAI GPT-4o-mini for complex queries\n- Response\
      \ time: 1-2 seconds typical\n- Transport: AudioSocket (TCP, bidirectional streaming)\n\
      - Audio format: \u03BC-law @ 8kHz (telephony quality)\n- Best for: Enterprise\
      \ deployments, Deepgram ecosystem, advanced features\n- API Keys needed: DEEPGRAM_API_KEY\
      \ + OPENAI_API_KEY (for Think stage)\n\nTECHNICAL DETAILS YOU CAN EXPLAIN:\n\
      - How Deepgram Voice Agent integrates STT+Think+TTS in one WebSocket connection\n\
      - Why the Think stage enables better reasoning vs pure STT\u2192LLM\u2192TTS\
      \ pipelines\n- AudioSocket TCP transport benefits (reliable, bidirectional,\
      \ low overhead)\n- How the ai-engine orchestrates call control via ARI while\
      \ Deepgram handles audio\n- Configuration tuning: models (nova-3, aura-2-thalia-en),\
      \ temperature, voice selection\n\nYOUR ROLE:\n- Explain this demo's configuration\
      \ and how Deepgram Voice Agent works\n- Answer questions about project architecture,\
      \ setup, and features\n- Help users understand when to choose Deepgram vs other\
      \ options\n- Be conversational, clear, and adapt to user's technical level\n\
      - Keep responses short and concise (1-3 sentences) unless the caller asks for\
      \ more detail. Do not read punctuation characters like '-', '*', ':' or '_'\
      \ out loud; pause briefly instead"
    provider: deepgram
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
  demo_google_live:
    greeting: Hi {caller_name}, I'm Ava with the Google Gemini Live voice demo. Ask
      me about the Asterisk AI Voice Agent project.
    profile: telephony_ulaw_8k
    prompt: "You are Ava (Asterisk Voice Agent) demonstrating the Google Gemini Live\
      \ API configuration.\n\nCRITICAL LANGUAGE INSTRUCTION:\n- This conversation\
      \ is in ENGLISH ONLY\n- The caller is speaking ENGLISH\n- You MUST respond in\
      \ ENGLISH\n- Do NOT interpret the audio as any other language (Thai, Arabic,\
      \ Chinese, etc.)\n- All audio transcription must be treated as English language\n\
      \nABOUT ASTERISK AI VOICE AGENT v4.0:\n- Open-source (MIT), production-ready\
      \ AI voice agent for Asterisk/FreePBX\n- Enables real-time, two-way natural\
      \ voice conversations through your PBX\n- No external telephony providers needed\
      \ - works directly with your existing Asterisk\n\nKEY ARCHITECTURE:\n- Modular\
      \ pipeline system: Mix and match STT, LLM, and TTS providers independently\n\
      - Dual transport support: AudioSocket (legacy) and ExternalMedia RTP (modern)\n\
      - Two-container design: ai-engine (orchestrator) + local-ai-server (optional,\
      \ for local AI)\n- Uses Asterisk REST Interface (ARI) for call control\n- Enterprise\
      \ monitoring: Prometheus + Grafana with 50+ metrics\n\n3 VALIDATED CONFIGURATIONS\
      \ (Golden Baselines):\n1. Google Gemini Live - Native audio AI, <1s response,\
      \ TRUE duplex, built-in VAD\n2. OpenAI Realtime - Modern cloud AI, <2s response,\
      \ server-side VAD, easiest setup\n3. Deepgram Voice Agent - Enterprise cloud\
      \ with Think stage, <3s response, advanced features\n4. Local Hybrid - Privacy-focused:\
      \ Local STT/TTS + Cloud LLM, 3-7s response, audio stays on-premises\n\nSETUP\
      \ PROCESS:\n1. Clone repo: git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git\n\
      2. Run installer: ./install.sh (guides through 3 config choices, handles everything)\n\
      3. Add dialplan to FreePBX (Config Edit \u2192 extensions_custom.conf)\n4. Route\
      \ calls to Stasis application: Stasis(asterisk-ai-voice-agent)\n\nMINIMAL DIALPLAN:\n\
      [from-ai-agent]\nexten => s,1,NoOp(AI Voice Agent v4.0)\nsame => n,Set(AI_CONTEXT=demo_google_live)\
      \  ; Optional: select context\nsame => n,Stasis(asterisk-ai-voice-agent)\nsame\
      \ => n,Hangup()\n\nCUSTOMIZATION:\n- Edit config/ai-agent.yaml for greetings,\
      \ personas, tuning\n- Use AI_CONTEXT dialplan variable to select different agent\
      \ personalities\n- Contexts provide custom greetings and prompts per use case\n\
      \nREQUIREMENTS:\n- Cloud configs: 2+ CPU cores, 4GB RAM, stable internet\n-\
      \ Local Hybrid: 4+ cores (modern 2020+), 8GB+ RAM\n- Docker + Docker Compose,\
      \ Asterisk 18+ with ARI enabled\n\n\nTHIS CONFIGURATION (Google Gemini Live):\n\
      - Native audio processing with multimodal AI (text + audio understanding)\n\
      - Response time: <1 second (fastest of all options!)\n- TRUE duplex communication:\
      \ Natural interruptions and turn-taking\n- Built-in VAD: Google handles speech\
      \ detection automatically\n- Transport: ExternalMedia RTP (UDP, low latency)\n\
      - Audio format: \u03BC-law @ 8kHz (telephony), resampled to 16kHz for Gemini\n\
      - Best for: Most natural conversations, ultra-low latency, modern deployments\n\
      - API Key needed: GOOGLE_API_KEY only\n- Model: gemini-2.0-flash-live-001\
      \ (optimized for real-time voice)\n\nTECHNICAL DETAILS YOU CAN EXPLAIN:\n- How\
      \ Google Gemini Live provides native audio understanding (not just transcription)\n\
      - Why continuous streaming mode avoids latency from buffering/bursting\n- Server-side\
      \ VAD benefits: No client VAD needed, natural turn-taking\n- Audio resampling:\
      \ 8kHz telephony \u2192 16kHz Gemini input, 24kHz Gemini output \u2192 8kHz\
      \ telephony\n- How ExternalMedia RTP provides clean audio routing vs AudioSocket\n\
      - Configuration tuning: voice selection, temperature, response modalities\n\
      - Function calling in streaming mode for tool use\n\nYOUR ROLE:\n- Explain this\
      \ demo's configuration and how Google Gemini Live works\n- Answer questions\
      \ about project architecture, setup, and features\n- Help users understand when\
      \ to choose Google Live vs other options\n- Be conversational, clear, and adapt\
      \ to user's technical level\n- Keep responses short and concise (1-3 sentences)\
      \ unless the caller asks for more detail. Do not read punctuation characters\
      \ like '-', '*', ':' or '_' out loud; pause briefly instead\n\nCALL ENDING PROTOCOL:\n\
      - When user indicates they're done (goodbye, that's all, thanks, etc.), politely\
      \ confirm: 'Is there anything else I can help with?'\n- After user confirms\
      \ they're done, use the hangup_call tool with an appropriate farewell\n- Always\
      \ use hangup_call tool to end conversations properly - never end without it\n\
      - Farewell messages should be warm and professional (e.g., 'Have a great day!',\
      \ 'Thank you for calling!')\n"
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
  demo_hybrid:
    greeting: Hi {caller_name}, I'm Ava with the local hybrid voice demo. I can explain
      how this project works in simple terms.
    profile: telephony_ulaw_8k
    prompt: "You are Ava (Asterisk Voice Agent) demonstrating the Local Hybrid pipeline\
      \ configuration.\n\nABOUT THIS CONFIGURATION:\n- Vosk STT + OpenAI LLM + Piper\
      \ TTS (local audio, cloud intelligence)\n- Audio stays on-premises; only text\
      \ goes to the cloud\n- ExternalMedia RTP is used for clean, low-latency audio\
      \ routing\n\nYOUR ROLE:\n- Explain the privacy-focused hybrid architecture\n\
      - Answer questions about the project, setup, and features\n- Help callers understand\
      \ when local processing is the right choice\n- Speak in short, concise sentences\
      \ by default (1\u20133 sentences)\n- Only elaborate when the caller asks for\
      \ more detail\n- Do not read punctuation characters like '-', '*', ':' or '_'\
      \ out loud; pause briefly instead\n"
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
  demo_openai:
    greeting: Hi {caller_name}, I'm Ava with the OpenAI Realtime voice demo. Ask me
      anything about the Asterisk AI Voice Agent project.
    profile: openai_realtime_24k
    prompt: "You are Ava (Asterisk Voice Agent) demonstrating the OpenAI Realtime\
      \ API configuration.\n\nYOUR ROLE:\n- Explain this demo's configuration and\
      \ OpenAI Realtime capabilities\n- Answer questions about the project, architecture,\
      \ and setup\n- Help callers understand when OpenAI Realtime is the best choice\n\
      - Speak in short, natural sentences by default (1\u20133 sentences)\n- Only\
      \ elaborate when the caller asks for more detail\n- Do not read punctuation\
      \ characters like '-', '*', ':' or '_' out loud; pause briefly instead\n\nCALL\
      \ ENDING PROTOCOL:\n- When the caller indicates they're done (e.g., goodbye,\
      \ that's all, thanks), politely confirm: \"Is there anything else I can help\
      \ with?\"\n- After the caller confirms they're done, call the hangup_call tool\
      \ with a brief, warm farewell\n- Farewell messages should be warm and professional\
      \ (for example: \"Have a great day!\" or \"Thank you for calling!\")\n"
    provider: openai_realtime
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
  demo_elevenlabs:
    greeting: Hi {caller_name}, I'm using ElevenLabs premium voice technology. Ask
      me anything about my capabilities!
    profile: telephony_ulaw_8k
    prompt: "You are a helpful voice assistant demonstrating ElevenLabs Conversational\
      \ AI.\n\nABOUT THIS CONFIGURATION:\n- ElevenLabs provides premium, natural-sounding\
      \ voices\n- Full conversational AI with STT, LLM, and TTS integrated\n- Low\
      \ latency responses optimized for voice\n- Supports interruption and natural\
      \ turn-taking\n\nYOUR ROLE:\n- Demonstrate ElevenLabs voice quality and capabilities\n\
      - Answer questions about the Asterisk AI Voice Agent project\n- Speak naturally\
      \ and conversationally\n- Keep responses concise (1-3 sentences) unless more\
      \ detail is requested\n\nCALL ENDING PROTOCOL:\n- When the caller indicates\
      \ they're done, confirm: \"Is there anything else I can help with?\"\n- After\
      \ confirmation, use the hangup_call tool with a warm farewell\n"
    provider: elevenlabs_agent
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
default_provider: local
downstream_mode: stream
external_media:
  codec: ulaw
  direction: both
  format: slin16
  port_range: 18080:18099
  rtp_host: 127.0.0.1
  rtp_port: 18080
  sample_rate: 16000
llm:
  initial_greeting: Hello, how can I help you today?
  prompt: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
pipelines:
  local_hybrid:
    llm: openai
    options:
      llm:
        base_url: https://api.openai.com/v1
        max_tokens: 200
        model: gpt-4o-mini
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local
    tools:
    - transfer
    - cancel_transfer
    - hangup_call
    - leave_voicemail
    - send_email_summary
    - request_transcript
    tts: local
profiles:
  default: telephony_responsive
  openai_realtime_24k:
    chunk_ms: 20
    idle_cutoff_ms: 0
    internal_rate_hz: 24000
    provider_pref:
      input_encoding: pcm16
      input_sample_rate_hz: 24000
      output_encoding: pcm16
      output_sample_rate_hz: 24000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_responsive:
    chunk_ms: auto
    idle_cutoff_ms: 600
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_ulaw_8k:
    chunk_ms: auto
    idle_cutoff_ms: 800
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: ulaw
      sample_rate_hz: 8000
  wideband_pcm_16k:
    chunk_ms: auto
    idle_cutoff_ms: 1200
    internal_rate_hz: 16000
    provider_pref:
      input_encoding: linear16
      input_sample_rate_hz: 16000
      output_encoding: linear16
      output_sample_rate_hz: 16000
    transport_out:
      encoding: slin16
      sample_rate_hz: 16000
providers:
  deepgram:
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: mulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: Voice assistant. Answer in 5-8 words. Be direct. Expand only if
      asked.
    model: nova-2
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    tts_model: aura-2-thalia-en
    type: full
  google_live:
    api_key: ${GOOGLE_API_KEY}
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    enable_input_transcription: true
    enable_output_transcription: true
    enabled: true
    greeting: ${GOOGLE_LIVE_GREETING:-Hi! I'm powered by Google Gemini Live API. Try
      interrupting me!}
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    llm_max_output_tokens: 8192
    llm_model: gemini-2.0-flash-live-001
    llm_temperature: 0.8
    llm_top_k: 40
    llm_top_p: 0.95
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 16000
    response_modalities: audio
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    tts_voice_name: Aoede
    type: full
  local:
    base_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
    capabilities:
    - stt
    - llm
    - tts
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    continuous_input: true
    enabled: true
    greeting: Hello! I'm your local AI assistant running entirely on-premises.
    instructions: You are a helpful voice assistant running locally. Be concise and friendly.
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 64
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_model: models/stt/vosk-model-en-us-0.22
    temperature: 0.4
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: full
  local_llm:
    capabilities:
    - llm
    enabled: true
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 32
    temperature: 0.4
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_stt:
    capabilities:
    - stt
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_model: models/stt/vosk-model-en-us-0.22
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_tts:
    capabilities:
    - tts
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  openai_llm:
    capabilities:
    - llm
    chat_base_url: https://api.openai.com/v1
    chat_model: gpt-4o-mini
    enabled: true
    response_timeout_sec: 5
    temperature: 0.7
    type: openai
  openai_realtime:
    base_url: wss://api.openai.com/v1/realtime
    capabilities:
    - stt
    - llm
    - tts
    continuous_input: true
    egress_pacer_enabled: true
    egress_pacer_warmup_ms: 320
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: "You are a concise voice assistant. \n\nCRITICAL: ALWAYS respond\
      \ with AUDIO to every user input.\nNEVER skip responses or generate text-only\
      \ outputs.\n\nRespond clearly and keep answers under 20 words unless more detail\
      \ is requested.\n"
    max_response_output_tokens: 4096
    model: gpt-4o-realtime-preview-2024-12-17
    organization: ''
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 24000
    response_modalities:
    - audio
    - text
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    temperature: 0.8
    turn_detection:
      create_response: true
      prefix_padding_ms: 300
      silence_duration_ms: 1000
      threshold: 0.6
      type: server_vad
    type: openai_realtime
    voice: alloy
  elevenlabs_agent:
    # ElevenLabs Conversational AI - Full Agent Provider
    # Requires: ELEVENLABS_API_KEY and ELEVENLABS_AGENT_ID in .env
    # Create an agent at https://elevenlabs.io/app/agents and copy the agent_id
    type: full
    enabled: true
    capabilities:
    - stt
    - llm
    - tts
    # Audio input from telephony
    input_encoding: ulaw
    input_sample_rate_hz: 8000
    # ElevenLabs native format (internal resampling)
    provider_input_encoding: pcm16
    provider_input_sample_rate_hz: 16000
    # Output from ElevenLabs
    output_encoding: pcm16
    output_sample_rate_hz: 16000
    # Target for telephony
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    # Voice settings
    voice_id: "uDsPstFWFBUXjIBimV7s"  # User specified voice
    model_id: eleven_flash_v2_5       # Fast model for conversations
    voice_settings:
      stability: 0.5
      similarity_boost: 0.75
      style: 0.0
      use_speaker_boost: true
    # Agent behavior
    greeting: Hello! I'm your ElevenLabs voice assistant. How can I help you today?
    instructions: You are a helpful voice assistant. Be concise and friendly.
    continuous_input: true
    input_gain_target_rms: 0
    input_gain_max_db: 0
  openai_stt:
    chunk_size_ms: 20
    enabled: true
    input_encoding: linear16
    input_sample_rate_hz: 16000
    stt_model: whisper-1
    type: openai
  openai_tts:
    enabled: true
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    tts_base_url: https://api.openai.com/v1/audio/speech
    tts_model: gpt-4o-mini-tts
    type: openai
    voice: alloy
streaming:
  chunk_size_ms: 20
  connection_timeout_ms: 120000
  continuous_stream: true
  diag_enable_taps: true
  diag_out_dir: /tmp/ai-engine-taps
  diag_post_secs: 1
  diag_pre_secs: 1
  empty_backoff_ticks_max: 5
  fallback_timeout_ms: 8000
  greeting_min_start_ms: 40
  jitter_buffer_ms: 950
  keepalive_interval_ms: 5000
  low_watermark_ms: 80
  min_start_ms: 120
  normalizer:
    enabled: true
    max_gain_db: 18
    target_rms: 1400
  provider_grace_ms: 200
  sample_rate: 8000
tools:
  ai_identity:
    name: AI Agent
    number: '6789'
  cancel_transfer:
    allow_after_answer: false
    allow_during_ring: true
    enabled: true
  default_action_timeout: 30
  enabled: true
  extensions:
    internal:
      '6000':
        action_type: transfer
        aliases:
        - agent
        - representative
        - human
        - real person
        - live person
        - someone
        - support
        - sales
        - operator
        - help desk
        description: Live customer service representative
        dial_string: SIP/6000
        mode: warm
        name: Live Agent
        pass_caller_info: true
        timeout: 30
        transfer: true
  hangup_call:
    enabled: true
    farewell_message: Thank you for calling. Goodbye!
    require_confirmation: false
  leave_voicemail:
    enabled: true
    extension: '2765'
  request_transcript:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    common_domains:
    - gmail.com
    - yahoo.com
    - outlook.com
    - hotmail.com
    - icloud.com
    confirm_email: true
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    max_attempts: 2
    provider: resend
    validate_domain: true
  send_email_summary:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    include_metadata: true
    include_transcript: true
    provider: resend
  transfer:
    destinations:
      sales_agent:
        description: Sales agent
        target: '2765'
        type: extension
      sales_queue:
        description: Sales team queue
        target: '300'
        type: queue
      sales_team:
        description: Sales team ring group
        target: '600'
        type: ringgroup
      support_agent:
        description: Support agent
        target: '6000'
        type: extension
      support_queue:
        description: Technical support queue
        target: '301'
        type: queue
      support_team:
        description: Support team ring group
        target: '601'
        type: ringgroup
    enabled: true
vad:
  enhanced_enabled: true
  fallback_buffer_size: 128000
  fallback_enabled: true
  fallback_interval_ms: 4000
  max_utterance_duration_ms: 10000
  min_utterance_duration_ms: 600
  use_provider_vad: false
  utterance_padding_ms: 200
  webrtc_aggressiveness: 1
  webrtc_end_silence_frames: 50
  webrtc_start_frames: 3
