active_pipeline: default
asterisk:
  app_name: asterisk-ai-voice-agent
audio_transport: externalmedia
audiosocket:
  format: slin
  host: 0.0.0.0
  port: 8090
barge_in:
  enabled: true
  energy_threshold: 1100
  initial_protection_ms: 100
  min_ms: 250
  post_tts_end_protection_ms: 100
config_version: 4
contexts:
  default:
    greeting: Hello, how can I help you today?
    profile: telephony_ulaw_8k
    prompt: You are a helpful AI assistant. Be concise and clear.
  premium:
    greeting: Welcome to premium service. How may I assist you today?
    profile: openai_realtime_24k
    prompt: You are a premium concierge assistant. Be courteous, attentive, and provide
      personalized service. Anticipate needs and offer proactive suggestions.
    provider: openai_realtime
  sales:
    greeting: Thanks for calling! How can I help you find what you need today?
    profile: wideband_pcm_16k
    prompt: You are an enthusiastic sales assistant. Be upbeat, helpful, and guide
      customers to products that meet their needs. Keep responses under 15 words unless
      explaining features.
    provider: deepgram
  support:
    greeting: Technical support, how can we assist you?
    profile: telephony_ulaw_8k
    prompt: You are technical support. Be precise, methodical, and patient. Gather
      information systematically. Provide step-by-step instructions when troubleshooting.
default_provider: deepgram
downstream_mode: stream
external_media:
  codec: ulaw
  direction: both
  jitter_buffer_ms: 20
  port_range: 18080:18099
  rtp_host: 0.0.0.0
  rtp_port: 18080
llm:
  initial_greeting: Hello, how can I help you today?
  model: gpt-4o-mini
  prompt: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
  temperature: 0.7
pipelines:
  cloud_only:
    llm: google_llm
    options:
      llm:
        base_url: https://generativelanguage.googleapis.com/v1
        model: models/gemini-1.5-pro-latest
      stt:
        base_url: https://api.deepgram.com
        language: en-US
      tts:
        audio_config:
          audio_encoding: MULAW
          sample_rate_hz: 8000
        base_url: https://texttospeech.googleapis.com/v1
        voice_name: en-US-Neural2-C
    stt: deepgram_stt
    tts: google_tts
  default:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        model: gpt-4o-realtime-preview-2024-12-17
      stt:
        base_url: wss://api.openai.com/v1/realtime
      tts:
        base_url: https://api.openai.com/v1/audio/speech
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: openai_stt
    tts: openai_tts
  hybrid_support:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        max_tokens: 150
        model: gpt-4o-mini
        response_timeout_sec: 15.0
        temperature: 0.7
      stt:
        base_url: wss://api.deepgram.com
        encoding: linear16
        language: en-US
        mode: stt
        sample_rate: 16000
        streaming: true
        stream_format: pcm16_16k
      tts:
        base_url: https://api.deepgram.com
        format:
          encoding: mulaw
          sample_rate: 8000
        voice: aura-thalia-en
    stt: deepgram_flux_stt
    tts: deepgram_tts
  local_only:
    llm: local_llm
    options:
      llm:
        llm_response_timeout_sec: 60.0
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tts: local_tts
  local_stt_cloud_tts:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        model: gpt-4o
      stt:
        mode: stt
      tts:
        base_url: https://api.deepgram.com
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tts: deepgram_tts
profiles:
  default: telephony_responsive
  openai_realtime_24k:
    chunk_ms: 20
    idle_cutoff_ms: 0
    internal_rate_hz: 24000
    provider_pref:
      input_encoding: pcm16
      input_sample_rate_hz: 24000
      output_encoding: pcm16
      output_sample_rate_hz: 24000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_responsive:
    chunk_ms: auto
    idle_cutoff_ms: 600
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_ulaw_8k:
    chunk_ms: auto
    idle_cutoff_ms: 800
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  wideband_pcm_16k:
    chunk_ms: auto
    idle_cutoff_ms: 1200
    internal_rate_hz: 16000
    provider_pref:
      input_encoding: linear16
      input_sample_rate_hz: 16000
      output_encoding: linear16
      output_sample_rate_hz: 16000
    transport_out:
      encoding: slin16
      sample_rate_hz: 16000
providers:
  deepgram:
    continuous_input: true
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: mulaw
    input_sample_rate_hz: 8000
    instructions: Voice assistant. Answer in 5-8 words. Be direct. Expand only if
      asked.
    model: nova-2-phonecall
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    tts_model: aura-2-thalia-en
  local:
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    enabled: false
    llm_model: models/llm/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf
    max_tokens: 64
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=5.0}
    stt_model: models/stt/vosk-model-small-en-us-0.15
    temperature: 0.4
    tts_voice: models/tts/en_US-lessac-medium.onnx
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  openai:
    chat_base_url: https://api.openai.com/v1
    chat_model: gpt-4o-mini
    chunk_size_ms: 20
    default_modalities:
    - text
    enabled: false
    input_encoding: linear16
    input_sample_rate_hz: 16000
    organization: ''
    project: ''
    realtime_base_url: wss://api.openai.com/v1/realtime
    realtime_model: gpt-4o-realtime-preview-2024-12-17
    response_timeout_sec: 5.0
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    tts_base_url: https://api.openai.com/v1/audio/speech
    tts_model: gpt-4o-mini-tts
    voice: alloy
  openai_realtime:
    base_url: wss://api.openai.com/v1/realtime
    egress_pacer_enabled: true
    egress_pacer_warmup_ms: 320
    enabled: true
    greeting: ${OPENAI_GREETING:-Hello, how can I help you today?}
    input_encoding: ulaw
    input_sample_rate_hz: 8000
    instructions: You are a concise voice assistant. Respond clearly and keep answers
      under 20 words unless more detail is requested.
    model: gpt-4o-realtime-preview-2024-12-17
    organization: ''
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 24000
    response_modalities:
    - audio
    - text
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    turn_detection:
      create_response: true
      prefix_padding_ms: 200
      silence_duration_ms: 500
      threshold: 0.5
      type: server_vad
    voice: alloy
streaming:
  chunk_size_ms: 20
  connection_timeout_ms: 120000
  continuous_stream: true
  empty_backoff_ticks_max: 5
  fallback_timeout_ms: 8000
  greeting_min_start_ms: 40
  jitter_buffer_ms: 950
  keepalive_interval_ms: 5000
  low_watermark_ms: 80
  min_start_ms: 120
  normalizer:
    enabled: true
    max_gain_db: 18.0
    target_rms: 1400
  provider_grace_ms: 500
  sample_rate: 8000
vad:
  enhanced_enabled: true
  fallback_buffer_size: 128000
  fallback_enabled: true
  fallback_interval_ms: 4000
  max_utterance_duration_ms: 10000
  min_utterance_duration_ms: 600
  use_provider_vad: false
  utterance_padding_ms: 200
  webrtc_aggressiveness: 1
  webrtc_end_silence_frames: 50
  webrtc_start_frames: 3
