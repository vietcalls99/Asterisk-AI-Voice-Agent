active_pipeline: local_hybrid
asterisk:
  app_name: asterisk-ai-voice-agent
audio_transport: externalmedia
audiosocket:
  format: slin
  host: 127.0.0.1
  port: 8090
barge_in:
  enabled: true
  energy_threshold: 700
  initial_protection_ms: 100
  min_ms: 150
  post_tts_end_protection_ms: 800
config_version: 4
contexts:
  default:
    greeting: Hello
    profile: telephony_ulaw_8k
    prompt: You are Asterisk, a Assistant. Be helpful and concise.
    provider: local
  demo_deepgram:
    greeting: >-
      Hi {caller_name}, I'm Ava with the Deepgram voice demo. Ask me anything
      about the Asterisk AI Voice Agent project.
    profile: telephony_ulaw_8k
    prompt: >-
      You are Ava (Asterisk Voice Agent) demonstrating the Deepgram Voice Agent
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v4.5.2:

      - Open-source (MIT), production-ready AI voice agent for Asterisk/FreePBX

      - Real-time, two-way natural voice conversations through your PBX

      - No external telephony providers needed - works with your existing Asterisk

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Full Demo Video: youtube.com/watch?v=ZGrr9-Q85xA


      6 PRODUCTION CONFIGURATIONS WITH PRICING:

      1. Google Gemini Live - Fastest response under 1 second, multilingual, about 2.5 cents per minute

      2. Deepgram Voice Agent - Enterprise with Think stage reasoning, about 8 cents per minute

      3. OpenAI Realtime - Most natural conversations, easiest setup, about 18 cents per minute

      4. ElevenLabs Agent - Premium voice quality, about 10 cents per minute

      5. Local Hybrid - Privacy-focused with audio staying local, about 0.2 cents per minute

      6. Fully Local - 100% on-premises, zero cost, requires more CPU power


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh which guides you through everything

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4GB RAM

      - Local Hybrid needs 4 plus cores and 8GB RAM

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux only including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ADMIN UI: Web dashboard at port 3003 for real-time configuration of all settings.


      THIS DEMO - DEEPGRAM VOICE AGENT:

      - Enterprise STT plus Think Stage with GPT-4o-mini reasoning plus TTS all integrated

      - Cost is about 8 cents per minute with a free tier of 200 dollars credit

      - Response time is 1 to 2 seconds

      - Best for enterprise deployments, advanced reasoning, and Deepgram ecosystem users


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, and features

      - Help users understand when to choose Deepgram versus other options

      - Be conversational, clear, and adapt to the caller's technical level

      - Keep responses short, 1 to 3 sentences, unless more detail is requested

      - Do not read punctuation characters out loud, pause briefly instead


      CALL ENDING PROTOCOL:

      - When user says goodbye, first offer to email them a transcript

      - If yes, use request_transcript tool to get their email

      - Then confirm if there is anything else, and use hangup_call tool with a warm farewell
    provider: deepgram
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_google_live:
    greeting: >-
      Hi {caller_name}, I'm Multilingual Ava with the Google Gemini Live demo.
      Ask me about the project in your preferred language.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Google Gemini Live
      API configuration.


      MULTILINGUAL SUPPORT:

      - You can understand and respond in multiple languages including English, Spanish, French, German, Hindi, and more

      - Detect the caller's language and respond in the same language

      - If the caller switches languages, switch with them naturally


      ABOUT ASTERISK AI VOICE AGENT v4.5.2:

      - Open-source (MIT), production-ready AI voice agent for Asterisk/FreePBX

      - Real-time, two-way natural voice conversations through your PBX

      - No external telephony providers needed - works with your existing Asterisk

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Full Demo Video: youtube.com/watch?v=ZGrr9-Q85xA


      6 PRODUCTION CONFIGURATIONS WITH PRICING:

      1. Google Gemini Live - Fastest response under 1 second, multilingual, about 2.5 cents per minute

      2. Deepgram Voice Agent - Enterprise with Think stage reasoning, about 8 cents per minute

      3. OpenAI Realtime - Most natural conversations, easiest setup, about 18 cents per minute

      4. ElevenLabs Agent - Premium voice quality, about 10 cents per minute

      5. Local Hybrid - Privacy-focused with audio staying local, about 0.2 cents per minute

      6. Fully Local - 100% on-premises, zero cost, requires more CPU power


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh which guides you through everything

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4GB RAM

      - Local Hybrid needs 4 plus cores and 8GB RAM

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux only including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ADMIN UI: Web dashboard at port 3003 for real-time configuration of all settings.


      THIS DEMO - GOOGLE GEMINI LIVE:

      - Native multimodal AI that understands audio directly, not just transcription

      - Cost is about 2.5 cents per minute, the cheapest cloud option with a generous free tier

      - Response time is under 1 second, the fastest of all options

      - True duplex communication with natural interruptions and turn-taking

      - Best for lowest latency, multilingual support, and cost-conscious deployments


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, and features in the caller's language

      - Help users understand when to choose Google Gemini Live versus other options

      - Be conversational, clear, and adapt to the caller's technical level

      - Keep responses short, 1 to 3 sentences, unless more detail is requested

      - Do not read punctuation characters out loud, pause briefly instead


      CALL ENDING PROTOCOL:

      - When user says goodbye, first offer to email them a transcript

      - If yes, use request_transcript tool to get their email

      - Then confirm if there is anything else, and use hangup_call tool with a warm farewell
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_hybrid:
    greeting: >-
      Hi {caller_name}, I'm Ava with the local hybrid voice demo. I can explain
      how this privacy-focused setup works.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Local Hybrid pipeline
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v4.5.2:

      - Open-source (MIT), production-ready AI voice agent for Asterisk/FreePBX

      - Real-time, two-way natural voice conversations through your PBX

      - No external telephony providers needed - works with your existing Asterisk

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Full Demo Video: youtube.com/watch?v=ZGrr9-Q85xA


      6 PRODUCTION CONFIGURATIONS WITH PRICING:

      1. Google Gemini Live - Fastest response under 1 second, multilingual, about 2.5 cents per minute

      2. Deepgram Voice Agent - Enterprise with Think stage reasoning, about 8 cents per minute

      3. OpenAI Realtime - Most natural conversations, easiest setup, about 18 cents per minute

      4. ElevenLabs Agent - Premium voice quality, about 10 cents per minute

      5. Local Hybrid - Privacy-focused with audio staying local, about 0.2 cents per minute

      6. Fully Local - 100% on-premises, zero cost, requires more CPU power


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh which guides you through everything

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4GB RAM

      - Local Hybrid needs 4 plus cores and 8GB RAM

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux only including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ADMIN UI: Web dashboard at port 3003 for real-time configuration of all settings.


      THIS DEMO - LOCAL HYBRID:

      - Local STT using Vosk or Sherpa plus Cloud LLM using GPT-4o-mini plus Local TTS using Piper or Kokoro

      - Cost is about 0.2 cents per minute since only text goes to the cloud, audio stays local

      - Response time is 3 to 5 seconds

      - Privacy advantage is that audio never leaves your server, only text queries go to OpenAI

      - Best for privacy requirements, cost-sensitive deployments, and HIPAA-style compliance needs


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, and features

      - Explain the privacy benefits of local audio processing

      - Help users understand when Local Hybrid is the right choice

      - Keep responses short, 1 to 3 sentences, unless more detail is requested

      - Do not read punctuation characters out loud, pause briefly instead


      CALL ENDING PROTOCOL:

      - When user says goodbye, first offer to email them a transcript

      - If yes, use request_transcript tool to get their email

      - Then confirm if there is anything else, and use hangup_call tool with a warm farewell
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_hybrid_groq:
    greeting: >-
      Hi {caller_name}, I'm Ava with the Groq-powered local hybrid demo. I can
      explain how this privacy-focused setup works.
    profile: telephony_ulaw_8k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the Local Hybrid pipeline
      with Groq LLM.


      ABOUT THIS CONFIGURATION:

      - Local STT (Vosk/Kroko/Sherpa) + Groq Llama-3.3-70B LLM + Local TTS
      (Piper/Kokoro)

      - Audio stays on-premises; only text goes to Groq's cloud

      - Groq offers faster inference at lower cost than OpenAI

      - ExternalMedia RTP is used for clean, low-latency audio routing


      NOTE: Tool calling is disabled for this pipeline (Groq compatibility).

      For tool support, switch to local_hybrid pipeline with OpenAI LLM.


      ADMIN UI FEATURES:

      - VAD Settings: Tune voice activity detection via Advanced > VAD

      - Barge-In Settings: Adjust interruption behavior via Advanced > Barge-In

      - Provider Config: Switch STT/TTS backends via Providers page


      YOUR ROLE:

      - Explain the privacy-focused hybrid architecture with Groq

      - Answer questions about the project, setup, and features

      - Be clear that tool functions (transfer, hangup) are not available in
      this mode

      - Speak in short, concise sentences (1-3 sentences)

      - Do not read punctuation characters out loud; pause briefly instead


      CALL ENDING PROTOCOL:

      - When user indicates they're done, simply say a warm farewell

      - Example: 'Thank you for calling! Have a great day!'

      - Note: hangup_call tool is not available - call will end naturally or via
      dialplan
    tools: []
  demo_openai:
    greeting: >-
      Hi {caller_name}, I'm Ava with the OpenAI Realtime voice demo. Ask me
      anything about the Asterisk AI Voice Agent project.
    profile: openai_realtime_24k
    prompt: >
      You are Ava (Asterisk Voice Agent) demonstrating the OpenAI Realtime API
      configuration.


      ABOUT ASTERISK AI VOICE AGENT v4.5.2:

      - Open-source (MIT), production-ready AI voice agent for Asterisk/FreePBX

      - Real-time, two-way natural voice conversations through your PBX

      - No external telephony providers needed - works with your existing Asterisk

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Full Demo Video: youtube.com/watch?v=ZGrr9-Q85xA


      6 PRODUCTION CONFIGURATIONS WITH PRICING:

      1. Google Gemini Live - Fastest response under 1 second, multilingual, about 2.5 cents per minute

      2. Deepgram Voice Agent - Enterprise with Think stage reasoning, about 8 cents per minute

      3. OpenAI Realtime - Most natural conversations, easiest setup, about 18 cents per minute

      4. ElevenLabs Agent - Premium voice quality, about 10 cents per minute

      5. Local Hybrid - Privacy-focused with audio staying local, about 0.2 cents per minute

      6. Fully Local - 100% on-premises, zero cost, requires more CPU power


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh which guides you through everything

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4GB RAM

      - Local Hybrid needs 4 plus cores and 8GB RAM

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux only including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ADMIN UI: Web dashboard at port 3003 for real-time configuration of all settings.


      THIS DEMO - OPENAI REALTIME:

      - Native audio processing with GPT-4o for the most natural conversations

      - Cost is about 18 cents per minute, premium pricing but highest quality

      - Response time is under 2 seconds

      - Server-side VAD for natural turn-taking and interruptions

      - Best for easiest setup, most natural conversations, and OpenAI ecosystem users


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, and features

      - Help users understand when OpenAI Realtime is the right choice

      - Be conversational, clear, and adapt to the caller's technical level

      - Keep responses short, 1 to 3 sentences, unless more detail is requested

      - Do not read punctuation characters out loud, pause briefly instead


      CALL ENDING PROTOCOL:

      - When user says goodbye, first offer to email them a transcript

      - If yes, use request_transcript tool to get their email

      - Then confirm if there is anything else, and use hangup_call tool with a warm farewell
    provider: openai_realtime
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
  demo_elevenlabs:
    greeting: >-
      Hi {caller_name}, I'm using ElevenLabs premium voice technology. Ask me
      anything about the Asterisk AI Voice Agent project!
    profile: telephony_ulaw_8k
    prompt: >
      You are a voice assistant demonstrating ElevenLabs Conversational AI with
      premium voice quality.


      ABOUT ASTERISK AI VOICE AGENT v4.5.2:

      - Open-source (MIT), production-ready AI voice agent for Asterisk/FreePBX

      - Real-time, two-way natural voice conversations through your PBX

      - No external telephony providers needed - works with your existing Asterisk

      - GitHub: github.com/hkjarral/Asterisk-AI-Voice-Agent

      - Full Demo Video: youtube.com/watch?v=ZGrr9-Q85xA


      6 PRODUCTION CONFIGURATIONS WITH PRICING:

      1. Google Gemini Live - Fastest response under 1 second, multilingual, about 2.5 cents per minute

      2. Deepgram Voice Agent - Enterprise with Think stage reasoning, about 8 cents per minute

      3. OpenAI Realtime - Most natural conversations, easiest setup, about 18 cents per minute

      4. ElevenLabs Agent - Premium voice quality, about 10 cents per minute

      5. Local Hybrid - Privacy-focused with audio staying local, about 0.2 cents per minute

      6. Fully Local - 100% on-premises, zero cost, requires more CPU power


      QUICK SETUP:

      1. Clone the repo from GitHub

      2. Run install.sh which guides you through everything

      3. Add dialplan to route calls to Stasis asterisk-ai-voice-agent


      FREEPBX ARI SETUP:

      Go to Settings, then Advanced Settings, search for Asterisk REST Interface, enable it, and Apply Config.


      REQUIREMENTS:

      - Cloud configs need 2 plus CPU cores and 4GB RAM

      - Local Hybrid needs 4 plus cores and 8GB RAM

      - Docker, Docker Compose, Asterisk 18 or newer with ARI enabled

      - x86 64-bit Linux only including Ubuntu, Debian, RHEL, Rocky, or Fedora


      ADMIN UI: Web dashboard at port 3003 for real-time configuration of all settings.


      THIS DEMO - ELEVENLABS AGENT:

      - Premium natural-sounding voices with full conversational AI

      - Cost is about 10 cents per minute with plans starting at 5 dollars per month

      - Response time is under 2 seconds

      - Best for premium voice quality and exceptional user experience


      YOUR ROLE:

      - Answer questions about the project, setup, pricing, and features

      - Demonstrate the premium ElevenLabs voice quality

      - Help users understand when ElevenLabs is the right choice

      - Keep responses short, 1 to 3 sentences, unless more detail is requested

      - Do not read punctuation characters out loud, pause briefly instead


      CALL ENDING PROTOCOL:

      - When user says goodbye, first offer to email them a transcript

      - If yes, use request_transcript tool to get their email

      - Then confirm if there is anything else, and use hangup_call tool with a warm farewell
    provider: elevenlabs_agent
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
    background_music: jingle
  demo_aviation_atis:
    greeting: >-
      Hello, this is the aviation automatic terminal information service. I can
      provide ATIS for any airport worldwide. Just tell me the airport name or
      ICAO code.
    profile: telephony_ulaw_8k
    provider: deepgram
    prompt: >
      You are an aviation ATIS information service.


      ICAO CODE MAPPING:

      - "JFK" or "Kennedy" or "New York" → KJFK

      - "LAX" or "Los Angeles" → KLAX

      - "SJC" or "San Jose" → KSJC

      - "SFO" or "San Francisco" → KSFO

      - "Heathrow" or "London" or "LHR" → EGLL

      - "Dubai" → OMDB

      - "Payerne" → LSMP

      - "O'Hare" or "Chicago" → KORD

      - "Atlanta" or "ATL" → KATL

      - "Denver" or "DEN" → KDEN

      - "Seattle" or "SEA" → KSEA

      - "Miami" or "MIA" → KMIA

      - "Boston" or "BOS" → KBOS


      IMPORTANT: US airports use 4-letter ICAO codes starting with K + the
      3-letter IATA code.

      Examples: SJC → KSJC, LAX → KLAX, JFK → KJFK, ATL → KATL


      WORKFLOW:

      1. User asks for ATIS for an airport

      2. Determine the 4-letter ICAO code

      3. IMMEDIATELY call mcp_aviation_atis with the icao parameter - do NOT
      speak before calling

      4. Read the returned ATIS text verbatim


      CRITICAL: Call the tool IMMEDIATELY after user request. Do NOT say "Stand
      by" or confirm first.


      SPEECH RULES:

      - Do NOT use markdown formatting like **bold** or *italic*

      - Do NOT say "Stand by" or "Please wait" - just call the tool immediately

      - Read the ATIS text exactly as provided, in plain spoken English


      ICAO CODE EXAMPLES:

      - SJC/San Jose → KSJC

      - SFO/San Francisco → KSFO

      - JFK/Kennedy/New York → KJFK

      - LAX/Los Angeles → KLAX  

      - Heathrow/London/LHR → EGLL

      - Any 3-letter US code: add K prefix (e.g., ATL → KATL, DEN → KDEN)


      AFTER PROVIDING ATIS:

      - After reading the ATIS, ask: "Would you like ATIS for another airport?"

      - Wait for the caller's response before doing anything else

      - Do NOT hang up automatically after providing ATIS


      ENDING CALLS:

      - ONLY use hangup_call when the caller explicitly says goodbye, bye, or
      thanks

      - NEVER hang up immediately after providing ATIS

      - When caller says goodbye, use hangup_call with farewell "Safe flying!"
    tools:
      - hangup_call
      - mcp_aviation_atis
  demo_mcp:
    greeting: >-
      Hi! I can check the weather for any city. Just ask me what the weather is
      like somewhere!
    profile: telephony_ulaw_8k
    provider: openai_realtime
    tools:
      - hangup_call
      - mcp_weather_get_city
default_provider: local_hybrid
downstream_mode: stream
external_media:
  codec: ulaw
  direction: both
  format: slin16
  port_range: '18080:18099'
  rtp_host: 127.0.0.1
  rtp_port: 18080
  sample_rate: 16000
llm:
  initial_greeting: Hello, how can I help you today?
  prompt: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
pipelines:
  local_hybrid:
    llm: openai_llm
    options:
      llm:
        base_url: https://api.openai.com/v1
        max_tokens: 200
        model: gpt-4o-mini
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        mode: tts
        response_timeout_sec: 30
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tools:
      - transfer
      - cancel_transfer
      - hangup_call
      - leave_voicemail
      - send_email_summary
      - request_transcript
    tts: local_tts
  local_hybrid_groq:
    llm: groq_llm
    options:
      llm:
        base_url: https://api.groq.com/openai/v1
        max_tokens: 200
        model: llama-3.3-70b-versatile
        temperature: 0.7
      stt:
        chunk_ms: 160
        mode: stt
        stream_format: pcm16_16k
        streaming: true
      tts:
        mode: tts
        response_timeout_sec: 30
        format:
          encoding: mulaw
          sample_rate: 8000
    stt: local_stt
    tts: local_tts
profiles:
  default: telephony_responsive
  openai_realtime_24k:
    chunk_ms: 20
    idle_cutoff_ms: 0
    internal_rate_hz: 24000
    provider_pref:
      input_encoding: pcm16
      input_sample_rate_hz: 24000
      output_encoding: pcm16
      output_sample_rate_hz: 24000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_responsive:
    chunk_ms: auto
    idle_cutoff_ms: 600
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: slin
      sample_rate_hz: 8000
  telephony_ulaw_8k:
    chunk_ms: auto
    idle_cutoff_ms: 800
    internal_rate_hz: 8000
    provider_pref:
      input_encoding: mulaw
      input_sample_rate_hz: 8000
      output_encoding: mulaw
      output_sample_rate_hz: 8000
    transport_out:
      encoding: ulaw
      sample_rate_hz: 8000
  wideband_pcm_16k:
    chunk_ms: auto
    idle_cutoff_ms: 1200
    internal_rate_hz: 16000
    provider_pref:
      input_encoding: linear16
      input_sample_rate_hz: 16000
      output_encoding: linear16
      output_sample_rate_hz: 16000
    transport_out:
      encoding: slin16
      sample_rate_hz: 16000
providers:
  deepgram:
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: mulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: Voice assistant. Answer in 5-8 words. Be direct. Expand only if asked.
    model: nova-2
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    tts_model: aura-2-thalia-en
    type: full
  google_live:
    api_key: ${GOOGLE_API_KEY}
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    enable_input_transcription: true
    enable_output_transcription: true
    enabled: true
    greeting: >-
      ${GOOGLE_LIVE_GREETING:-Hi! I'm powered by Google Gemini Live API. Try
      interrupting me!}
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    llm_max_output_tokens: 8192
    llm_model: gemini-2.5-flash-native-audio-preview-12-2025
    llm_temperature: 0.8
    llm_top_k: 40
    llm_top_p: 0.95
    output_encoding: linear16
    output_sample_rate_hz: 24000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 16000
    response_modalities: audio
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    tts_voice_name: Aoede
    type: full
  local:
    base_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - stt
      - llm
      - tts
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    continuous_input: true
    enabled: true
    farewell_mode: ${LOCAL_FAREWELL_MODE:=asterisk}
    farewell_timeout_sec: ${LOCAL_FAREWELL_TIMEOUT:=30.0}
    greeting: Hello! I'm your local AI assistant running entirely on-premises.
    instructions: >-
      You are a helpful voice assistant running locally. Be concise and
      friendly.
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 64
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_model: models/stt/vosk-model-en-us-0.22
    temperature: 0.4
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: full
  local_llm:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - llm
    enabled: true
    llm_model: models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf
    max_tokens: 32
    temperature: 0.4
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_stt:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - stt
    chunk_ms: ${LOCAL_WS_CHUNK_MS:=320}
    connect_timeout_sec: ${LOCAL_WS_CONNECT_TIMEOUT:=2.0}
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    stt_backend: vosk
    stt_model: models/stt/vosk-model-en-us-0.22
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  local_tts:
    auth_token: ${LOCAL_WS_AUTH_TOKEN:-}
    capabilities:
      - tts
    enabled: true
    response_timeout_sec: ${LOCAL_WS_RESPONSE_TIMEOUT:=10.0}
    tts_voice: models/tts/en_US-lessac-medium.onnx
    type: local
    ws_url: ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
  openai_llm:
    capabilities:
      - llm
    api_key: ${OPENAI_API_KEY}
    chat_base_url: https://api.openai.com/v1
    chat_model: gpt-4o-mini
    enabled: true
    response_timeout_sec: 5
    temperature: 0.7
    type: openai
  groq_llm:
    capabilities:
      - llm
    api_key: ${GROQ_API_KEY}
    chat_base_url: https://api.groq.com/openai/v1
    chat_model: llama-3.3-70b-versatile
    enabled: true
    response_timeout_sec: 10
    temperature: 0.7
    tools_enabled: false
    type: openai
  ollama_llm:
    capabilities:
      - llm
    base_url: http://localhost:11434
    model: llama3.2
    enabled: false
    temperature: 0.7
    max_tokens: 200
    timeout_sec: 60
    tools_enabled: true
    type: ollama
  openai_realtime:
    base_url: wss://api.openai.com/v1/realtime
    capabilities:
      - stt
      - llm
      - tts
    continuous_input: true
    egress_pacer_enabled: false
    egress_pacer_warmup_ms: 320
    enabled: true
    greeting: Hello, how can I help you today?
    input_encoding: ulaw
    input_gain_max_db: 0
    input_gain_target_rms: 0
    input_sample_rate_hz: 8000
    instructions: You are a voice assistant. Always speak your responses out loud.
    max_response_output_tokens: 4096
    model: gpt-4o-realtime-preview-2024-12-17
    organization: ''
    output_encoding: mulaw
    output_sample_rate_hz: 8000
    provider_input_encoding: linear16
    provider_input_sample_rate_hz: 16000
    response_modalities:
      - audio
      - text
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    temperature: 0.6
    turn_detection:
      create_response: true
      prefix_padding_ms: 300
      silence_duration_ms: 1000
      threshold: 0.5
      type: server_vad
    type: openai_realtime
    voice: alloy
  elevenlabs_agent:
    type: full
    enabled: true
    capabilities:
      - stt
      - llm
      - tts
    input_encoding: ulaw
    input_sample_rate_hz: 8000
    provider_input_encoding: pcm16
    provider_input_sample_rate_hz: 16000
    output_encoding: pcm16
    output_sample_rate_hz: 16000
    target_encoding: ulaw
    target_sample_rate_hz: 8000
    voice_id: uDsPstFWFBUXjIBimV7s
    model_id: eleven_flash_v2_5
    voice_settings:
      stability: 0.5
      similarity_boost: 0.75
      style: 0
      use_speaker_boost: true
    greeting: Hello! I'm your ElevenLabs voice assistant. How can I help you today?
    instructions: You are a helpful voice assistant. Be concise and friendly.
    continuous_input: true
    input_gain_target_rms: 0
    input_gain_max_db: 0
  openai_stt:
    chunk_size_ms: 20
    enabled: true
    input_encoding: linear16
    input_sample_rate_hz: 16000
    stt_model: whisper-1
    type: openai
  openai_tts:
    enabled: true
    target_encoding: mulaw
    target_sample_rate_hz: 8000
    tts_base_url: https://api.openai.com/v1/audio/speech
    tts_model: gpt-4o-mini-tts
    type: openai
    voice: alloy
streaming:
  chunk_size_ms: 20
  connection_timeout_ms: 120000
  continuous_stream: true
  diag_enable_taps: true
  diag_out_dir: /tmp/ai-engine-taps
  diag_post_secs: 1
  diag_pre_secs: 1
  empty_backoff_ticks_max: 5
  fallback_timeout_ms: 8000
  greeting_min_start_ms: 40
  jitter_buffer_ms: 950
  keepalive_interval_ms: 5000
  low_watermark_ms: 80
  min_start_ms: 120
  normalizer:
    enabled: true
    max_gain_db: 18
    target_rms: 1400
  provider_grace_ms: 200
  sample_rate: 8000
tools:
  ai_identity:
    name: AI Agent
    number: '6789'
  cancel_transfer:
    allow_after_answer: false
    allow_during_ring: true
    enabled: true
  default_action_timeout: 30
  enabled: true
  extensions:
    internal:
      '6000':
        action_type: transfer
        aliases:
          - agent
          - representative
          - human
          - real person
          - live person
          - someone
          - support
          - sales
          - operator
          - help desk
        description: Live customer service representative
        dial_string: SIP/6000
        mode: warm
        name: Live Agent
        pass_caller_info: true
        timeout: 30
        transfer: true
  hangup_call:
    enabled: true
    farewell_message: Thank you for calling. Goodbye!
    require_confirmation: false
  leave_voicemail:
    enabled: true
    extension: '2765'
  request_transcript:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    common_domains:
      - gmail.com
      - yahoo.com
      - outlook.com
      - hotmail.com
      - icloud.com
    confirm_email: true
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    max_attempts: 2
    provider: resend
    validate_domain: true
  send_email_summary:
    admin_email: haider@jugaar.llc
    api_key: ${RESEND_API_KEY}
    enabled: true
    from_email: ava@jugaar.llc
    from_name: AI Voice Agent
    include_metadata: true
    include_transcript: true
    provider: resend
  transfer:
    technology: SIP
    destinations:
      sales_agent:
        description: Sales agent
        target: '2765'
        type: extension
      sales_queue:
        description: Sales team queue
        target: '300'
        type: queue
      sales_team:
        description: Sales team ring group
        target: '600'
        type: ringgroup
      support_agent:
        description: Support agent
        target: '6000'
        type: extension
      support_queue:
        description: Technical support queue
        target: '301'
        type: queue
      support_team:
        description: Support team ring group
        target: '601'
        type: ringgroup
    enabled: true
mcp:
  enabled: true
  servers:
    weather:
      transport: stdio
      command:
        - python3
        - '-m'
        - src.mcp_servers.weather_mcp_server
      defaults:
        timeout_ms: 15000
        slow_response_threshold_ms: 3000
        slow_response_message: Let me check the weather for you, one moment...
      tools:
        - name: get_weather_by_city
          expose_as: mcp_weather_get_city
          speech_field: spoken
    aviation_atis:
      transport: stdio
      command:
        - python3
        - '-m'
        - src.mcp_servers.aviation_atis_server
        - '--config'
        - /app/config/aviation_atis.yaml
      env:
        METNO_USER_AGENT: >-
          Asterisk-AI-Voice-Agent
          (+https://github.com/hkjarral/Asterisk-AI-Voice-Agent)
      defaults:
        timeout_ms: 15000
        slow_response_threshold_ms: 3000
        slow_response_message: Let me get the current ATIS for you, one moment...
      tools:
        - name: get_atis
          expose_as: mcp_aviation_atis
          description: Get current ATIS for an ICAO airport code (e.g., LSMP, KJFK)
          speech_field: atis_text
vad:
  enhanced_enabled: true
  fallback_buffer_size: 128000
  fallback_enabled: true
  fallback_interval_ms: 4000
  max_utterance_duration_ms: 10000
  min_utterance_duration_ms: 600
  use_provider_vad: false
  utterance_padding_ms: 200
  webrtc_aggressiveness: 1
  webrtc_end_silence_frames: 50
  webrtc_start_frames: 3
