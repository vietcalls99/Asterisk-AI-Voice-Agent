import asyncio
import copy
import logging
import math
import os
import random
import signal
import struct
import time
import uuid
import audioop
import base64
import json
import ipaddress
from collections import deque
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List, Set, Tuple, Callable

# Simple audio capture system removed - not used in production

# WebRTC VAD for robust speech detection
try:
    import webrtcvad  # pyright: ignore[reportMissingImports]
    WEBRTC_VAD_AVAILABLE = True
except ImportError:
    WEBRTC_VAD_AVAILABLE = False
    webrtcvad = None

from prometheus_client import CONTENT_TYPE_LATEST, generate_latest, Histogram, Counter, Gauge

from .ari_client import ARIClient
from aiohttp import web
from pydantic import ValidationError

from .config import (
    AppConfig,
    load_config,
    LocalProviderConfig,
    DeepgramProviderConfig,
    GoogleProviderConfig,
    OpenAIRealtimeProviderConfig,
)
from .pipelines import PipelineOrchestrator, PipelineOrchestratorError, PipelineResolution
from .logging_config import get_logger, configure_logging
from .rtp_server import RTPServer
from .audio.audiosocket_server import AudioSocketServer
from .providers.base import AIProviderInterface
from .providers.deepgram import DeepgramProvider
from .providers.local import LocalProvider
from .providers.openai_realtime import OpenAIRealtimeProvider
from .providers.google_live import GoogleLiveProvider
from .providers.elevenlabs_agent import ElevenLabsAgentProvider
from .providers.elevenlabs_config import ElevenLabsAgentConfig
from .core import SessionStore, PlaybackManager, ConversationCoordinator
from .core.vad_manager import EnhancedVADManager, VADResult
from .core.streaming_playback_manager import StreamingPlaybackManager
from .core.transport_orchestrator import TransportOrchestrator, TransportProfile
from .core.models import CallSession
from .utils.audio_capture import AudioCaptureManager
from src.pipelines.base import LLMResponse

logger = get_logger(__name__)

# -----------------------------------------------------------------------------
# Environment variable resolution helper
# -----------------------------------------------------------------------------
import re

def _resolve_env_vars(value: Any) -> Any:
    """
    Resolve environment variable placeholders in config values.
    Supports ${VAR}, ${VAR:-default}, and ${VAR:=default} syntax.
    """
    if not isinstance(value, str):
        return value
    
    # Pattern matches ${VAR}, ${VAR:-default}, ${VAR:=default}
    pattern = r'\$\{([^}:]+)(?::-|:=)?([^}]*)?\}'
    
    def replace_env(match):
        var_name = match.group(1)
        default_value = match.group(2) if match.group(2) else ""
        return os.getenv(var_name, default_value)
    
    resolved = re.sub(pattern, replace_env, value)
    return resolved


def _resolve_config_env_vars(config_dict: Dict[str, Any]) -> Dict[str, Any]:
    """Resolve environment variables in all string values of a config dict."""
    resolved = {}
    for key, value in config_dict.items():
        if isinstance(value, str):
            resolved[key] = _resolve_env_vars(value)
        elif isinstance(value, dict):
            resolved[key] = _resolve_config_env_vars(value)
        else:
            resolved[key] = value
    return resolved

# -----------------------------------------------------------------------------
# Prometheus latency histograms (module scope, registered once)
# -----------------------------------------------------------------------------
_TURN_STT_TO_TTS = Histogram(
    "ai_agent_stt_to_tts_seconds",
    "Time from STT final transcript to first TTS bytes",
    buckets=(0.1, 0.2, 0.3, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 5.0),
    labelnames=("pipeline", "provider"),
)
_TURN_RESPONSE_SECONDS = Histogram(
    "ai_agent_turn_response_seconds",
    "Approx time from STT final transcript to ARI playback start",
    buckets=(0.2, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 5.0, 8.0),
    labelnames=("pipeline", "provider"),
)

# Config exposure gauges (per call at session start)
_CFG_BARGE_MS = Gauge(
    "ai_agent_config_barge_in_ms",
    "Configured barge-in timing values (ms)",
    labelnames=("param",),
)
_CFG_BARGE_THRESHOLD = Gauge(
    "ai_agent_config_barge_in_threshold",
    "Configured barge-in energy threshold",
)
_CFG_STREAM_MS = Gauge(
    "ai_agent_config_streaming_ms",
    "Configured streaming timing values (ms)",
    labelnames=("param",),
)
_CFG_TD_MS = Gauge(
    "ai_agent_config_turn_detection_ms",
    "Configured provider turn detection timing values (ms)",
    labelnames=("param",),
)
_CFG_TD_THRESHOLD = Gauge(
    "ai_agent_config_turn_detection_threshold",
    "Configured provider turn detection threshold",
)

# Barge-in reaction latency (seconds) from first energy to trigger
_BARGE_REACTION_SECONDS = Histogram(
    "ai_agent_barge_in_reaction_seconds",
    "Time from first speech energy to barge-in trigger",
    buckets=(0.1, 0.2, 0.3, 0.5, 0.8, 1.2, 2.0),
)

# Per-call audio byte counters (ingress)
_STREAM_RX_BYTES = Counter(
    "ai_agent_stream_rx_bytes_total",
    "Inbound audio bytes from caller (per call)",
)
_CODEC_ALIGNMENT = Gauge(
    "ai_agent_codec_alignment",
    "Codec/sample-rate alignment status per call/provider (1=aligned,0=degraded)",
    labelnames=("provider",),
)
_AUDIO_RMS_GAUGE = Gauge(
    "ai_agent_audio_rms",
    "Observed RMS levels for audio stages",
    labelnames=("stage",),
)
_AUDIO_DC_OFFSET = Gauge(
    "ai_agent_audio_dc_offset",
    "Observed DC offset (mean sample value) for audio stages",
    labelnames=("stage",),
)

# Call duration tracking (aggregate)
_CALL_DURATION = Histogram(
    "ai_agent_call_duration_seconds",
    "Total call duration from start to end",
    labelnames=("pipeline", "provider"),
    buckets=(10, 30, 60, 120, 180, 300, 600, 900, 1800, 3600),
)
# Track call start times for duration calculation
_call_start_times = {}  # call_id -> timestamp

# In-memory set to prevent duplicate cleanup (race condition guard)
_cleanup_in_progress: set = set()  # call_ids currently being cleaned up


class Engine:
    """The main application engine."""

    def __init__(self, config: AppConfig):
        self.config = config
        self._start_time = time.time()  # Track engine start time for uptime
        base_url = f"http://{config.asterisk.host}:{config.asterisk.port}/ari"
        self.ari_client = ARIClient(
            username=config.asterisk.username,
            password=config.asterisk.password,
            base_url=base_url,
            app_name=config.asterisk.app_name
        )
        # Set engine reference for event propagation
        self.ari_client.engine = self
        
        # Initialize core components
        self.session_store = SessionStore()
        self.conversation_coordinator = ConversationCoordinator(self.session_store)
        self.playback_manager = PlaybackManager(
            self.session_store,
            self.ari_client,
            conversation_coordinator=self.conversation_coordinator,
        )
        self.conversation_coordinator.set_playback_manager(self.playback_manager)
        # Per-call transcript timing cache for latency histograms
        self._last_transcript_ts: Dict[str, float] = {}
        
        # Initialize streaming playback manager
        streaming_config = {}
        if hasattr(config, 'streaming') and config.streaming:
            audiosocket_fmt = "ulaw"
            try:
                if getattr(config, "audiosocket", None) and getattr(config.audiosocket, "format", None):
                    audiosocket_fmt = str(config.audiosocket.format).lower()
            except Exception:
                audiosocket_fmt = "ulaw"
            streaming_sample_rate = int(getattr(config.streaming, 'sample_rate', 8000) or 8000)
            # For PCM transport over AudioSocket, prefer 16 kHz by default unless explicitly set
            if self._canonicalize_encoding(audiosocket_fmt) in {"slin16", "linear16", "pcm16"}:
                try:
                    if not getattr(config.streaming, 'sample_rate', None):
                        streaming_sample_rate = 16000
                except Exception:
                    streaming_sample_rate = 16000
            streaming_config = {
                'sample_rate': streaming_sample_rate,
                'jitter_buffer_ms': config.streaming.jitter_buffer_ms,
                'keepalive_interval_ms': config.streaming.keepalive_interval_ms,
                'connection_timeout_ms': config.streaming.connection_timeout_ms,
                'fallback_timeout_ms': config.streaming.fallback_timeout_ms,
                'chunk_size_ms': config.streaming.chunk_size_ms,
                # Additional tuning knobs
                'min_start_ms': config.streaming.min_start_ms,
                'low_watermark_ms': config.streaming.low_watermark_ms,
                'provider_grace_ms': config.streaming.provider_grace_ms,
                'logging_level': config.streaming.logging_level,
                'egress_swap_mode': getattr(config.streaming, 'egress_swap_mode', 'auto'),
                'egress_force_mulaw': self._should_force_mulaw(
                    getattr(config.streaming, 'egress_force_mulaw', False),
                    audiosocket_fmt,
                ),
                # Continuous stream across provider segments (single pacer per call)
                'continuous_stream': bool(getattr(config.streaming, 'continuous_stream', True)),
                # Audio normalizer (RMS make-up gain prior to Î¼-law encode)
                'normalizer': {
                    'enabled': bool(getattr(getattr(config, 'streaming', {}), 'normalizer', {}).get('enabled', True)) if hasattr(config, 'streaming') else True,
                    'target_rms': int(getattr(getattr(config, 'streaming', {}), 'normalizer', {}).get('target_rms', 1400)) if hasattr(config, 'streaming') else 1400,
                    'max_gain_db': float(getattr(getattr(config, 'streaming', {}), 'normalizer', {}).get('max_gain_db', 9.0)) if hasattr(config, 'streaming') else 9.0,
                },
                # Diagnostics (optional): enable short PCM taps pre/post compand
                'diag_enable_taps': bool(getattr(config.streaming, 'diag_enable_taps', False)),
                'diag_pre_secs': int(getattr(config.streaming, 'diag_pre_secs', 0) or 0),
                'diag_post_secs': int(getattr(config.streaming, 'diag_post_secs', 0) or 0),
                'diag_out_dir': str(getattr(config.streaming, 'diag_out_dir', '') or ''),
            }
        # Debug/diagnostics: allow broadcasting outbound frames to all AudioSocket conns
        try:
            streaming_config['audiosocket_broadcast_debug'] = bool(int(os.getenv('AUDIOSOCKET_BROADCAST_DEBUG', '0')))
        except Exception:
            streaming_config['audiosocket_broadcast_debug'] = False

        # Initialize per-call audio capture used for diagnostics/RCA.
        # Captures are written under /tmp/ai-engine-captures/<call_id>/stream_name.wav,
        # which is what scripts/rca_collect.sh expects when building the "captures" bundle.
        capture_dir = "/tmp/ai-engine-captures"
        # Use DIAG_ENABLE_TAPS as a generic switch for keeping capture files after calls complete.
        keep_captures = os.getenv("DIAG_ENABLE_TAPS", "false").lower() in ("true", "1", "yes")
        self.audio_capture = AudioCaptureManager(base_dir=capture_dir, keep_files=keep_captures)
        logger.info(
            "Audio capture initialized",
            base_dir=capture_dir,
            keep_files=keep_captures,
        )
        self.streaming_playback_manager = StreamingPlaybackManager(
            self.session_store,
            self.ari_client,
            conversation_coordinator=self.conversation_coordinator,
            fallback_playback_manager=self.playback_manager,
            streaming_config=streaming_config,
            audio_transport=self.config.audio_transport,
            audio_diag_callback=self._update_audio_diagnostics_by_call,
            audio_capture_manager=self.audio_capture,
        )
        # Pre-seed audiosocket_format from YAML so provider audits use correct value
        try:
            initial_as_fmt = None
            if getattr(self.config, "audiosocket", None) and hasattr(self.config.audiosocket, "format"):
                initial_as_fmt = self.config.audiosocket.format
            if initial_as_fmt:
                self.streaming_playback_manager.set_transport(
                    audio_transport=self.config.audio_transport,
                    audiosocket_format=initial_as_fmt,
                )
        except Exception:
            logger.debug("Failed to pre-seed streaming manager format", exc_info=True)
        
        # Modular pipeline orchestrator coordinates per-call STT/LLM/TTS adapters.
        self.pipeline_orchestrator = PipelineOrchestrator(config)
        
        # P1: Transport orchestrator for multi-provider audio format negotiation
        self.transport_orchestrator = TransportOrchestrator(config.dict() if hasattr(config, 'dict') else config.__dict__)
        logger.info(
            "TransportOrchestrator initialized",
            profiles=list(self.transport_orchestrator.profiles.keys()),
            contexts=list(self.transport_orchestrator.contexts.keys()),
            default=self.transport_orchestrator.default_profile_name,
        )
        
        # Provider templates are safe to use for readiness/capability inspection, but
        # MUST NOT be used for per-call sessions (providers keep call-specific state).
        self.providers: Dict[str, AIProviderInterface] = {}
        # Factories for creating per-call provider instances (supports concurrent calls).
        self.provider_factories: Dict[str, Callable[[], AIProviderInterface]] = {}
        # Active provider instances keyed by call_id (one provider instance per call).
        self._call_providers: Dict[str, AIProviderInterface] = {}
        # Single-flight start tasks keyed by call_id (prevents duplicate start_session races).
        self._provider_start_tasks: Dict[str, asyncio.Task] = {}
        # Track static codec/sample-rate validation issues per provider
        self.provider_alignment_issues: Dict[str, List[str]] = {}
        # Per-call provider streaming queues (AgentAudio -> streaming playback)
        self._provider_stream_queues: Dict[str, asyncio.Queue] = {}
        self._provider_stream_formats: Dict[str, Dict[str, Any]] = {}
        # Prevent duplicate runtime warnings per call when misalignment persists
        self._runtime_alignment_logged: Set[str] = set()
        # Per-call downstream audio preferences (format/sample-rate)
        self.call_audio_preferences: Dict[str, Dict[str, Any]] = {}
        self.conn_to_channel: Dict[str, str] = {}
        self.channel_to_conn: Dict[str, str] = {}
        self.conn_to_caller: Dict[str, str] = {}  # conn_id -> caller_channel_id
        self.audio_socket_server: Optional[AudioSocketServer] = None
        self.audiosocket_conn_to_ssrc: Dict[str, int] = {}
        self.audiosocket_resample_state: Dict[str, Optional[tuple]] = {}
        # Stateful resampling: maintain per-call/per-provider ratecv states to avoid drift
        # Provider input (caller -> provider) resample state
        self._resample_state_provider_in: Dict[str, Dict[str, Optional[tuple]]] = {}
        # Forced pipeline PCM16@16k path (per-call)
        self._resample_state_pipeline16k: Dict[str, Optional[tuple]] = {}
        # Enhanced VAD normalization to 8 kHz (per-call)
        self._resample_state_vad8k: Dict[str, Optional[tuple]] = {}
        self.pending_channel_for_bind: Optional[str] = None
        # Support duplicate Local ;1/;2 AudioSocket connections per call
        self.channel_to_conns: Dict[str, set] = {}
        self.audiosocket_primary_conn: Dict[str, str] = {}
        # Audio buffering for better playback quality
        self.audio_buffers: Dict[str, bytes] = {}
        self.buffer_size = 1600  # 200ms of audio at 8kHz (1600 bytes of ulaw)
        self.rtp_server: Optional[Any] = None
        self.headless_sessions: Dict[str, Dict[str, Any]] = {}
        # Bridge and Local channel tracking for Local Channel Bridge pattern
        self.bridges: Dict[str, str] = {}  # channel_id -> bridge_id
        self.local_channels: Dict[str, str] = {}  # channel_id -> legacy local_channel_id
        self.audiosocket_channels: Dict[str, str] = {}  # call_id -> audiosocket_channel_id
        # Streaming per-call persistent stream and gating state
        self._provider_stream_ids: Dict[str, str] = {}
        self._segment_tts_active: Set[str] = set()
        
        self.vad_manager: Optional[EnhancedVADManager] = None
        self.webrtc_vad = None
        try:
            vad_cfg = getattr(config, "vad", None)
            use_provider_vad = bool(getattr(vad_cfg, "use_provider_vad", False)) if vad_cfg else False
            if use_provider_vad:
                logger.info("Using provider-managed VAD; local VAD disabled")
            elif vad_cfg and getattr(vad_cfg, "enhanced_enabled", False):
                self.vad_manager = EnhancedVADManager(
                    energy_threshold=int(getattr(vad_cfg, "energy_threshold", 1500)),
                    confidence_threshold=float(getattr(vad_cfg, "confidence_threshold", 0.6)),
                    adaptive_threshold_enabled=bool(getattr(vad_cfg, "adaptive_threshold_enabled", False)),
                    noise_adaptation_rate=float(getattr(vad_cfg, "noise_adaptation_rate", 0.1)),
                    webrtc_aggressiveness=int(getattr(vad_cfg, "webrtc_aggressiveness", 1)),
                    min_speech_frames=int(getattr(vad_cfg, "webrtc_start_frames", 2)),
                    max_silence_frames=int(getattr(vad_cfg, "webrtc_end_silence_frames", 15)),
                )
                logger.info(
                    "Enhanced VAD enabled",
                    energy_threshold=self.vad_manager.energy_threshold,
                    confidence_threshold=self.vad_manager.confidence_threshold,
                )
                logger.info(
                    "ðŸŽ¯ WebRTC VAD settings",
                    aggressiveness=int(getattr(vad_cfg, "webrtc_aggressiveness", 1)),
                )
                if WEBRTC_VAD_AVAILABLE:
                    try:
                        aggressiveness = config.vad.webrtc_aggressiveness
                        self.webrtc_vad = webrtcvad.Vad(aggressiveness)
                        logger.info("ðŸŽ¤ WebRTC VAD initialized", aggressiveness=aggressiveness)
                    except Exception as e:
                        logger.warning("ðŸŽ¤ WebRTC VAD initialization failed", error=str(e))
                        self.webrtc_vad = None
                elif not use_provider_vad:
                    logger.warning("ðŸŽ¤ WebRTC VAD not available - install py-webrtcvad")
        except Exception:
            logger.error("Failed to initialize VAD components", exc_info=True)
        
        # Initialize Audio Gating Manager (for echo prevention in OpenAI Realtime)
        self.audio_gating_manager = None
        try:
            # Only initialize if VAD is available (needed for interrupt detection)
            if self.vad_manager:
                from src.core.audio_gating_manager import AudioGatingManager
                self.audio_gating_manager = AudioGatingManager(vad_manager=self.vad_manager)
                logger.info("ðŸŽ›ï¸ Audio gating manager initialized (OpenAI echo prevention)")
            else:
                logger.debug("Audio gating manager not initialized (VAD not available)")
        except Exception:
            logger.error("Failed to initialize audio gating manager", exc_info=True)
            self.audio_gating_manager = None
        
        # Map our synthesized UUID extension to the real ARI caller channel id
        self.uuidext_to_channel: Dict[str, str] = {}
        # NEW: Caller channel tracking for dual StasisStart handling
        self.pending_local_channels: Dict[str, str] = {}  # local_channel_id -> caller_channel_id
        # For smoke/dialplan-driven test calls that originate a Local channel directly into
        # an AI-agent context, track the Local channel "base" so we can treat only one
        # half as the caller and map the other half as the Local helper leg.
        self._smoke_local_base_to_caller: Dict[str, str] = {}  # base_name -> caller_channel_id
        # Track the non-caller half of the Local channel. In practice, the dialplan side
        # is typically `;2` (caller leg for our smoke tests) and `;1` is the paired leg.
        self._smoke_local_base_to_leg1: Dict[str, str] = {}  # base_name -> local_channel_id (leg1)
        self.pending_audiosocket_channels: Dict[str, str] = {}  # audiosocket_channel_id -> caller_channel_id
        self._audio_rx_debug: Dict[str, int] = {}
        self._keepalive_tasks: Dict[str, asyncio.Task] = {}
        # Track provider segment start timestamps per call for duration logging
        self._provider_segment_start_ts: Dict[str, float] = {}
        # Track provider AgentAudio chunk sequence per call for duration logging
        self._provider_chunk_seq: Dict[str, int] = {}
        # Track per-segment provider bytes vs. bytes enqueued to streaming
        self._provider_bytes: Dict[str, int] = {}
        self._enqueued_bytes: Dict[str, int] = {}
        # Transport observability
        self._transport_card_logged: Set[str] = set()
        # Audio Profile Resolution card one-shot tracker
        self._profile_card_logged: Set[str] = set()
        # Experimental coalescing: per-call buffer for provider TTS chunks
        self._provider_coalesce_buf: Dict[str, bytearray] = {}
        # Active playbacks are now managed by SessionStore
        # ExternalMedia to caller channel mapping is now managed by SessionStore
        # SSRC to caller channel mapping for RTP audio routing
        self.ssrc_to_caller: Dict[int, str] = {}  # ssrc -> caller_channel_id
        # Pipeline runtime structures (Milestone 7): per-call audio queues and runner tasks
        self._pipeline_queues: Dict[str, asyncio.Queue] = {}
        self._pipeline_tasks: Dict[str, asyncio.Task] = {}
        # Track calls where a pipeline was explicitly requested via AI_PROVIDER
        self._pipeline_forced: Dict[str, bool] = {}
        # Health server runner
        self._health_runner: Optional[web.AppRunner] = None
        # MCP client manager (experimental)
        self.mcp_manager = None

        # Event handlers
        self.ari_client.on_event("StasisStart", self._handle_stasis_start)
        self.ari_client.on_event("StasisEnd", self._handle_stasis_end)
        self.ari_client.on_event("ChannelDestroyed", self._handle_channel_destroyed)
        self.ari_client.on_event("ChannelDtmfReceived", self._handle_dtmf_received)
        self.ari_client.on_event("ChannelVarset", self._handle_channel_varset)
        # Pipelines (local_hybrid): use Asterisk talk detection to trigger barge-in during
        # channel playback, where ExternalMedia RTP can be paused/altered.
        self.ari_client.on_event("ChannelTalkingStarted", self._handle_channel_talking_started)
        self.ari_client.on_event("ChannelTalkingFinished", self._handle_channel_talking_finished)

    async def on_rtp_packet(self, packet: bytes, addr: tuple):
        """Handle incoming RTP packets from the UDP server."""
        # ARCHITECT FIX: This legacy bypass fragments STT and bypasses VAD
        # Log warning and disable to ensure all audio goes through VAD
        logger.warning("ðŸš¨ LEGACY RTP BYPASS - This method bypasses VAD and fragments STT", 
                      packet_len=len(packet), 
                      addr=addr)
        
        # All audio goes through RTPServer -> _on_rtp_audio -> _process_rtp_audio_with_vad
        return

    async def _on_ari_event(self, event: Dict[str, Any]):
        """Default event handler for unhandled ARI events."""
        logger.debug("Received unhandled ARI event", event_type=event.get("type"), ari_event=event)

    async def _save_session(self, session: CallSession, *, new: bool = False) -> None:
        """Persist session updates and keep coordinator metrics in sync."""
        await self.session_store.upsert_call(session)
        if self.conversation_coordinator:
            if new:
                await self.conversation_coordinator.register_call(session)
            else:
                await self.conversation_coordinator.sync_from_session(session)

    async def start(self):
        """Connect to ARI and start the engine."""
        # 1) Load providers first (low risk)
        await self._load_providers()
        
        # Initialize tool calling system
        try:
            from src.tools.registry import tool_registry
            tool_registry.initialize_default_tools()
            logger.info("âœ… Tool calling system initialized", tool_count=len(tool_registry.list_tools()))
        except Exception as e:
            logger.warning(f"Failed to initialize tool calling system: {e}", exc_info=True)

        # Initialize MCP tools (experimental)
        try:
            from src.mcp.manager import MCPClientManager
            mcp_cfg = getattr(self.config, "mcp", None)
            if mcp_cfg and getattr(mcp_cfg, "enabled", False):
                self.mcp_manager = MCPClientManager(mcp_cfg)
                await self.mcp_manager.start()
                from src.tools.registry import tool_registry
                self.mcp_manager.register_tools(tool_registry)
                logger.info("âœ… MCP tools initialized")
        except Exception as e:
            logger.warning("Failed to initialize MCP tools", error=str(e), exc_info=True)

        # Start modular pipeline orchestrator to prepare per-call component lookups.
        # Note: Full agent providers (deepgram, google_live, openai_realtime, elevenlabs_agent, local)
        # don't need pipelines - they handle STT+LLM+TTS internally. Pipeline errors are expected
        # when using full agent mode without modular pipeline configuration.
        try:
            await self.pipeline_orchestrator.start()
        except PipelineOrchestratorError as exc:
            # This is expected when using full agent mode without modular pipelines configured
            logger.info(
                "Pipeline orchestrator not configured - using full agent provider mode. "
                "This is normal when default_provider is a full agent (deepgram, google_live, openai_realtime, elevenlabs_agent, local).",
                detail=str(exc),
            )
        except Exception as exc:
            logger.warning(
                "Unexpected error starting pipeline orchestrator - falling back to direct provider mode",
                error=str(exc),
            )

        # 2) Start health server EARLY so diagnostics are available even if transport/ARI fail
        try:
            asyncio.create_task(self._start_health_server())
        except Exception:
            logger.debug("Health server failed to start", exc_info=True)

        # 3) Log transport and downstream modes
        logger.info("Runtime modes", audio_transport=self.config.audio_transport, downstream_mode=self.config.downstream_mode)

        # 4) Prepare AudioSocket transport (guarded)
        if self.config.audio_transport == "audiosocket":
            try:
                if not self.config.audiosocket:
                    raise ValueError("AudioSocket configuration not found")

                host = self.config.audiosocket.host
                port = self.config.audiosocket.port
                self.audio_socket_server = AudioSocketServer(
                    host=host,
                    port=port,
                    on_uuid=self._audiosocket_handle_uuid,
                    on_audio=self._audiosocket_handle_audio,
                    on_disconnect=self._audiosocket_handle_disconnect,
                    on_dtmf=self._audiosocket_handle_dtmf,
                )
                await self.audio_socket_server.start()
                logger.info("AudioSocket server listening", host=host, port=port)
                # Configure streaming manager with AudioSocket format expected by dialplan
                as_format = None
                try:
                    if self.config.audiosocket and hasattr(self.config.audiosocket, 'format'):
                        as_format = self.config.audiosocket.format
                except Exception:
                    as_format = None
                self.streaming_playback_manager.set_transport(
                    audio_transport=self.config.audio_transport,
                    audiosocket_server=self.audio_socket_server,
                    audiosocket_format=as_format,
                )
                # Pre-call transport summary and alignment audit
                try:
                    self._audit_transport_alignment()
                except Exception:
                    logger.debug("Transport alignment audit failed", exc_info=True)
            except Exception as exc:
                logger.error("Failed to start AudioSocket transport", error=str(exc), exc_info=True)
                self.audio_socket_server = None

        # 5) Prepare RTP server for ExternalMedia transport (guarded)
        if self.config.audio_transport == "externalmedia":
            try:
                if not self.config.external_media:
                    raise ValueError("ExternalMedia configuration not found")
                
                rtp_host = self.config.external_media.rtp_host
                rtp_port = int(getattr(self.config.external_media, "rtp_port", 0) or 18080)
                codec = getattr(self.config.external_media, "codec", "ulaw")
                format = getattr(self.config.external_media, "format", "slin16")
                sample_rate = getattr(self.config.external_media, "sample_rate", None)
                
                # Infer sample_rate from format if not explicitly set
                if not sample_rate:
                    if format in ("slin16", "linear16", "pcm16"):
                        sample_rate = 16000
                    elif format in ("slin", "linear"):
                        sample_rate = 8000
                    else:  # ulaw, alaw
                        sample_rate = 8000
                
                
                port_range = self._parse_port_range(
                    getattr(self.config.external_media, "port_range", None),
                    rtp_port,
                )
                allowed_remote_hosts = getattr(self.config.external_media, "allowed_remote_hosts", None)
                if not allowed_remote_hosts:
                    try:
                        ipaddress.ip_address(str(self.config.asterisk.host))
                        allowed_remote_hosts = [str(self.config.asterisk.host)]
                        logger.info(
                            "ExternalMedia RTP allowlist defaulted to Asterisk host IP",
                            allowed_remote_hosts=allowed_remote_hosts,
                        )
                    except Exception:
                        allowed_remote_hosts = None
                lock_remote_endpoint = bool(
                    getattr(self.config.external_media, "lock_remote_endpoint", True)
                )
                
                # Create RTP server with callback to route audio to providers
                self.rtp_server = RTPServer(
                    host=rtp_host,
                    port=rtp_port,
                    engine_callback=self._on_rtp_audio,
                    codec=codec,
                    format=format,
                    sample_rate=sample_rate,
                    port_range=port_range,
                    allowed_remote_hosts=allowed_remote_hosts,
                    lock_remote_endpoint=lock_remote_endpoint,
                )
                
                # Start RTP server
                await self.rtp_server.start()
                logger.info("RTP server started for ExternalMedia transport", 
                           host=rtp_host, port=rtp_port, codec=codec, format=format, sample_rate=sample_rate)
                self.streaming_playback_manager.set_transport(
                    rtp_server=self.rtp_server,
                    audio_transport=self.config.audio_transport,
                )
                
                # Validate provider format alignment with ExternalMedia transport
                try:
                    for prov_name, provider in self.providers.items():
                        if hasattr(provider, 'config'):
                            cfg = provider.config
                            # Check provider input alignment.
                            # ExternalMedia "codec" reflects the RTP wire codec (e.g., ulaw@8k),
                            # while "sample_rate" here is the engine's internal PCM rate derived from external_media.format.
                            def _enc_class(enc: Any) -> str:
                                e = str(enc or "").strip().lower()
                                if e in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                                    return "g711_ulaw"
                                if e in ("alaw", "g711_alaw"):
                                    return "g711_alaw"
                                if e in ("slin", "slin16", "linear16", "pcm16", "pcm"):
                                    return "pcm16"
                                return e

                            transport_codec_class = _enc_class(codec)
                            provider_in_enc = getattr(cfg, "provider_input_encoding", None) or getattr(cfg, "input_encoding", None)
                            provider_in_class = _enc_class(provider_in_enc)

                            provider_rate_key = (
                                "provider_input_sample_rate_hz"
                                if getattr(cfg, "provider_input_sample_rate_hz", None) is not None
                                else "input_sample_rate_hz"
                            )
                            provider_input_rate = getattr(cfg, provider_rate_key, None)
                            try:
                                provider_input_rate = int(provider_input_rate) if provider_input_rate else None
                            except Exception:
                                provider_input_rate = None

                            # If the provider expects G.711, 8 kHz is correct regardless of internal PCM rate.
                            # If the provider expects PCM, align to the internal PCM rate to avoid resampling.
                            expected_rate = None
                            if provider_in_class in ("g711_ulaw", "g711_alaw"):
                                expected_rate = 8000
                            elif provider_in_class == "pcm16":
                                expected_rate = int(sample_rate or 0) or None

                            if provider_input_rate and expected_rate and provider_input_rate != expected_rate:
                                logger.warning(
                                    "âš ï¸  TRANSPORT/PROVIDER MISMATCH",
                                    provider=prov_name,
                                    transport="ExternalMedia",
                                    transport_codec=codec,
                                    transport_internal_rate=sample_rate,
                                    provider_input_encoding=str(provider_in_enc or ""),
                                    provider_rate=provider_input_rate,
                                    expected_rate=expected_rate,
                                    impact="Extra resampling step - slight quality loss",
                                    suggestion=f"Consider updating providers.{prov_name}.{provider_rate_key} to {expected_rate} to avoid resampling",
                                )
                except Exception:
                    logger.debug("Provider format validation failed", exc_info=True)
                
                # Pre-call transport summary and alignment audit
                try:
                    for prov_name, prov in self.providers.items():
                        issues = self._describe_provider_alignment(prov_name, prov)
                        if issues:
                            for issue in issues:
                                logger.info("Provider alignment info", provider=prov_name, issue=issue)
                except Exception:
                    logger.debug("Transport alignment audit failed", exc_info=True)
            except Exception as exc:
                logger.error("Failed to start ExternalMedia RTP transport", error=str(exc), exc_info=True)
                self.rtp_server = None

        # 6) Connect to ARI regardless to keep readiness visible and allow Stasis handling
        await self.ari_client.connect()
        # Add PlaybackFinished event handler for timing control
        self.ari_client.add_event_handler("PlaybackFinished", self._on_playback_finished)
        asyncio.create_task(self.ari_client.start_listening())
        logger.info("Engine started and listening for calls.")

    def _parse_port_range(self, value: Optional[Any], fallback_port: int) -> Tuple[int, int]:
        """Parse external_media.port_range into an inclusive (start, end) tuple."""
        try:
            if value is None:
                return (int(fallback_port), int(fallback_port))

            if isinstance(value, (list, tuple)) and len(value) == 2:
                start, end = int(value[0]), int(value[1])
            else:
                raw = str(value).strip()
                if not raw:
                    return (int(fallback_port), int(fallback_port))
                if ":" in raw:
                    start_s, end_s = raw.split(":", 1)
                elif "-" in raw:
                    start_s, end_s = raw.split("-", 1)
                else:
                    start_s = end_s = raw
                start, end = int(start_s), int(end_s)

            if start > end:
                start, end = end, start
            if start <= 0 or end <= 0:
                raise ValueError("Ports must be positive integers")
            return (start, end)
        except Exception:
            logger.warning(
                "Invalid external_media.port_range configuration; using fallback port",
                value=value,
                fallback=fallback_port,
            )
            return (int(fallback_port), int(fallback_port))

    async def stop(self, graceful_timeout: float = 30.0):
        """Disconnect from ARI and stop the engine.
        
        Args:
            graceful_timeout: Maximum seconds to wait for active calls to complete.
                             Set to 0 for immediate shutdown.
        """
        sessions = await self.session_store.get_all_sessions()
        active_count = len(sessions)
        
        if active_count > 0 and graceful_timeout > 0:
            logger.info(
                "[SHUTDOWN] Graceful shutdown initiated - waiting for active calls",
                active_calls=active_count,
                timeout_seconds=graceful_timeout,
            )
            
            # Wait for calls to complete (check every 1 second)
            start_time = time.time()
            while time.time() - start_time < graceful_timeout:
                sessions = await self.session_store.get_all_sessions()
                if len(sessions) == 0:
                    logger.info("[SHUTDOWN] All calls completed - proceeding with shutdown")
                    break
                remaining = graceful_timeout - (time.time() - start_time)
                logger.debug(
                    "[SHUTDOWN] Waiting for calls to complete",
                    active_calls=len(sessions),
                    remaining_seconds=int(remaining),
                )
                await asyncio.sleep(1.0)
            else:
                # Timeout reached - force cleanup
                sessions = await self.session_store.get_all_sessions()
                if len(sessions) > 0:
                    logger.warning(
                        "[SHUTDOWN] Timeout reached - forcing cleanup of remaining calls",
                        remaining_calls=len(sessions),
                    )
        
        # Clean up all remaining sessions
        sessions = await self.session_store.get_all_sessions()
        for session in sessions:
            await self._cleanup_call(session.call_id)
        await self.ari_client.disconnect()
        # Stop RTP server if running
        if hasattr(self, 'rtp_server') and self.rtp_server:
            await self.rtp_server.stop()
        # Stop health server
        if self.audio_socket_server:
            await self.audio_socket_server.stop()
            self.audio_socket_server = None
        try:
            if self._health_runner:
                await self._health_runner.cleanup()
        except Exception:
            logger.debug("Health server cleanup error", exc_info=True)
        # Ensure orchestrator releases component assignments before shutdown.
        try:
            await self.pipeline_orchestrator.stop()
        except Exception:
            logger.debug("Pipeline orchestrator stop error", exc_info=True)
        # Stop MCP servers last (best-effort)
        try:
            if self.mcp_manager:
                await self.mcp_manager.stop()
        except Exception:
            logger.debug("MCP manager stop error", exc_info=True)
        logger.info("Engine stopped.")

    async def _load_providers(self):
        """Load and initialize AI providers from the configuration."""
        # Pipeline adapter suffixes - these are loaded by PipelineOrchestrator, not Engine
        ADAPTER_SUFFIXES = ('_stt', '_llm', '_tts')
        
        # Provider templates are for readiness/capability checks only.
        # Per-call provider sessions are created via provider_factories.
        self.providers.clear()
        self.provider_factories.clear()
        
        logger.info("Loading AI providers...", provider_names=list(self.config.providers.keys()))
        for name, provider_config_data in self.config.providers.items():
            # Skip pipeline adapters - they're handled by PipelineOrchestrator
            if any(name.endswith(suffix) for suffix in ADAPTER_SUFFIXES):
                logger.debug("Skipping pipeline adapter '%s' (loaded by PipelineOrchestrator)", name)
                continue
            if isinstance(provider_config_data, dict) and not provider_config_data.get("enabled", True):
                logger.info("Provider '%s' disabled in configuration; skipping initialization.", name)
                continue
            try:
                issues = self._audit_provider_config(name, provider_config_data)
                if issues:
                    self.provider_alignment_issues[name] = issues
                elif name in self.provider_alignment_issues:
                    self.provider_alignment_issues.pop(name, None)
                if name == "local":
                    # Resolve env vars like ${LOCAL_WS_URL:-ws://127.0.0.1:8765}
                    resolved_config = _resolve_config_env_vars(provider_config_data)
                    config = LocalProviderConfig(**resolved_config)
                    provider = LocalProvider(config, self.on_provider_event)
                    self.providers[name] = provider
                    # Per-call factory (supports concurrent calls).
                    self.provider_factories[name] = lambda cfg=config: LocalProvider(self._clone_config(cfg), self.on_provider_event)
                    logger.info(f"Provider '{name}' loaded successfully.")

                    # Provide initial greeting from global LLM config
                    try:
                        if hasattr(provider, 'set_initial_greeting'):
                            provider.set_initial_greeting(getattr(self.config.llm, 'initial_greeting', None))
                    except Exception:
                        logger.debug("Failed to set initial greeting on LocalProvider", exc_info=True)

                    runtime_issues = self._describe_provider_alignment(name, provider)
                    if runtime_issues:
                        self.provider_alignment_issues.setdefault(name, []).extend(runtime_issues)
                elif name == "deepgram":
                    deepgram_config = self._build_deepgram_config(provider_config_data)
                    if not deepgram_config:
                        continue

                    # Validate OpenAI dependency for Deepgram
                    if not self.config.llm.api_key:
                        logger.error("Deepgram provider requires OpenAI API key in LLM config")
                        continue

                    provider = DeepgramProvider(deepgram_config, self.config.llm, self.on_provider_event)
                    # Set session store for turn latency tracking (Milestone 21)
                    provider.set_session_store(self.session_store)
                    self.providers[name] = provider
                    # Per-call factory (supports concurrent calls).
                    self.provider_factories[name] = lambda cfg=deepgram_config: DeepgramProvider(self._clone_config(cfg), self.config.llm, self.on_provider_event)
                    logger.info("Provider 'deepgram' loaded successfully with OpenAI LLM dependency.")

                    runtime_issues = self._describe_provider_alignment(name, provider)
                    if runtime_issues:
                        self.provider_alignment_issues.setdefault(name, []).extend(runtime_issues)
                elif name == "openai_realtime":
                    openai_cfg = self._build_openai_realtime_config(provider_config_data)
                    if not openai_cfg:
                        continue

                    provider = OpenAIRealtimeProvider(
                        openai_cfg,
                        self.on_provider_event,
                        gating_manager=self.audio_gating_manager
                    )
                    # Set session store for turn latency tracking (Milestone 21)
                    provider._session_store = self.session_store
                    self.providers[name] = provider
                    # Per-call factory (supports concurrent calls).
                    self.provider_factories[name] = (
                        lambda cfg=openai_cfg: OpenAIRealtimeProvider(self._clone_config(cfg), self.on_provider_event, gating_manager=self.audio_gating_manager)
                    )
                    logger.info(
                        "Provider 'openai_realtime' loaded successfully",
                        audio_gating_enabled=self.audio_gating_manager is not None
                    )

                    runtime_issues = self._describe_provider_alignment(name, provider)
                    if runtime_issues:
                        self.provider_alignment_issues.setdefault(name, []).extend(runtime_issues)
                elif name == "google_live":
                    # google_live uses GoogleProviderConfig like the pipeline adapters
                    try:
                        # SECURITY: API key ONLY from environment variables, never from YAML
                        merged = dict(provider_config_data)
                        merged['api_key'] = os.getenv('GOOGLE_API_KEY') or ''
                        google_cfg = GoogleProviderConfig(**merged)
                        # Note: Don't skip for missing API key - let is_ready() handle it
                        if not google_cfg.api_key:
                            logger.warning("Google Live provider API key missing (GOOGLE_API_KEY) - provider will show as Not Ready")
                    except Exception as e:
                        logger.error(f"Failed to build GoogleProviderConfig for google_live: {e}", exc_info=True)
                        continue

                    provider = GoogleLiveProvider(
                        google_cfg,
                        self.on_provider_event,
                        gating_manager=self.audio_gating_manager
                    )
                    # Set session store for turn latency tracking (Milestone 21)
                    provider._session_store = self.session_store
                    self.providers[name] = provider
                    # Per-call factory (supports concurrent calls).
                    self.provider_factories[name] = (
                        lambda cfg=google_cfg: GoogleLiveProvider(self._clone_config(cfg), self.on_provider_event, gating_manager=self.audio_gating_manager)
                    )
                    logger.info(
                        "Provider 'google_live' loaded successfully",
                        audio_gating_enabled=self.audio_gating_manager is not None
                    )

                    runtime_issues = self._describe_provider_alignment(name, provider)
                    if runtime_issues:
                        self.provider_alignment_issues.setdefault(name, []).extend(runtime_issues)
                elif name == "elevenlabs_agent":
                    elevenlabs_cfg = self._build_elevenlabs_config(provider_config_data)
                    if not elevenlabs_cfg:
                        continue

                    provider = ElevenLabsAgentProvider(
                        elevenlabs_cfg, 
                        self.on_provider_event,
                    )
                    # Set session store for turn latency tracking (Milestone 21)
                    provider._session_store = self.session_store
                    self.providers[name] = provider
                    # Per-call factory (supports concurrent calls).
                    self.provider_factories[name] = (
                        lambda cfg=elevenlabs_cfg: ElevenLabsAgentProvider(self._clone_config(cfg), self.on_provider_event)
                    )
                    logger.info(
                        "Provider 'elevenlabs_agent' loaded successfully"
                    )

                    runtime_issues = self._describe_provider_alignment(name, provider)
                    if runtime_issues:
                        self.provider_alignment_issues.setdefault(name, []).extend(runtime_issues)
                else:
                    logger.warning(f"Unknown provider type: {name}")
                    continue
                    
            except Exception as e:
                logger.error(f"Failed to load provider '{name}': {e}", exc_info=True)
        
        # Validate that default provider is available
        available_providers = list(self.providers.keys())
        default_target = getattr(self.config, "default_provider", None)
        pipelines_cfg = getattr(self.config, "pipelines", None) or {}
        available_pipelines = list(pipelines_cfg.keys()) if isinstance(pipelines_cfg, dict) else []

        if default_target in available_providers:
            logger.info(f"Default provider '{default_target}' is available and ready.")
        elif default_target in available_pipelines:
            # Note: default_provider may point at a pipeline name for pipeline-first deployments.
            # Startup should not error in that case; the orchestrator will initialize shortly after startup.
            logger.info(
                "Default pipeline is configured",
                default_pipeline=default_target,
            )
        else:
            logger.error(
                f"Default provider '{default_target}' not loaded. "
                f"Check provider configuration and API keys. Available providers: {available_providers}. "
                f"Available pipelines: {available_pipelines}"
            )
            
            # Validate provider connectivity (full agent mode)
            for provider_name, provider in self.providers.items():
                # Check basic readiness - providers must have is_ready() and return True
                try:
                    if hasattr(provider, 'is_ready'):
                        ready = provider.is_ready()
                        if not ready:
                            logger.warning(
                                "âš ï¸ Provider NOT ready - missing API key or config",
                                provider=provider_name,
                                hint="Check that API key is set in ai-agent.yaml or .env"
                            )
                        else:
                            logger.info(
                                "âœ… Provider validated and ready",
                                provider=provider_name,
                                type=provider.__class__.__name__
                            )
                    else:
                        logger.warning(
                            "âš ï¸ Provider missing is_ready() method",
                            provider=provider_name,
                            type=provider.__class__.__name__
                        )
                except Exception as exc:
                    logger.error(
                        "âŒ Provider readiness check failed",
                        provider=provider_name,
                        error=str(exc),
                        exc_info=True
                    )
            
            # Check codec/sample alignment
            for provider_name in self.providers:
                issues = self.provider_alignment_issues.get(provider_name, [])
                for detail in dict.fromkeys(issues):
                    logger.warning(
                        "Provider codec/sample alignment issue",
                        provider=provider_name,
                        detail=detail,
                    )
                if not issues:
                    logger.info(
                        "Provider codec/sample alignment verified",
                        provider=provider_name,
                    )

    def _is_caller_channel(self, channel: dict) -> bool:
        """Check if this is a caller channel (SIP, PJSIP, etc.)"""
        channel_name = channel.get('name', '')
        return any(channel_name.startswith(prefix) for prefix in ['SIP/', 'PJSIP/', 'DAHDI/', 'IAX2/'])

    def _is_local_channel(self, channel: dict) -> bool:
        """Check if this is a Local channel"""
        channel_name = channel.get('name', '')
        return channel_name.startswith('Local/')

    def _is_audiosocket_channel(self, channel: dict) -> bool:
        """Check if this is an AudioSocket channel (native channel interface)."""
        channel_name = channel.get('name', '')
        return channel_name.startswith('AudioSocket/')

    def _is_external_media_channel(self, channel: dict) -> bool:
        """Check if this is an ExternalMedia channel"""
        channel_name = channel.get('name', '')
        return channel_name.startswith('UnicastRTP/')

    async def _find_caller_for_local(self, local_channel_id: str) -> Optional[str]:
        """Find the caller channel that corresponds to this Local channel."""
        # Check if we have a pending Local channel mapping
        if local_channel_id in self.pending_local_channels:
            return self.pending_local_channels[local_channel_id]
        
        # Fallback: search through SessionStore
        sessions = await self.session_store.get_all_sessions()
        for session in sessions:
            if session.local_channel_id == local_channel_id:
                return session.caller_channel_id
        
        return None

    async def _handle_stasis_start(self, event: dict):
        """Handle StasisStart events - Hybrid ARI approach with single handler."""
        logger.info("ðŸŽ¯ HYBRID ARI - StasisStart event received", event_data=event)
        channel = event.get('channel', {})
        channel_id = channel.get('id')
        channel_name = channel.get('name', '')
        args = event.get('args', [])
        
        logger.info("ðŸŽ¯ HYBRID ARI - Channel analysis", 
                   channel_id=channel_id,
                   channel_name=channel_name,
                   args=args,
                   is_caller=self._is_caller_channel(channel),
                   is_local=self._is_local_channel(channel))
        
        # Check if this is an agent action (transfer, voicemail, queue, etc.)
        if args and len(args) > 0:
            action_type = args[0]
            logger.info(f"ðŸ”€ AGENT ACTION - Stasis entry with action: {action_type}",
                       channel_id=channel_id,
                       action_type=action_type,
                       args=args)
            await self._handle_agent_action_stasis(channel_id, channel, args)
            return
        
        if self._is_caller_channel(channel):
            # This is the caller channel entering Stasis - MAIN FLOW
            logger.info("ðŸŽ¯ HYBRID ARI - Processing caller channel", channel_id=channel_id)
            await self._handle_caller_stasis_start_hybrid(channel_id, channel)
        elif self._is_local_channel(channel):
            # Local channels are normally used as a helper leg (e.g. transfers) and must
            # be mapped back to a real caller channel. However, for automated smoke tests
            # (and some controlled dialplan flows), we intentionally originate a Local
            # channel directly into an AI-agent context. In that case we want to treat
            # the Local channel itself as the caller so we can inject audio via bridge
            # playback and validate end-to-end behavior without a human endpoint.
            dialplan_ctx = (channel.get("dialplan", {}) or {}).get("context", "") or ""
            local_caller_contexts = {
                "ava-test",
                "from-ai-agent-google",
                "from-ai-agent-deepgram",
                "from-ai-agent-openai",
                "from-ai-agent-local",
                "from-ai-agent-custom",
                "from-ai-agent-mcp",
                "from-ai-agent-elevlabs",
            }

            if dialplan_ctx in local_caller_contexts:
                # Local channels always have two halves (";1" and ";2"). For smoke calls we
                # want exactly one CallSession + one call history record. Treat the first
                # half we see as the caller and map the other half back to it.
                base_name = (channel_name.split(";", 1)[0] if ";" in channel_name else channel_name) or channel_name
                suffix = channel_name.rsplit(";", 1)[-1] if ";" in channel_name else ""

                if suffix == "1":
                    caller_id = self._smoke_local_base_to_caller.get(base_name)
                    if caller_id and caller_id != channel_id:
                        self.pending_local_channels[channel_id] = caller_id
                        logger.info(
                            "ðŸŽ¯ HYBRID ARI - Smoke Local helper leg mapped",
                            local_channel_id=channel_id,
                            caller_channel_id=caller_id,
                            base=base_name,
                            context=dialplan_ctx,
                        )
                        await self._handle_local_stasis_start_hybrid(channel_id, channel)
                        self._smoke_local_base_to_leg1.pop(base_name, None)
                        return

                    # Park leg1 until the dialplan/caller leg (;2) arrives.
                    self._smoke_local_base_to_leg1[base_name] = channel_id
                    logger.info(
                        "ðŸŽ¯ HYBRID ARI - Smoke Local leg1 parked (waiting for leg2)",
                        local_channel_id=channel_id,
                        base=base_name,
                        context=dialplan_ctx,
                    )
                    return

                # Caller leg (prefer ;2 / dialplan side)
                self._smoke_local_base_to_caller[base_name] = channel_id
                logger.info(
                    "ðŸŽ¯ HYBRID ARI - Treating Local channel as caller (smoke/dialplan test)",
                    channel_id=channel_id,
                    channel_name=channel_name,
                    context=dialplan_ctx,
                )
                await self._handle_caller_stasis_start_hybrid(channel_id, channel)

                # If leg1 was parked, join it now as the Local helper leg.
                leg1_id = self._smoke_local_base_to_leg1.pop(base_name, None)
                if leg1_id and leg1_id != channel_id:
                    try:
                        self.pending_local_channels[leg1_id] = channel_id
                        await self._handle_local_stasis_start_hybrid(
                            leg1_id,
                            {"id": leg1_id, "name": f"{base_name};1", "dialplan": {"context": dialplan_ctx}},
                        )
                    except Exception:
                        logger.debug(
                            "Smoke Local leg2 join failed",
                            caller_channel_id=channel_id,
                            local_channel_id=leg1_id,
                            context=dialplan_ctx,
                            exc_info=True,
                        )
                return

            # This is the Local channel entering Stasis - legacy path
            logger.info(
                "ðŸŽ¯ HYBRID ARI - Local channel entered Stasis",
                channel_id=channel_id,
                channel_name=channel_name,
            )
            # Now add the Local channel to the bridge
            await self._handle_local_stasis_start_hybrid(channel_id, channel)
        elif self._is_audiosocket_channel(channel):
            logger.info(
                "ðŸŽ¯ HYBRID ARI - AudioSocket channel entered Stasis",
                channel_id=channel_id,
                channel_name=channel_name,
            )
            await self._handle_audiosocket_channel_stasis_start(channel_id, channel)
        elif self._is_external_media_channel(channel):
            # This is an ExternalMedia channel entering Stasis
            logger.info("ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel entered Stasis", 
                       channel_id=channel_id,
                       channel_name=channel_name)
            await self._handle_external_media_stasis_start(channel_id, channel)
        else:
            logger.warning("ðŸŽ¯ HYBRID ARI - Unknown channel type in StasisStart", 
                          channel_id=channel_id, 
                          channel_name=channel_name)

    async def _start_external_media_channel(self, caller_channel_id: str) -> Optional[str]:
        """Allocate RTP resources and originate the ExternalMedia channel via ARI."""
        if not self.config.external_media:
            logger.error("ðŸŽ¯ EXTERNAL MEDIA - Configuration missing; cannot start ExternalMedia channel",
                         caller_channel_id=caller_channel_id)
            return None
        if not self.rtp_server:
            logger.error("ðŸŽ¯ EXTERNAL MEDIA - RTP server unavailable; cannot start ExternalMedia channel",
                         caller_channel_id=caller_channel_id)
            return None

        try:
            port = await self.rtp_server.allocate_session(caller_channel_id)
        except Exception as exc:
            logger.error("ðŸŽ¯ EXTERNAL MEDIA - RTP session allocation failed",
                         caller_channel_id=caller_channel_id,
                         error=str(exc),
                         exc_info=True)
            return None

        host = self.config.external_media.rtp_host
        codec = getattr(self.config.external_media, "codec", "ulaw")
        direction = getattr(self.config.external_media, "direction", "both")
        external_host = f"{host}:{port}"

        try:
            response = await self.ari_client.create_external_media_channel(
                app=self.config.asterisk.app_name,
                external_host=external_host,
                format=codec,
                direction=direction,
                encapsulation="rtp",
            )
        except Exception as exc:
            logger.error("ðŸŽ¯ EXTERNAL MEDIA - ARI create_external_media_channel failed",
                         caller_channel_id=caller_channel_id,
                         external_host=external_host,
                         error=str(exc),
                         exc_info=True)
            await self.rtp_server.cleanup_session(caller_channel_id)
            try:
                session = await self.session_store.get_by_call_id(caller_channel_id)
                if session:
                    session.external_media_port = None
                    session.pending_external_media_id = None
                    await self._save_session(session)
            except Exception:
                logger.debug("Failed to reset session after ARI external media failure",
                             caller_channel_id=caller_channel_id,
                             exc_info=True)
            return None

        channel_id = response.get("id") if isinstance(response, dict) else None
        if not channel_id:
            logger.error("ðŸŽ¯ EXTERNAL MEDIA - ARI create_external_media_channel returned no channel id",
                         caller_channel_id=caller_channel_id,
                         response=response)
            await self.rtp_server.cleanup_session(caller_channel_id)
            try:
                session = await self.session_store.get_by_call_id(caller_channel_id)
                if session:
                    session.external_media_port = None
                    session.pending_external_media_id = None
                    await self._save_session(session)
            except Exception:
                logger.debug("Failed to reset session after missing ExternalMedia channel id",
                             caller_channel_id=caller_channel_id,
                             exc_info=True)
            return None

        session = await self.session_store.get_by_call_id(caller_channel_id)
        if session:
            session.pending_external_media_id = channel_id
            session.external_media_port = port
            session.external_media_codec = codec  # Store codec for RTP byte-swap logic
            await self._save_session(session)

        logger.info("ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel originated",
                    caller_channel_id=caller_channel_id,
                    external_media_id=channel_id,
                    rtp_host=host,
                    rtp_port=port,
                    codec=codec,
                    direction=direction)
        return channel_id

    async def _handle_external_media_stasis_start(self, external_media_id: str, channel: dict):
        """Handle ExternalMedia channel entering Stasis."""
        try:
            # Find session by external_media_id
            session = await self.session_store.get_by_channel_id(external_media_id)
            if not session:
                # Fallback: search all sessions for external_media_id
                sessions = await self.session_store.get_all_sessions()
                for s in sessions:
                    if s.external_media_id == external_media_id or s.pending_external_media_id == external_media_id:
                        session = s
                        break
            
            if not session:
                logger.warning(
                    "ExternalMedia channel entered Stasis but no caller found (will retry attach)",
                    external_media_id=external_media_id,
                )
                asyncio.create_task(self._retry_attach_external_media_channel(external_media_id))
                return
            
            caller_channel_id = session.caller_channel_id
            
            # Add ExternalMedia channel to the bridge
            bridge_id = session.bridge_id
            if bridge_id:
                success = await self.ari_client.add_channel_to_bridge(bridge_id, external_media_id)
                if success:
                    session.external_media_id = external_media_id
                    session.pending_external_media_id = None
                    await self._save_session(session)
                    logger.info("ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel added to bridge", 
                               external_media_id=external_media_id,
                               bridge_id=bridge_id,
                               caller_channel_id=caller_channel_id)
                    
                    # Start the provider session now that media path is connected
                    if not session.provider_session_active:
                        await self._ensure_provider_session_started(caller_channel_id)
                else:
                    logger.error("ðŸŽ¯ EXTERNAL MEDIA - Failed to add ExternalMedia channel to bridge", 
                               external_media_id=external_media_id,
                               bridge_id=bridge_id)
            else:
                logger.error("ExternalMedia channel entered Stasis but no bridge found", 
                           external_media_id=external_media_id,
                           caller_channel_id=caller_channel_id)
                
        except Exception as e:
            logger.error("Error handling ExternalMedia StasisStart", 
                        external_media_id=external_media_id, 
                        error=str(e), 
                        exc_info=True)

    async def _retry_attach_external_media_channel(
        self,
        external_media_id: str,
        *,
        attempts: int = 25,
        delay_seconds: float = 0.1,
    ) -> None:
        """
        Best-effort retry for attaching an ExternalMedia channel to its call bridge.

        Mitigates an ARI event-order race where the ExternalMedia channel's StasisStart
        can arrive before the call session has been updated with external_media_id.
        """
        for attempt in range(1, max(1, attempts) + 1):
            try:
                session = await self.session_store.get_by_channel_id(external_media_id)
                if not session:
                    sessions = await self.session_store.get_all_sessions()
                    for s in sessions:
                        if s.external_media_id == external_media_id or s.pending_external_media_id == external_media_id:
                            session = s
                            break

                if session and session.bridge_id:
                    success = await self.ari_client.add_channel_to_bridge(session.bridge_id, external_media_id)
                    if success:
                        session.external_media_id = external_media_id
                        session.pending_external_media_id = None
                        await self._save_session(session)
                        logger.info(
                            "ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel attached after retry",
                            external_media_id=external_media_id,
                            bridge_id=session.bridge_id,
                            caller_channel_id=session.caller_channel_id,
                            attempt=attempt,
                        )
                        if not session.provider_session_active:
                            await self._ensure_provider_session_started(session.caller_channel_id)
                        return
            except Exception:
                logger.debug(
                    "ExternalMedia attach retry failed",
                    external_media_id=external_media_id,
                    attempt=attempt,
                    exc_info=True,
                )
            await asyncio.sleep(delay_seconds)

        logger.error(
            "ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia attach retry exhausted",
            external_media_id=external_media_id,
            attempts=attempts,
        )

    async def _handle_caller_stasis_start_hybrid(self, caller_channel_id: str, channel: dict):
        """Handle caller channel entering Stasis - Hybrid ARI approach."""
        caller_info = channel.get('caller', {})
        logger.info("ðŸŽ¯ HYBRID ARI - Caller channel entered Stasis", 
                    channel_id=caller_channel_id,
                    caller_name=caller_info.get('name'),
                    caller_number=caller_info.get('number'))
        
        # Check if call is already in progress
        existing_session = await self.session_store.get_by_call_id(caller_channel_id)
        if existing_session:
            logger.warning("ðŸŽ¯ HYBRID ARI - Caller already in progress", channel_id=caller_channel_id)
            return
        
        try:
            # Answer the caller
            logger.info("ðŸŽ¯ HYBRID ARI - Step 1: Answering caller channel", channel_id=caller_channel_id)
            await self.ari_client.answer_channel(caller_channel_id)
            logger.info("ðŸŽ¯ HYBRID ARI - Step 1: âœ… Caller channel answered", channel_id=caller_channel_id)
            
            # Create bridge immediately (use default bridge_type to prevent simple_bridge optimization)
            logger.info("ðŸŽ¯ HYBRID ARI - Step 2: Creating bridge immediately", channel_id=caller_channel_id)
            bridge_id = await self.ari_client.create_bridge()  # Uses default: mixing,dtmf_events,proxy_media
            if not bridge_id:
                raise RuntimeError("Failed to create mixing bridge")
            logger.info("ðŸŽ¯ HYBRID ARI - Step 2: âœ… Bridge created", 
                       channel_id=caller_channel_id, 
                       bridge_id=bridge_id)
            
            # Add caller to bridge
            logger.info("ðŸŽ¯ HYBRID ARI - Step 3: Adding caller to bridge", 
                       channel_id=caller_channel_id, 
                       bridge_id=bridge_id)
            caller_success = await self.ari_client.add_channel_to_bridge(bridge_id, caller_channel_id)
            if not caller_success:
                raise RuntimeError("Failed to add caller channel to bridge")
            logger.info("ðŸŽ¯ HYBRID ARI - Step 3: âœ… Caller added to bridge", 
                       channel_id=caller_channel_id, 
                       bridge_id=bridge_id)
            self.bridges[caller_channel_id] = bridge_id
            
            # Create CallSession and store in SessionStore
            session = CallSession(
                call_id=caller_channel_id,
                caller_channel_id=caller_channel_id,
                caller_name=caller_info.get('name'),
                caller_number=caller_info.get('number'),
                bridge_id=bridge_id,
                provider_name=self.config.default_provider,
                audio_capture_enabled=True,  # FIX #1: Start with capture enabled, only disable when TTS actually starts
                status="connected",
                start_time=datetime.now(timezone.utc)  # Track call start time (UTC for consistent storage)
            )
            session.enhanced_vad_enabled = bool(self.vad_manager)
            await self._save_session(session, new=True)
            
            # Record call start time for duration tracking
            import time
            _call_start_times[caller_channel_id] = time.time()
            logger.debug("Recorded call start time", call_id=caller_channel_id)
            
            # Export config metrics for this call
            try:
                await self._export_config_metrics(caller_channel_id)
            except Exception:
                logger.debug("Failed to export config metrics for call", call_id=caller_channel_id, exc_info=True)
            logger.info("ðŸŽ¯ HYBRID ARI - Step 4: âœ… Caller session created and stored",
                       channel_id=caller_channel_id,
                       bridge_id=bridge_id)

            # Resolve transport profile from dialplan hints/config defaults
            try:
                await self._hydrate_transport_from_dialplan(session, caller_channel_id)
            except Exception:
                logger.debug("Transport profile hydration failed", call_id=caller_channel_id, exc_info=True)

            # Detect caller codec/sample-rate so downstream playback matches the trunk.
            try:
                await self._detect_caller_codec(session, caller_channel_id)
            except Exception:
                logger.debug("Caller codec detection failed", call_id=caller_channel_id, exc_info=True)

            # P1: Resolve Audio Profile (profiles.* + contexts.* + channel var overrides)
            try:
                await self._resolve_audio_profile(session, caller_channel_id)
            except Exception:
                logger.debug("Audio profile resolution failed", call_id=caller_channel_id, exc_info=True)

            # Per-call override via Asterisk channel var AI_PROVIDER.
            # Values:
            #   - openai_realtime | deepgram â†’ full agent override
            #   - customX (any other token) â†’ pipeline name
            ai_provider_value = None
            try:
                resp = await self.ari_client.send_command(
                    "GET",
                    f"channels/{caller_channel_id}/variable",
                    params={"variable": "AI_PROVIDER"},
                )
                if isinstance(resp, dict):
                    ai_provider_value = (resp.get("value") or "").strip()
            except Exception:
                logger.debug(
                    "AI_PROVIDER read failed; continuing with defaults",
                    channel_id=caller_channel_id,
                    exc_info=True,
                )

            provider_aliases = {
                "openai": "openai_realtime",
                "deepgram_agent": "deepgram",
                "google": "google_live",
            }
            resolved_provider = (
                provider_aliases.get(ai_provider_value, ai_provider_value)
                if ai_provider_value
                else None
            )

            pipeline_resolution = None
            if resolved_provider and resolved_provider in self.providers:
                # Full agent override for this call
                previous = session.provider_name
                session.provider_name = resolved_provider
                await self._save_session(session)
                logger.info(
                    "AI provider override applied from channel variable",
                    channel_id=caller_channel_id,
                    variable="AI_PROVIDER",
                    value=ai_provider_value,
                    resolved_provider=resolved_provider,
                    previous_provider=previous,
                    resolved_mode="full_agent",
                )
            elif ai_provider_value:
                # Treat as a pipeline name for this call
                pipeline_resolution = await self._assign_pipeline_to_session(
                    session, pipeline_name=ai_provider_value
                )
                if pipeline_resolution:
                    logger.info(
                        "AI pipeline selection applied from channel variable",
                        channel_id=caller_channel_id,
                        variable="AI_PROVIDER",
                        value=ai_provider_value,
                        pipeline=pipeline_resolution.pipeline_name,
                        components=pipeline_resolution.component_summary(),
                        resolved_mode="pipeline",
                    )
                    # Opt-in to adapter-driven pipeline execution for this call
                    try:
                        await self._ensure_pipeline_runner(session, forced=True)
                    except Exception:
                        logger.debug("Failed to start pipeline runner", call_id=caller_channel_id, exc_info=True)
                elif getattr(self.pipeline_orchestrator, "started", False):
                    logger.warning(
                        "Requested pipeline via AI_PROVIDER not found; falling back",
                        channel_id=caller_channel_id,
                        requested_pipeline=ai_provider_value,
                    )
                    pipeline_resolution = await self._assign_pipeline_to_session(session)
            else:
                # Default behavior: check context pipeline first, then provider
                # If context specifies a pipeline, use modular pipeline even if provider is set
                context_pipeline = None
                if session.context_name:
                    ctx_config = self.transport_orchestrator.get_context_config(session.context_name)
                    if ctx_config and getattr(ctx_config, 'pipeline', None):
                        context_pipeline = ctx_config.pipeline
                        logger.info(
                            "Context specifies pipeline - using modular pipeline",
                            call_id=caller_channel_id,
                            context=session.context_name,
                            pipeline=context_pipeline,
                        )
                
                if context_pipeline:
                    # Use the pipeline specified by context
                    pipeline_resolution = await self._assign_pipeline_to_session(
                        session, pipeline_name=context_pipeline
                    )
                    if pipeline_resolution:
                        try:
                            await self._ensure_pipeline_runner(session, forced=True)
                        except Exception:
                            logger.debug("Failed to start pipeline runner", call_id=caller_channel_id, exc_info=True)
                elif session.provider_name and session.provider_name in self.providers:
                    # Skip pipeline resolution if context already set a monolithic provider
                    logger.info(
                        "Skipping pipeline resolution - context already set valid provider",
                        call_id=caller_channel_id,
                        provider=session.provider_name,
                        source="context",
                    )
                else:
                    pipeline_resolution = await self._assign_pipeline_to_session(session)
                    if not pipeline_resolution and getattr(self.pipeline_orchestrator, "started", False):
                        logger.info(
                            "Pipeline orchestrator using direct provider mode",
                            call_id=caller_channel_id,
                            provider=session.provider_name,
                        )
            
            # Step 5: Create ExternalMedia channel or originate Local channel
            if self.config.audio_transport == "externalmedia":
                logger.info("ðŸŽ¯ EXTERNAL MEDIA - Step 5: Creating ExternalMedia channel", channel_id=caller_channel_id)
                external_media_id = await self._start_external_media_channel(caller_channel_id)
                if external_media_id:
                    # Update session with ExternalMedia ID
                    session.external_media_id = external_media_id
                    session.status = "external_media_created"
                    await self._save_session(session)
                    logger.info("ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel created, session updated", 
                               channel_id=caller_channel_id, 
                               external_media_id=external_media_id)

                    # Attach immediately to avoid reliance on ExternalMedia StasisStart ordering.
                    if session.bridge_id:
                        attached = False
                        for attempt in range(1, 26):
                            added = await self.ari_client.add_channel_to_bridge(session.bridge_id, external_media_id)
                            if added:
                                attached = True
                                session.pending_external_media_id = None
                                await self._save_session(session)
                                logger.info(
                                    "ðŸŽ¯ EXTERNAL MEDIA - ExternalMedia channel added to bridge (direct attach)",
                                    external_media_id=external_media_id,
                                    bridge_id=session.bridge_id,
                                    caller_channel_id=caller_channel_id,
                                    attempt=attempt,
                                )
                                break
                            await asyncio.sleep(0.1)

                        if attached and not session.provider_session_active:
                            await self._ensure_provider_session_started(caller_channel_id)
                        elif not attached:
                            logger.error(
                                "ðŸŽ¯ EXTERNAL MEDIA - Failed to add ExternalMedia channel to bridge (direct attach)",
                                external_media_id=external_media_id,
                                bridge_id=session.bridge_id,
                                caller_channel_id=caller_channel_id,
                            )
                else:
                    logger.error("ðŸŽ¯ EXTERNAL MEDIA - Failed to create ExternalMedia channel", channel_id=caller_channel_id)
            else:
                logger.info("ðŸŽ¯ HYBRID ARI - Step 5: Originating AudioSocket channel", channel_id=caller_channel_id)
                await self._originate_audiosocket_channel_hybrid(caller_channel_id)
            
        except Exception as e:
            logger.error("ðŸŽ¯ HYBRID ARI - Failed to handle caller StasisStart", 
                        caller_channel_id=caller_channel_id, 
                        error=str(e), exc_info=True)
            await self._cleanup_call(caller_channel_id)

    async def _handle_local_stasis_start_hybrid(self, local_channel_id: str, channel: dict):
        """Handle Local channel entering Stasis - Hybrid ARI approach."""
        logger.info("ðŸŽ¯ HYBRID ARI - Processing Local channel StasisStart", 
                   local_channel_id=local_channel_id)
        
        # Find the caller channel that this Local channel belongs to
        caller_channel_id = await self._find_caller_for_local(local_channel_id)
        if not caller_channel_id:
            logger.error("ðŸŽ¯ HYBRID ARI - No caller found for Local channel", 
                        local_channel_id=local_channel_id)
            await self.ari_client.hangup_channel(local_channel_id)
            return
        
        # Check if caller channel exists and has a bridge
        session = await self.session_store.get_by_call_id(caller_channel_id)
        if not session:
            logger.error("ðŸŽ¯ HYBRID ARI - Caller channel not found for Local channel", 
                        local_channel_id=local_channel_id,
                        caller_channel_id=caller_channel_id)
            await self.ari_client.hangup_channel(local_channel_id)
            return
        
        bridge_id = session.bridge_id
        
        try:
            # Add Local channel to bridge
            logger.info("ðŸŽ¯ HYBRID ARI - Adding Local channel to bridge", 
                       local_channel_id=local_channel_id,
                       bridge_id=bridge_id)
            local_success = await self.ari_client.add_channel_to_bridge(bridge_id, local_channel_id)
            if local_success:
                logger.info("ðŸŽ¯ HYBRID ARI - âœ… Local channel added to bridge", 
                           local_channel_id=local_channel_id,
                           bridge_id=bridge_id)
                # Update session with Local channel info
                session.local_channel_id = local_channel_id
                session.status = "connected"
                await self._save_session(session)
                self.local_channels[caller_channel_id] = local_channel_id
                
                
                # Start provider session now that media path is connected
                await self._ensure_provider_session_started(caller_channel_id)
            else:
                logger.error("ðŸŽ¯ HYBRID ARI - Failed to add Local channel to bridge", 
                           local_channel_id=local_channel_id,
                           bridge_id=bridge_id)
                await self.ari_client.hangup_channel(local_channel_id)
        except Exception as e:
            logger.error("ðŸŽ¯ HYBRID ARI - Failed to handle Local channel StasisStart", 
                        local_channel_id=local_channel_id,
                        error=str(e), exc_info=True)
            await self.ari_client.hangup_channel(local_channel_id)

    async def _handle_audiosocket_channel_stasis_start(self, audiosocket_channel_id: str, channel: dict):
        """Handle AudioSocket channel entering Stasis when using channel interface."""
        logger.info(
            "ðŸŽ¯ HYBRID ARI - Processing AudioSocket channel StasisStart",
            audiosocket_channel_id=audiosocket_channel_id,
            channel_name=channel.get('name'),
        )

        caller_channel_id = self.pending_audiosocket_channels.pop(audiosocket_channel_id, None)
        if not caller_channel_id:
            # Fallback 1: try to parse the AudioSocket UUID from the channel name and map via uuidext_to_channel
            name = channel.get('name', '') or ''
            parsed_uuid = None
            try:
                # Expected form: "AudioSocket/host:port-<uuid>"; take substring after last '-'
                if name.startswith('AudioSocket/') and '-' in name:
                    candidate = name.rsplit('-', 1)[-1]
                    # Basic UUID sanity (contains 4 dashes)
                    if candidate.count('-') == 4:
                        parsed_uuid = candidate
            except Exception:
                parsed_uuid = None

            if parsed_uuid and parsed_uuid in self.uuidext_to_channel:
                caller_channel_id = self.uuidext_to_channel.get(parsed_uuid)
            
            # Fallback 2: brief retry loop to allow originate path to record mappings
            if not caller_channel_id:
                for attempt in range(5):
                    await asyncio.sleep(0.05)
                    # Recheck pending mapping
                    caller_channel_id = self.pending_audiosocket_channels.pop(audiosocket_channel_id, None)
                    if caller_channel_id:
                        break
                    # Recheck uuid mapping if we parsed one
                    if parsed_uuid and parsed_uuid in self.uuidext_to_channel:
                        caller_channel_id = self.uuidext_to_channel.get(parsed_uuid)
                        if caller_channel_id:
                            break
            
            # Fallback 3: scan sessions as a last resort
            if not caller_channel_id:
                sessions = await self.session_store.get_all_sessions()
                for s in sessions:
                    if getattr(s, 'audiosocket_channel_id', None) == audiosocket_channel_id:
                        caller_channel_id = s.caller_channel_id
                        break

        if not caller_channel_id:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - No caller found for AudioSocket channel",
                audiosocket_channel_id=audiosocket_channel_id,
                channel_name=channel.get('name'),
            )
            await self.ari_client.hangup_channel(audiosocket_channel_id)
            return

        session = await self.session_store.get_by_call_id(caller_channel_id)
        if not session:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - Session missing for AudioSocket channel",
                audiosocket_channel_id=audiosocket_channel_id,
                caller_channel_id=caller_channel_id,
            )
            await self.ari_client.hangup_channel(audiosocket_channel_id)
            return

        bridge_id = session.bridge_id
        if not bridge_id:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - No bridge available for AudioSocket channel",
                audiosocket_channel_id=audiosocket_channel_id,
                caller_channel_id=caller_channel_id,
            )
            await self.ari_client.hangup_channel(audiosocket_channel_id)
            return

        try:
            added = await self.ari_client.add_channel_to_bridge(bridge_id, audiosocket_channel_id)
            if not added:
                raise RuntimeError("Failed to add AudioSocket channel to bridge")

            logger.info(
                "ðŸŽ¯ HYBRID ARI - âœ… AudioSocket channel added to bridge",
                audiosocket_channel_id=audiosocket_channel_id,
                bridge_id=bridge_id,
                caller_channel_id=caller_channel_id,
            )

            session.audiosocket_channel_id = audiosocket_channel_id
            session.status = "audiosocket_channel_connected"
            await self._save_session(session)

            self.audiosocket_channels[caller_channel_id] = audiosocket_channel_id
            self.bridges[audiosocket_channel_id] = bridge_id

            if not session.provider_session_active:
                await self._ensure_provider_session_started(caller_channel_id)

            # Start ARI channel recording on the AudioSocket channel (only when diagnostics enabled)
            # Check if diagnostic taps are enabled
            diag_enabled = False
            try:
                diag_enabled = bool(getattr(self.config.streaming, 'diag_enable_taps', False)) if hasattr(self.config, 'streaming') else False
            except Exception:
                pass
            
            if diag_enabled:
                try:
                    ts = time.strftime("%Y%m%d-%H%M%S")
                    rec_name = f"out-{caller_channel_id}-{ts}"
                    ok = await self.ari_client.record_channel(
                        audiosocket_channel_id,
                        name=rec_name,
                        format="wav",
                        if_exists="overwrite",
                        max_duration_seconds=360,
                        max_silence_seconds=0,
                        beep=False,
                        terminate_on="none",
                    )
                    if ok:
                        logger.info(
                            "ðŸ“¼ ARI channel recording started on AudioSocket channel",
                            audiosocket_channel_id=audiosocket_channel_id,
                            name=rec_name,
                        )
                    else:
                        logger.debug(
                            "ARI channel recording failed to start (diagnostic recording)",
                            audiosocket_channel_id=audiosocket_channel_id,
                            name=rec_name,
                        )
                except Exception:
                    logger.debug("ARI channel recording start failed (diagnostic recording)", exc_info=True)
            else:
                logger.debug(
                    "ARI channel recording skipped (diag_enable_taps not enabled)",
                    audiosocket_channel_id=audiosocket_channel_id,
                )
        except Exception as exc:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - Failed to process AudioSocket channel",
                audiosocket_channel_id=audiosocket_channel_id,
                caller_channel_id=caller_channel_id,
                error=str(exc),
                exc_info=True,
            )
            await self.ari_client.hangup_channel(audiosocket_channel_id)

    async def _handle_agent_action_stasis(self, channel_id: str, channel: dict, args: list):
        """
        Handle agent action channels entering Stasis (direct SIP origination via ARI).
        
        Channels enter Stasis directly when originated by tool execution (e.g., transfer_call).
        NO dialplan context is used - channels are originated with app="asterisk-ai-voice-agent".
        
        Args:
            channel_id: Channel that entered Stasis
            channel: Channel dict
            args: Stasis args [action_type, caller_id, target, ...]
        """
        if len(args) < 2:
            logger.error("ðŸ”€ AGENT ACTION - Insufficient args", 
                        channel_id=channel_id, args=args)
            await self.ari_client.hangup_channel(channel_id)
            return
        
        action_type = args[0]
        caller_id = args[1]
        
        logger.info("ðŸ”€ AGENT ACTION - Processing action",
                   action_type=action_type,
                   caller_id=caller_id,
                   channel_id=channel_id)
        
        # Route to specific handler based on action type
        handlers = {
            'transfer': self._handle_transfer_answered,
            'warm-transfer': self._handle_transfer_answered,  # Warm transfer uses same handler
            'transfer-failed': self._handle_transfer_failed,
            'voicemail-complete': self._handle_voicemail_complete,
            'queue-answered': self._handle_queue_answered,
            'queue-failed': self._handle_queue_failed,
            'bgm': self._handle_background_music_channel,  # Background music snoop channel (AAVA-89)
        }
        
        handler = handlers.get(action_type)
        if handler:
            await handler(channel_id, args)
        else:
            logger.warning(f"ðŸ”€ AGENT ACTION - Unknown action type: {action_type}",
                          channel_id=channel_id, args=args)
            await self.ari_client.hangup_channel(channel_id)
    
    async def _handle_background_music_channel(self, channel_id: str, args: list):
        """
        Handle background music snoop channel entering Stasis.
        
        The snoop channel is created by _start_background_music() and enters Stasis
        automatically. We just need to keep it alive - MOH is already started.
        The channel will be cleaned up when the call ends.
        """
        call_id = args[1] if len(args) > 1 else "unknown"
        logger.info("ðŸŽµ Background music channel entered Stasis - keeping alive",
                   channel_id=channel_id,
                   call_id=call_id)
        # Don't hang up - let MOH play. Channel cleanup happens in _stop_background_music()
    
    async def _handle_transfer_answered(self, channel_id: str, args: list):
        """
        Handle successful transfer (target answered).
        Args: ['warm-transfer', caller_id, target_extension]
        
        With direct SIP origination:
        - SIP channel (e.g., SIP/6000) enters Stasis directly on answer
        - We remove AI (UnicastRTP), stop provider, then bridge SIP to caller
        - Creates direct audio path: Caller â†” SIP/Agent
        """
        action_type = args[0]
        caller_id = args[1]
        target = args[2] if len(args) > 2 else 'unknown'
        
        logger.info("ðŸ”€ TRANSFER ANSWERED - Direct SIP channel",
                   action_type=action_type,
                   channel_id=channel_id,
                   caller_id=caller_id,
                   target=target)
        
        # Find session
        session = await self.session_store.get_by_call_id(caller_id)
        if not session:
            logger.error("ðŸ”€ TRANSFER - Session not found",
                        caller_id=caller_id)
            await self.ari_client.hangup_channel(channel_id)
            return
        
        # Step 1: Remove AI audio channel from bridge (ExternalMedia OR AudioSocket)
        if session.external_media_id:
            try:
                await self.ari_client.remove_channel_from_bridge(
                    session.bridge_id,
                    session.external_media_id
                )
                logger.info("âœ… UnicastRTP removed from bridge",
                           external_media_id=session.external_media_id)
            except Exception as e:
                logger.warning(f"Failed to remove UnicastRTP: {e}")
        
        if session.audiosocket_channel_id:
            try:
                await self.ari_client.remove_channel_from_bridge(
                    session.bridge_id,
                    session.audiosocket_channel_id
                )
                logger.info("âœ… AudioSocket channel removed from bridge",
                           audiosocket_channel_id=session.audiosocket_channel_id)
            except Exception as e:
                logger.warning(f"Failed to remove AudioSocket channel: {e}")
        
        # Step 2: Stop AI provider session (per-call instance)
        try:
            start_task = self._provider_start_tasks.pop(session.call_id, None)
            if start_task:
                start_task.cancel()
        except Exception:
            pass
        provider = self._call_providers.pop(session.call_id, None)
        if provider:
            try:
                # Stop the provider's session for this call
                if hasattr(provider, 'stop_session'):
                    await provider.stop_session()
                    logger.info("âœ… AI provider session stopped",
                               provider=session.provider_name)
            except Exception as e:
                logger.warning(f"Failed to stop provider: {e}")
        
        # Step 3: Bridge SIP channel directly to caller
        try:
            await self.ari_client.add_channel_to_bridge(
                session.bridge_id,
                channel_id  # This is SIP/6000 directly
            )
            logger.info("âœ… TRANSFER COMPLETE - Direct SIP channel bridged",
                       channel_id=channel_id,
                       bridge_id=session.bridge_id,
                       target=target)
            
            # Step 4: Update session state
            if session.current_action:
                session.current_action['answered'] = True
                session.current_action['channel_id'] = channel_id
            await self.session_store.upsert_call(session)
            
        except Exception as e:
            logger.error(f"ðŸ”€ TRANSFER - Failed to bridge: {e}",
                        channel_id=channel_id)
            await self.ari_client.hangup_channel(channel_id)
    
    async def _handle_transfer_failed(self, channel_id: str, args: list):
        """
        Handle failed transfer (target didn't answer).
        Args: ['transfer-failed', caller_id, target, dial_status]
        """
        caller_id = args[1]
        target = args[2] if len(args) > 2 else 'unknown'
        status = args[3] if len(args) > 3 else 'UNKNOWN'
        
        logger.info("ðŸ”€ TRANSFER FAILED",
                   channel_id=channel_id,
                   caller_id=caller_id,
                   target=target,
                   status=status)
        
        # Find session and stop MOH
        session = await self.session_store.get_by_call_id(caller_id)
        if session:
            try:
                await self.ari_client.send_command(
                    method="DELETE",
                    resource=f"channels/{session.caller_channel_id}/moh"
                )
            except:
                pass
            
            # Clear current action
            session.current_action = None
            await self.session_store.upsert_call(session)
        
        # Hangup the Local channel
        await self.ari_client.hangup_channel(channel_id)
    
    async def _handle_voicemail_complete(self, channel_id: str, args: list):
        """Handle voicemail completion."""
        caller_id = args[1]
        vmbox = args[2] if len(args) > 2 else 'unknown'
        
        logger.info("ðŸ“§ VOICEMAIL COMPLETE", vmbox=vmbox)
        await self.ari_client.hangup_channel(channel_id)
    
    async def _handle_queue_answered(self, channel_id: str, args: list):
        """Handle queue agent answered."""
        caller_id = args[1]
        queue_name = args[2] if len(args) > 2 else 'unknown'
        
        logger.info("ðŸ“ž QUEUE ANSWERED", queue=queue_name)
        
        # Similar to transfer_answered - bridge the channel
        session = await self.session_store.get_by_call_id(caller_id)
        if session:
            try:
                await self.ari_client.add_channel_to_bridge(
                    session.bridge_id,
                    channel_id
                )
                logger.info("âœ… QUEUE AGENT BRIDGED")
            except Exception as e:
                logger.error(f"Failed to bridge queue agent: {e}")
                await self.ari_client.hangup_channel(channel_id)
    
    async def _handle_queue_failed(self, channel_id: str, args: list):
        """Handle queue failure."""
        caller_id = args[1]
        logger.info("ðŸ“ž QUEUE FAILED")
        await self.ari_client.hangup_channel(channel_id)

    async def _originate_audiosocket_channel_hybrid(self, caller_channel_id: str):
        """Originate an AudioSocket channel using the native channel interface."""
        if not self.config.audiosocket:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - AudioSocket config missing, cannot originate channel",
                caller_channel_id=caller_channel_id,
            )
            raise RuntimeError("AudioSocket configuration missing")

        audio_uuid = str(uuid.uuid4())
        host = self.config.audiosocket.host or "127.0.0.1"
        # Only rewrite bind-all addresses if no explicit host was configured
        # This allows remote Asterisk deployments to specify the actual AI engine host
        if host in ("0.0.0.0", "::") and not self.config.audiosocket.host:
            host = "127.0.0.1"
        port = self.config.audiosocket.port
        # Match channel interface codec to YAML audiosocket.format
        codec = "slin"
        try:
            fmt = (getattr(self.config.audiosocket, 'format', '') or '').lower()
            if fmt in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                codec = "ulaw"
            elif fmt in ("slin16", "linear16", "pcm16"):
                codec = "slin16"
            else:
                # Treat any other/legacy value (e.g., 'slin') as 8 kHz PCM16
                codec = "slin"
        except Exception:
            codec = "slin"
        endpoint = f"AudioSocket/{host}:{port}/{audio_uuid}/c({codec})"

        orig_params = {
            "endpoint": endpoint,
            "app": self.config.asterisk.app_name,
            "timeout": "30",
            "channelVars": {
                "AUDIOSOCKET_UUID": audio_uuid,
            },
        }

        logger.info(
            "ðŸŽ¯ HYBRID ARI - Originating AudioSocket channel",
            caller_channel_id=caller_channel_id,
            endpoint=endpoint,
            audio_uuid=audio_uuid,
        )

        try:
            response = await self.ari_client.send_command("POST", "channels", params=orig_params)
            if response and response.get("id"):
                audiosocket_channel_id = response["id"]
                self.pending_audiosocket_channels[audiosocket_channel_id] = caller_channel_id
                self.uuidext_to_channel[audio_uuid] = caller_channel_id

                session = await self.session_store.get_by_call_id(caller_channel_id)
                if session:
                    session.audiosocket_uuid = audio_uuid
                    await self._save_session(session)
                    logger.info(
                        "ðŸŽ¯ HYBRID ARI - AudioSocket channel originated",
                        caller_channel_id=caller_channel_id,
                        audiosocket_channel_id=audiosocket_channel_id,
                    )
            else:
                raise RuntimeError("Failed to originate AudioSocket channel")
        except Exception as e:
            logger.error(
                "ðŸŽ¯ HYBRID ARI - AudioSocket channel originate failed",
                caller_channel_id=caller_channel_id,
                error=str(e),
                exc_info=True,
            )
            raise

    async def _handle_stasis_end(self, event: dict):
        """Handle StasisEnd event and clean up call resources."""
        try:
            channel = event.get("channel", {}) or {}
            channel_id = channel.get("id")
            if not channel_id:
                return
            logger.info("Stasis ended", channel_id=channel_id)
            await self._cleanup_call(channel_id)
        except Exception as exc:
            logger.error("Error handling StasisEnd", error=str(exc), exc_info=True)

    async def _handle_channel_destroyed(self, event: dict):
        """Clean up when a channel is destroyed."""
        try:
            channel = event.get("channel", {}) or {}
            channel_id = channel.get("id")
            if not channel_id:
                return
            logger.info("Channel destroyed", channel_id=channel_id)
            await self._cleanup_call(channel_id)
        except Exception as exc:
            logger.error("Error handling ChannelDestroyed", error=str(exc), exc_info=True)

    async def _handle_dtmf_received(self, event: dict):
        """Handle ChannelDtmfReceived events (informational logging for now)."""
        try:
            channel = event.get("channel", {}) or {}
            digit = event.get("digit")
            channel_id = channel.get("id")
            logger.info(
                "Channel DTMF received",
                channel_id=channel_id,
                digit=digit,
            )
        except Exception as exc:
            logger.error("Error handling ChannelDtmfReceived", error=str(exc), exc_info=True)

    async def _handle_channel_varset(self, event: dict):
        """Monitor ChannelVarset events for debugging configuration state."""
        try:
            channel = event.get("channel", {}) or {}
            variable = event.get("variable")
            value = event.get("value")
            channel_id = channel.get("id")
            logger.debug(
                "Channel variable set",
                channel_id=channel_id,
                variable=variable,
                value=value,
            )
        except Exception as exc:
            logger.error("Error handling ChannelVarset", error=str(exc), exc_info=True)

    async def _enable_pipeline_talk_detect(self, session: CallSession) -> None:
        """Enable Asterisk talk detection (TALK_DETECT) on the caller channel for pipelines."""
        try:
            cfg = getattr(self.config, "barge_in", None)
            if not cfg or not bool(getattr(cfg, "pipeline_talk_detect_enabled", False)):
                return
            call_id = session.call_id
            if not bool(self._pipeline_forced.get(call_id)):
                return
            channel_id = getattr(session, "caller_channel_id", None)
            if not channel_id:
                return
            if not getattr(session, "vad_state", None):
                session.vad_state = {}
            td = session.vad_state.setdefault("pipeline_talk_detect", {})
            if bool(td.get("enabled", False)):
                return
            silence_ms = int(getattr(cfg, "pipeline_talk_detect_silence_ms", 1200))
            talking_thr = int(getattr(cfg, "pipeline_talk_detect_talking_threshold", 128))
            value = f"{silence_ms},{talking_thr}"
            ok = await self.ari_client.set_channel_var(channel_id, "TALK_DETECT(set)", value)
            td.update(
                {
                    "enabled": bool(ok),
                    "channel_id": channel_id,
                    "set_ts": time.time(),
                    "silence_ms": silence_ms,
                    "talking_threshold": talking_thr,
                }
            )
            await self._save_session(session)
            if ok:
                logger.info(
                    "Enabled TALK_DETECT for pipeline",
                    call_id=call_id,
                    channel_id=channel_id,
                    silence_ms=silence_ms,
                    talking_threshold=talking_thr,
                )
            else:
                logger.warning("Failed to enable TALK_DETECT for pipeline", call_id=call_id, channel_id=channel_id)
        except Exception:
            logger.debug("Enable TALK_DETECT failed", call_id=getattr(session, "call_id", None), exc_info=True)

    async def _disable_pipeline_talk_detect(self, session: CallSession) -> None:
        """Disable Asterisk talk detection (TALK_DETECT) on the caller channel for pipelines."""
        try:
            cfg = getattr(self.config, "barge_in", None)
            if not cfg or not bool(getattr(cfg, "pipeline_talk_detect_enabled", False)):
                return
            call_id = session.call_id
            channel_id = getattr(session, "caller_channel_id", None)
            if not channel_id:
                return
            td_enabled = False
            if getattr(session, "vad_state", None):
                td = session.vad_state.get("pipeline_talk_detect", {}) or {}
                td_enabled = bool(td.get("enabled", False))
            if not td_enabled:
                return
            await self.ari_client.set_channel_var(channel_id, "TALK_DETECT(remove)", "")
            try:
                td = session.vad_state.get("pipeline_talk_detect", {}) or {}
                td["enabled"] = False
                td["remove_ts"] = time.time()
                session.vad_state["pipeline_talk_detect"] = td
                await self._save_session(session)
            except Exception:
                pass
            logger.info("Disabled TALK_DETECT for pipeline", call_id=call_id, channel_id=channel_id)
        except Exception:
            logger.debug("Disable TALK_DETECT failed", call_id=getattr(session, "call_id", None), exc_info=True)

    async def _handle_channel_talking_started(self, event: dict) -> None:
        """Trigger pipeline barge-in when Asterisk detects caller speech during TTS playback."""
        try:
            channel = event.get("channel", {}) or {}
            channel_id = channel.get("id")
            if not channel_id:
                return

            session = await self.session_store.get_by_channel_id(channel_id)
            if not session:
                return
            call_id = session.call_id

            if not bool(self._pipeline_forced.get(call_id)):
                return

            # Only act when local playback/gating is active; otherwise this is just "caller is talking".
            if bool(getattr(session, "audio_capture_enabled", True)) and not bool(getattr(session, "tts_playing", False)):
                return

            cfg = getattr(self.config, "barge_in", None)
            if not cfg or not getattr(cfg, "enabled", True):
                return

            now = time.time()
            tts_elapsed_ms = 0
            try:
                if getattr(session, "tts_started_ts", 0.0) > 0:
                    tts_elapsed_ms = int((now - float(session.tts_started_ts)) * 1000)
            except Exception:
                tts_elapsed_ms = 0

            initial_protect = int(getattr(cfg, "initial_protection_ms", 200))
            try:
                if getattr(session, "conversation_state", None) == "greeting":
                    greet_ms = int(getattr(cfg, "greeting_protection_ms", 0))
                    if greet_ms > initial_protect:
                        initial_protect = greet_ms
            except Exception:
                pass
            if tts_elapsed_ms < initial_protect:
                return

            cooldown_ms = int(getattr(cfg, "cooldown_ms", 500))
            last_barge_in_ts = float(getattr(session, "last_barge_in_ts", 0.0) or 0.0)
            if last_barge_in_ts and (now - last_barge_in_ts) * 1000 < cooldown_ms:
                return

            # Treat talk detection as sufficient evidence of an active media path for platform flush.
            try:
                if not bool(getattr(session, "media_rx_confirmed", False)):
                    session.media_rx_confirmed = True
                    session.first_media_rx_ts = now
                    await self._save_session(session)
            except Exception:
                pass

            await self._apply_barge_in_action(call_id, source="talkdetect", reason="ChannelTalkingStarted")
            logger.info("ðŸŽ§ BARGE-IN (TalkDetect) triggered", call_id=call_id, channel_id=channel_id)
        except Exception:
            logger.debug("ChannelTalkingStarted handler failed", ari_event=event, exc_info=True)

    async def _handle_channel_talking_finished(self, event: dict) -> None:
        """Informational handler for talk detection end events (pipelines)."""
        try:
            channel = event.get("channel", {}) or {}
            channel_id = channel.get("id")
            if not channel_id:
                return
            session = await self.session_store.get_by_channel_id(channel_id)
            if not session:
                return
            call_id = session.call_id
            if not bool(self._pipeline_forced.get(call_id)):
                return
            logger.debug("TalkDetect finished", call_id=call_id, channel_id=channel_id)
        except Exception:
            logger.debug("ChannelTalkingFinished handler failed", ari_event=event, exc_info=True)

    async def _cleanup_call(self, channel_or_call_id: str) -> None:
        """Shared cleanup for StasisEnd/ChannelDestroyed paths."""
        resolved_call_id = None  # Track for finally block cleanup
        try:
            # Resolve session by call_id first, then fallback to channel lookup.
            session = await self.session_store.get_by_call_id(channel_or_call_id)
            if not session:
                session = await self.session_store.get_by_channel_id(channel_or_call_id)
            if not session:
                logger.debug("No session found during cleanup", identifier=channel_or_call_id)
                return

            call_id = session.call_id
            resolved_call_id = call_id  # Save for finally block
            
            # In-memory re-entrancy guard (atomic, no race condition)
            if call_id in _cleanup_in_progress:
                logger.debug("Cleanup already in progress (in-memory guard)", call_id=call_id)
                return
            _cleanup_in_progress.add(call_id)
            
            logger.info("Cleaning up call", call_id=call_id)
            
            # Record call duration if we have start time
            try:
                import time
                if call_id in _call_start_times:
                    duration = time.time() - _call_start_times[call_id]
                    pipeline_name = getattr(session, 'pipeline_name', None) or "default"
                    provider_name = getattr(session, 'provider_name', None) or "unknown"
                    
                    _CALL_DURATION.labels(
                        pipeline=pipeline_name,
                        provider=provider_name,
                    ).observe(duration)
                    
                    # Clean up start time
                    del _call_start_times[call_id]
                    
                    logger.info("Recorded call duration", 
                               call_id=call_id,
                               duration_seconds=round(duration, 2),
                               pipeline=pipeline_name,
                               provider=provider_name)
            except Exception as e:
                logger.debug("Failed to record call duration", call_id=call_id, error=str(e))

            # Stop any active streaming playback.
            try:
                await self.streaming_playback_manager.stop_streaming_playback(call_id)
            except Exception:
                logger.debug("Streaming playback stop failed during cleanup", call_id=call_id, exc_info=True)

            # Stop background music if playing (AAVA-89)
            try:
                await self._stop_background_music(session)
            except Exception:
                logger.debug("Background music stop failed during cleanup", call_id=call_id, exc_info=True)

            # Stop the active provider session if one exists (per-call instance).
            try:
                start_task = self._provider_start_tasks.pop(call_id, None)
                if start_task:
                    start_task.cancel()
            except Exception:
                pass
            try:
                provider = self._call_providers.pop(call_id, None)
                if provider and hasattr(provider, "stop_session"):
                    await provider.stop_session()
            except Exception:
                logger.debug("Provider stop_session failed during cleanup", call_id=call_id, exc_info=True)

            # Check if call was transferred to dialplan (e.g., queue transfer)
            # If so, skip hanging up the caller channel
            transfer_active = getattr(session, 'transfer_active', False)
            
            # Tear down bridge.
            bridge_id = session.bridge_id
            if bridge_id:
                try:
                    await self.ari_client.destroy_bridge(bridge_id)
                    logger.info("Bridge destroyed", call_id=call_id, bridge_id=bridge_id)
                except Exception:
                    logger.debug("Bridge destroy failed", call_id=call_id, bridge_id=bridge_id, exc_info=True)

            # Hang up RTP and supporting channels (always)
            for channel_id in filter(None, [session.local_channel_id, session.external_media_id, session.audiosocket_channel_id]):
                try:
                    await self.ari_client.hangup_channel(channel_id)
                except Exception:
                    logger.debug("Hangup failed during cleanup", call_id=call_id, channel_id=channel_id, exc_info=True)
            
            # Hang up caller channel ONLY if not transferred
            if not transfer_active:
                try:
                    await self.ari_client.hangup_channel(session.caller_channel_id)
                except Exception:
                    logger.debug("Hangup failed during cleanup", call_id=call_id, channel_id=session.caller_channel_id, exc_info=True)
            else:
                logger.info("Skipping caller hangup - transferred to dialplan", call_id=call_id, transfer_target=getattr(session, 'transfer_target', 'unknown'))

            if getattr(self, 'rtp_server', None):
                try:
                    await self.rtp_server.cleanup_session(call_id)
                except Exception:
                    logger.debug("RTP session cleanup failed during call cleanup", call_id=call_id, exc_info=True)

            # Remove residual mappings so new calls donâ€™t inherit.
            self.bridges.pop(session.caller_channel_id, None)
            if session.local_channel_id:
                self.pending_local_channels.pop(session.local_channel_id, None)
                self.local_channels.pop(session.caller_channel_id, None)
            # Smoke Local mapping cleanup (best-effort)
            try:
                for base, cid in list(getattr(self, "_smoke_local_base_to_caller", {}).items()):
                    if cid == call_id:
                        self._smoke_local_base_to_caller.pop(base, None)
                for base, cid in list(getattr(self, "_smoke_local_base_to_leg1", {}).items()):
                    if cid == call_id:
                        self._smoke_local_base_to_leg1.pop(base, None)
            except Exception:
                logger.debug("Smoke Local mapping cleanup failed", call_id=call_id, exc_info=True)
            if session.audiosocket_channel_id:
                self.pending_audiosocket_channels.pop(session.audiosocket_channel_id, None)
                self.audiosocket_channels.pop(session.caller_channel_id, None)
            if session.audiosocket_uuid:
                self.uuidext_to_channel.pop(session.audiosocket_uuid, None)

            # Cancel adapter pipeline runner, clear queue and forced flag
            try:
                task = self._pipeline_tasks.pop(call_id, None)
                if task:
                    task.cancel()
                q = self._pipeline_queues.pop(call_id, None)
                if q:
                    try:
                        q.put_nowait(None)
                    except Exception:
                        pass
                try:
                    await self._disable_pipeline_talk_detect(session)
                except Exception:
                    logger.debug("Pipeline talk detect disable failed", call_id=call_id, exc_info=True)
                self._pipeline_forced.pop(call_id, None)
            except Exception:
                logger.debug("Pipeline cleanup failed", call_id=call_id, exc_info=True)

            # Clear detected codec preferences
            self.call_audio_preferences.pop(call_id, None)

            # Remove SSRC mapping for this call (if any)
            try:
                to_delete = [ssrc for ssrc, cid in self.ssrc_to_caller.items() if cid == call_id]
                for ssrc in to_delete:
                    self.ssrc_to_caller.pop(ssrc, None)
            except Exception:
                pass

            # Release pipeline components before dropping session.
            if getattr(self, "pipeline_orchestrator", None) and self.pipeline_orchestrator.enabled:
                try:
                    await self.pipeline_orchestrator.release_pipeline(call_id)
                except Exception:
                    logger.debug("Pipeline release failed during cleanup", call_id=call_id, exc_info=True)

            # Auto-send email summary if enabled (before session is removed)
            try:
                # Auto-trigger email summary if configured and session has conversation history
                email_tool_config = self.config.tools.get('send_email_summary', {})
                if email_tool_config.get('enabled', False):
                    from src.tools.registry import tool_registry
                    email_tool = tool_registry.get('send_email_summary')
                    if email_tool:
                        # Verify session still exists (race condition with multiple cleanup calls)
                        check_session = await self.session_store.get_by_call_id(call_id)
                        if not check_session:
                            logger.debug(
                                "Skipping email summary - session already removed by concurrent cleanup",
                                call_id=call_id
                            )
                        else:
                            # Build execution context
                            from src.tools.context import ToolExecutionContext
                            context = ToolExecutionContext(
                                call_id=call_id,
                                caller_channel_id=session.caller_channel_id,
                                bridge_id=session.bridge_id,
                                session_store=self.session_store,
                                ari_client=self.ari_client,
                                config=self.config.dict()
                            )
                            # Execute synchronously to ensure session is available
                            # Email sending itself is still async (non-blocking)
                            await email_tool.execute({}, context)
                            logger.info("ðŸ“§ Auto-triggered email summary", call_id=call_id)
            except RuntimeError as e:
                # Session not found is expected in concurrent cleanup scenarios
                if "Session not found" in str(e):
                    logger.debug(
                        "Email summary skipped - session already cleaned up",
                        call_id=call_id
                    )
                else:
                    logger.warning("Failed to auto-trigger email summary", call_id=call_id, error=str(e))
            except Exception as e:
                logger.warning("Failed to auto-trigger email summary", call_id=call_id, error=str(e), exc_info=True)

            # Send transcript emails if requested during call (complete conversation)
            try:
                if hasattr(session, 'transcript_emails') and session.transcript_emails:
                    transcript_tool_config = self.config.tools.get('request_transcript', {})
                    if transcript_tool_config.get('enabled', False):
                        from src.tools.registry import tool_registry
                        transcript_tool = tool_registry.get('request_transcript')
                        if transcript_tool:
                            # Send transcript to each requested email
                            for email_address in session.transcript_emails:
                                try:
                                    # Build execution context
                                    from src.tools.context import ToolExecutionContext
                                    context = ToolExecutionContext(
                                        call_id=call_id,
                                        caller_channel_id=session.caller_channel_id,
                                        bridge_id=session.bridge_id,
                                        session_store=self.session_store,
                                        ari_client=self.ari_client,
                                        config=self.config.dict()
                                    )
                                    
                                    # Get fresh session data with complete conversation
                                    current_session = await self.session_store.get_by_call_id(call_id)
                                    if current_session:
                                        # Prepare and send transcript email
                                        email_data = transcript_tool._prepare_email_data(
                                            email_address,
                                            current_session,
                                            transcript_tool_config,
                                            call_id
                                        )
                                        # Send asynchronously (don't block cleanup)
                                        asyncio.create_task(transcript_tool._send_transcript_async(email_data, call_id))
                                        logger.info(
                                            "ðŸ“§ Sent end-of-call transcript",
                                            call_id=call_id,
                                            email=email_address
                                        )
                                except Exception as e:
                                    logger.warning(
                                        "Failed to send transcript to email",
                                        call_id=call_id,
                                        email=email_address,
                                        error=str(e)
                                    )
            except Exception as e:
                logger.warning("Failed to process transcript emails", call_id=call_id, error=str(e), exc_info=True)

            # Persist call to history before removing session (Milestone 21)
            try:
                await self._persist_call_history(session, call_id)
            except Exception as e:
                logger.debug("Failed to persist call history", call_id=call_id, error=str(e))

            # Finally remove the session.
            await self.session_store.remove_call(call_id)

            try:
                self.audio_capture.close_call(call_id)
            except Exception:
                logger.debug("Audio capture cleanup failed", call_id=call_id, exc_info=True)

            if self.conversation_coordinator:
                await self.conversation_coordinator.unregister_call(call_id)
            
            # Clean up VAD manager state for this call
            if self.vad_manager:
                try:
                    await self.vad_manager.reset_call(call_id)
                    self.vad_manager.context_analyzer.cleanup_call(call_id)
                except Exception:
                    logger.debug("VAD cleanup failed during call cleanup", call_id=call_id, exc_info=True)
            
            # Clean up audio gating manager state for this call
            if self.audio_gating_manager:
                try:
                    await self.audio_gating_manager.cleanup_call(call_id)
                except Exception:
                    logger.debug("Audio gating cleanup failed during call cleanup", call_id=call_id, exc_info=True)

            try:
                # If the session still exists in store (rare race), mark completed; otherwise ignore
                sess2 = await self.session_store.get_by_call_id(call_id)
                if sess2:
                    sess2.cleanup_completed = True
                    sess2.cleanup_in_progress = False
                    await self.session_store.upsert_call(sess2)
            except Exception:
                pass

            # Reset per-call alignment warning state
            self._runtime_alignment_logged.discard(call_id)

            logger.info("Call cleanup completed", call_id=call_id)
        except Exception as exc:
            logger.error("Error cleaning up call", identifier=channel_or_call_id, error=str(exc), exc_info=True)
        finally:
            # Clean up in-memory guard
            if resolved_call_id:
                _cleanup_in_progress.discard(resolved_call_id)

    async def _persist_call_history(self, session: CallSession, call_id: str) -> None:
        """Persist call record to history database (Milestone 21)."""
        try:
            from src.core.call_history import CallRecord, get_call_history_store
            
            store = get_call_history_store()
            if not store._enabled:
                return
            
            # Calculate end time and duration (use UTC for consistent timezone handling)
            from datetime import timezone
            end_time = datetime.now(timezone.utc)
            start_time = session.start_time
            if start_time and start_time.tzinfo is None:
                start_time = start_time.replace(tzinfo=timezone.utc)
            elif not start_time:
                start_time = datetime.fromtimestamp(session.created_at, tz=timezone.utc)
            duration = (end_time - start_time).total_seconds() if start_time else 0.0
            
            # Determine outcome
            outcome = "completed"
            if session.error_message:
                outcome = "error"
            elif session.transfer_destination:
                outcome = "transferred"
            elif not session.conversation_history:
                outcome = "abandoned"
            
            # Calculate latency stats
            turn_latencies = getattr(session, 'turn_latencies_ms', []) or []
            avg_latency = sum(turn_latencies) / len(turn_latencies) if turn_latencies else 0.0
            max_latency = max(turn_latencies) if turn_latencies else 0.0
            
            # Barge-in count: number of times we applied a barge-in action (user interrupted agent output).
            # This is the value the UI should display as "Barge-ins".
            barge_in_count = int(getattr(session, 'barge_in_count', 0) or 0)
            
            record = CallRecord(
                call_id=call_id,
                caller_number=session.caller_number,
                caller_name=session.caller_name,
                start_time=start_time,
                end_time=end_time,
                duration_seconds=duration,
                provider_name=session.provider_name,
                pipeline_name=session.pipeline_name,
                pipeline_components=session.pipeline_components or {},
                context_name=session.context_name,
                conversation_history=session.conversation_history or [],
                outcome=outcome,
                transfer_destination=session.transfer_destination,
                error_message=session.error_message,
                tool_calls=getattr(session, 'tool_calls', []) or [],
                avg_turn_latency_ms=avg_latency,
                max_turn_latency_ms=max_latency,
                total_turns=len(turn_latencies),
                caller_audio_format=session.caller_audio_format,
                codec_alignment_ok=session.codec_alignment_ok,
                barge_in_count=barge_in_count,
            )
            
            saved = await store.save(record)
            if saved:
                logger.debug("Call history record saved", call_id=call_id, record_id=record.id)
        except ImportError:
            logger.debug("Call history module not available", call_id=call_id)
        except Exception as e:
            logger.debug("Failed to persist call history", call_id=call_id, error=str(e))

    async def _resolve_audio_profile(self, session: CallSession, channel_id: str) -> None:
        """Resolve TransportProfile and provider prefs from profiles/contexts.

        Precedence (provider): AI_PROVIDER (later) > contexts.*.provider > default_provider.
        """
        call_id = session.call_id
        # Read channel vars
        ai_profile = None
        ai_context = None
        try:
            resp = await self.ari_client.send_command(
                "GET",
                f"channels/{channel_id}/variable",
                params={"variable": "AI_AUDIO_PROFILE"},
            )
            if isinstance(resp, dict):
                ai_profile = (resp.get("value") or "").strip()
        except Exception:
            pass
        try:
            resp = await self.ari_client.send_command(
                "GET",
                f"channels/{channel_id}/variable",
                params={"variable": "AI_CONTEXT"},
            )
            if isinstance(resp, dict):
                ai_context = (resp.get("value") or "").strip()
        except Exception:
            pass

        cfg_profiles = getattr(self.config, "profiles", {}) or {}
        cfg_contexts = getattr(self.config, "contexts", {}) or {}
        # Extract default profile name
        default_profile_name = None
        try:
            dp = cfg_profiles.get("default")
            if isinstance(dp, str) and dp:
                default_profile_name = dp
        except Exception:
            default_profile_name = None
        # Build profile map excluding the 'default' selector key
        profile_map = {k: v for (k, v) in cfg_profiles.items() if isinstance(v, dict)}

        # Resolve profile name from channel var, then context mapping, else default
        context_block = cfg_contexts.get(ai_context) if ai_context else None
        ctx_profile = None
        try:
            if isinstance(context_block, dict):
                ctx_profile = context_block.get("profile")
        except Exception:
            ctx_profile = None
        selected_profile_name = ai_profile or ctx_profile or default_profile_name
        profile_obj = profile_map.get(selected_profile_name) if selected_profile_name else None
        if profile_obj is None and default_profile_name:
            profile_obj = profile_map.get(default_profile_name)

        # Extract transport_out and provider prefs
        transport_out = (profile_obj or {}).get("transport_out", {}) if isinstance(profile_obj, dict) else {}
        prov_pref = (profile_obj or {}).get("provider_pref", {}) if isinstance(profile_obj, dict) else {}
        chunk_ms = None
        idle_cutoff_ms = None
        try:
            v = prov_pref.get("preferred_chunk_ms")
            if v is not None:
                chunk_ms = int(v)
        except Exception:
            pass
        try:
            v = (profile_obj or {}).get("idle_cutoff_ms")
            if v is not None:
                idle_cutoff_ms = int(v)
        except Exception:
            pass

        # Determine transport encoding/rate from profile (fallback to existing)
        enc = self._canonicalize_encoding(transport_out.get("encoding")) or session.transport_profile.format
        try:
            rate = int(transport_out.get("sample_rate_hz") or 0)
        except Exception:
            rate = 0
        if rate <= 0:
            rate = session.transport_profile.sample_rate

        # Apply transport settings with 'config' source (won't override dialplan/detected)
        try:
            await self._update_transport_profile(session, fmt=enc, sample_rate=rate, source="config")
        except Exception:
            logger.debug("Transport profile update from profile failed", call_id=call_id, exc_info=True)

        # Apply context-level provider override (Option A), lower precedence than AI_PROVIDER.
        provider_origin = None
        try:
            ctx_provider = None
            if isinstance(context_block, dict):
                ctx_provider = (context_block.get("provider") or "").strip()
            if ctx_provider:
                aliases = {"openai": "openai_realtime", "deepgram_agent": "deepgram"}
                resolved = aliases.get(ctx_provider, ctx_provider)
                if resolved in self.providers and session.provider_name != resolved:
                    prev = session.provider_name
                    session.provider_name = resolved
                    await self._save_session(session)
                    provider_origin = "context"
                    logger.info("Context provider override applied", call_id=call_id, context=ai_context, previous_provider=prev, provider=resolved)
        except Exception:
            logger.debug("Context provider override failed", call_id=call_id, exc_info=True)

        # Wire streaming manager parameters (global fields; per-call override is a future improvement)
        spm = getattr(self, "streaming_playback_manager", None)
        if spm is not None:
            # CRITICAL: Do NOT override audiosocket_format from transport profile.
            # AudioSocket wire format must always match config.audiosocket.format (set at engine init),
            # NOT the caller's SIP codec. Caller codec applies only to provider transcoding.
            # Bug fix: removed lines that set spm.audiosocket_format = enc
            try:
                if rate and rate > 0:
                    spm.sample_rate = int(rate)
            except Exception:
                pass
            try:
                if chunk_ms and int(chunk_ms) > 0:
                    spm.chunk_size_ms = int(chunk_ms)
            except Exception:
                pass
            try:
                if idle_cutoff_ms and int(idle_cutoff_ms) > 0:
                    spm.idle_cutoff_ms = int(idle_cutoff_ms)
            except Exception:
                pass

        # Emit one-shot profile resolution card
        try:
            self._emit_profile_resolution_card(
                session.call_id,
                session,
                profile_name=selected_profile_name,
                context_name=ai_context,
                transport_encoding=enc,
                transport_sample_rate=rate,
                chunk_ms=chunk_ms,
                idle_cutoff_ms=idle_cutoff_ms,
                provider_origin=provider_origin or ("profile" if ai_profile else ("context" if ai_context else None)),
            )
        except Exception:
            logger.debug("Audio Profile Resolution card logging failed", call_id=call_id, exc_info=True)

    def _emit_profile_resolution_card(
        self,
        call_id: Optional[str],
        session: Optional[CallSession],
        *,
        profile_name: Optional[str],
        context_name: Optional[str],
        transport_encoding: Optional[Any],
        transport_sample_rate: Optional[Any],
        chunk_ms: Optional[Any],
        idle_cutoff_ms: Optional[Any],
        provider_origin: Optional[str],
    ) -> None:
        if not call_id or call_id in self._profile_card_logged:
            return
        def _ir(v):
            try:
                return int(v) if v is not None else None
            except Exception:
                return None
        payload = {
            "call_id": call_id,
            "log_event": "Audio Profile Resolution",
            "profile": profile_name,
            "context": context_name,
            "provider": getattr(session, "provider_name", None) if session else None,
            "provider_origin": provider_origin,
            "transport_encoding": self._canonicalize_encoding(transport_encoding) or None,
            "transport_sample_rate_hz": _ir(transport_sample_rate),
            "chunk_size_ms": _ir(chunk_ms),
            "idle_cutoff_ms": _ir(idle_cutoff_ms),
        }
        try:
            logger.info("AudioProfileResolution", **{k: v for k, v in payload.items() if v is not None})
            self._profile_card_logged.add(call_id)
        except Exception:
            logger.debug("Profile resolution card logging failed", call_id=call_id, exc_info=True)

    async def _audiosocket_handle_uuid(self, conn_id: str, uuid_str: str) -> bool:
        """Bind inbound AudioSocket connection to the caller channel via UUID."""
        try:
            caller_channel_id = self.uuidext_to_channel.get(uuid_str)

            # Handle race where the TCP client connects before we finish recording
            # the UUID mapping. Give the originate path a brief window to catch up.
            if not caller_channel_id:
                for attempt in range(3):
                    await asyncio.sleep(0.05)
                    caller_channel_id = self.uuidext_to_channel.get(uuid_str)
                    if caller_channel_id:
                        logger.debug(
                            "AudioSocket UUID resolved after retry",
                            conn_id=conn_id,
                            uuid=uuid_str,
                            attempt=attempt + 1,
                        )
                        break

            if not caller_channel_id:
                logger.warning(
                    "AudioSocket UUID not recognized",
                    conn_id=conn_id,
                    uuid=uuid_str,
                )
                return False

            # Track mappings
            self.conn_to_channel[conn_id] = caller_channel_id
            self.channel_to_conn[caller_channel_id] = conn_id
            self.channel_to_conns.setdefault(caller_channel_id, set()).add(conn_id)
            if caller_channel_id not in self.audiosocket_primary_conn:
                self.audiosocket_primary_conn[caller_channel_id] = conn_id

            # Update session
            session = await self.session_store.get_by_call_id(caller_channel_id)
            if session:
                session.audiosocket_uuid = uuid_str
                # Record current AudioSocket connection for streaming playback
                try:
                    session.audiosocket_conn_id = conn_id
                except Exception:
                    pass
                session.status = "audiosocket_bound"
                await self._save_session(session)

            logger.info(
                "AudioSocket connection bound to caller",
                conn_id=conn_id,
                uuid=uuid_str,
                caller_channel_id=caller_channel_id,
            )
            return True
        except Exception as exc:
            logger.error("Error binding AudioSocket UUID", conn_id=conn_id, uuid=uuid_str, error=str(exc), exc_info=True)
            return False

    async def _audiosocket_handle_audio(self, conn_id: str, audio_bytes: bytes) -> None:
        """Forward inbound AudioSocket audio to the active provider for the bound call."""
        # Track every frame for diagnostics
        if not hasattr(self, '_audiosocket_frame_count'):
            self._audiosocket_frame_count = {}
        
        try:
            caller_channel_id = self.conn_to_channel.get(conn_id)
            if not caller_channel_id and self.audio_socket_server:
                # Fallback: resolve via server's UUID registry
                try:
                    uuid_str = self.audio_socket_server.get_uuid_for_conn(conn_id)
                    if uuid_str:
                        caller_channel_id = self.uuidext_to_channel.get(uuid_str)
                        if caller_channel_id:
                            self.conn_to_channel[conn_id] = caller_channel_id
                except Exception:
                    pass

            if not caller_channel_id:
                logger.debug("AudioSocket audio received for unknown connection", conn_id=conn_id, bytes=len(audio_bytes))
                return

            # Track frame count per call
            self._audiosocket_frame_count[caller_channel_id] = self._audiosocket_frame_count.get(caller_channel_id, 0) + 1
            frame_num = self._audiosocket_frame_count[caller_channel_id]
            
            # Log every 10th frame + first 5 frames
            if frame_num <= 5 or frame_num % 10 == 0:
                logger.info(
                    "ðŸŽ¤ AUDIOSOCKET RX - Frame received",
                    call_id=caller_channel_id,
                    frame_num=frame_num,
                    frame_bytes=len(audio_bytes),
                    conn_id=conn_id,
                )

            session = await self.session_store.get_by_call_id(caller_channel_id)
            if not session:
                logger.debug("No session for caller; dropping AudioSocket audio", conn_id=conn_id, caller_channel_id=caller_channel_id)
                return

            # Media-path confirmation: first inbound audio frame observed.
            # Used to gate barge-in actions so we don't trigger during setup races.
            try:
                if not bool(getattr(session, "media_rx_confirmed", False)):
                    session.media_rx_confirmed = True
                    session.first_media_rx_ts = time.time()
                    await self._save_session(session)
                    logger.info("Media RX confirmed (AudioSocket)", call_id=caller_channel_id)
            except Exception:
                logger.debug("Failed to set media_rx_confirmed (AudioSocket)", call_id=caller_channel_id, exc_info=True)

            diagnostics_flags = session.audio_diagnostics
            if "inbound_first_frame" not in diagnostics_flags:
                fmt, rate = self._infer_transport_from_frame(len(audio_bytes))
                await self._update_transport_profile(session, fmt=fmt, sample_rate=rate, source="audiosocket")
                diagnostics_flags["inbound_first_frame"] = True

            # Per-call RX bytes
            try:
                _STREAM_RX_BYTES.inc(len(audio_bytes))
            except Exception:
                pass

            # First-frame diagnostics probe (no mutation): log RMS for format verification
            try:
                vad_state = session.vad_state
            except Exception:
                vad_state = session.vad_state = {}
            if not vad_state.get('format_probe_done'):
                try:
                    try:
                        as_fmt = (getattr(self.config, 'audiosocket', None).format or 'ulaw').lower()
                    except Exception:
                        as_fmt = 'ulaw'
                    if as_fmt in ('slin16', 'linear16', 'pcm16'):
                        rms_native = audioop.rms(audio_bytes, 2)
                        try:
                            swapped = audioop.byteswap(audio_bytes, 2)
                            rms_swapped = audioop.rms(swapped, 2)
                        except Exception:
                            rms_swapped = 0
                        logger.info(
                            "AudioSocket frame probe",
                            call_id=caller_channel_id,
                            audiosocket_format=as_fmt,
                            frame_bytes=len(audio_bytes),
                            rms_native=rms_native,
                            rms_swapped=rms_swapped,
                        )
                        # Determine if inbound PCM16 appears byte-swapped (big-endian on wire)
                        try:
                            frame_bytes = len(audio_bytes)
                            # Conservative rule: only flag swap when swapped energy is clearly higher
                            swap_flag = (
                                frame_bytes >= 640 and  # 20ms @ 16k PCM
                                rms_swapped >= 2048 and
                                rms_swapped >= 16 * max(1, rms_native)
                            )
                            vad_state['pcm16_inbound_swap'] = bool(swap_flag)
                            if swap_flag:
                                logger.warning(
                                    "Inbound slin16 appears byte-swapped; will normalize to PCM16-LE for processing",
                                    call_id=caller_channel_id,
                                    rms_native=rms_native,
                                    rms_swapped=rms_swapped,
                                )
                        except Exception:
                            pass
                    else:
                        try:
                            pcm = audioop.ulaw2lin(audio_bytes, 2)
                            rms_pcm = audioop.rms(pcm, 2)
                        except Exception:
                            rms_pcm = 0
                        logger.info(
                            "AudioSocket frame probe",
                            call_id=caller_channel_id,
                            audiosocket_format=as_fmt,
                            frame_bytes=len(audio_bytes),
                            rms_pcm8k=rms_pcm,
                        )
                        # Î¼-law path: no PCM16 swap needed
                        vad_state['pcm16_inbound_swap'] = False
                    vad_state['format_probe_done'] = True
                except Exception:
                    pass

            try:
                swap_needed_flag = bool(session.vad_state.get('pcm16_inbound_swap', False))
            except Exception:
                swap_needed_flag = False
            try:
                # CRITICAL: AudioSocket format is authoritative for AudioSocket transport
                # For RTP, use transport profile (negotiated codec)
                if self.config.audio_transport == "audiosocket":
                    # Use AudioSocket's actual format (from YAML)
                    profile_fmt = getattr(self.config.audiosocket, "format", "slin16")
                    # Get sample rate from AudioSocket config or infer from format
                    profile_rate = getattr(self.config.audiosocket, "sample_rate", None)
                    if not profile_rate:
                        # Infer rate from format: slin=8kHz, slin16=16kHz
                        canonical_fmt = self._canonicalize_encoding(profile_fmt)
                        if canonical_fmt == "slin":
                            profile_rate = 8000
                        elif canonical_fmt == "slin16":
                            profile_rate = 16000
                        else:
                            profile_rate = getattr(self.config.streaming, "sample_rate", 8000)
                else:
                    # For RTP: use transport profile (negotiated codec)
                    profile_fmt = session.transport_profile.format or "ulaw"
                    profile_rate = session.transport_profile.sample_rate or 8000
            except Exception:
                # Safe fallback based on transport type
                if self.config.audio_transport == "audiosocket":
                    profile_fmt = "slin16"
                    profile_rate = 16000
                else:
                    profile_fmt = "ulaw"
                    profile_rate = 8000
            pcm_bytes, pcm_rate = self._wire_to_pcm16(audio_bytes, profile_fmt, swap_needed_flag, profile_rate)
            # Remove DC bias ONLY (disable IIR DC-block filter - causes audio degradation)
            try:
                if pcm_bytes:
                    try:
                        mean = int(audioop.avg(pcm_bytes, 2))
                    except Exception:
                        mean = 0
                    if mean:
                        try:
                            pcm_bytes = audioop.bias(pcm_bytes, 2, -mean)
                        except Exception:
                            pass
                    # DC-block IIR filter DISABLED - was causing progressive audio level collapse
                    # Symptoms: Audio started strong (RMS 4000) but degraded to near-silence (RMS 16)
                    # Root cause: Stateful filter accumulated error, over-attenuated speech
                    # Keep simple DC offset removal (audioop.bias) above, skip IIR filter
            except Exception:
                logger.debug("Inbound DC conditioning failed", call_id=caller_channel_id, exc_info=True)
            try:
                if pcm_bytes:
                    self._update_audio_diagnostics(session, "transport_in", pcm_bytes, "slin16", pcm_rate)
                    self.audio_capture.append_pcm16(session.call_id, "caller_inbound", pcm_bytes, pcm_rate)
            except Exception:
                logger.debug("Inbound diagnostics update failed", call_id=caller_channel_id, exc_info=True)

            # CRITICAL FIX: Check for pipeline mode FIRST before routing to monolithic providers
            if self._pipeline_forced.get(caller_channel_id):
                # AAVA-28: Check gating to prevent agent from hearing its own TTS output
                if not session.audio_capture_enabled:
                    # Pipelines: allow barge-in detection during TTS gating, but do not forward audio until triggered.
                    cfg = getattr(self.config, "barge_in", None)
                    if not cfg or not getattr(cfg, "enabled", True):
                        return
                    # If TALK_DETECT is enabled for this pipeline, prefer it over local energy checks
                    # to avoid double-triggering and false positives on AudioSocket.
                    try:
                        td = (session.vad_state or {}).get("pipeline_talk_detect", {}) or {}
                        if bool(td.get("enabled", False)):
                            return
                    except Exception:
                        pass
                    now = time.time()
                    tts_elapsed_ms = 0
                    try:
                        if getattr(session, "tts_started_ts", 0.0) > 0:
                            tts_elapsed_ms = int((now - float(session.tts_started_ts)) * 1000)
                    except Exception:
                        tts_elapsed_ms = 0
                    initial_protect = int(getattr(cfg, "initial_protection_ms", 200))
                    try:
                        if getattr(session, "conversation_state", None) == "greeting":
                            greet_ms = int(getattr(cfg, "greeting_protection_ms", 0))
                            if greet_ms > initial_protect:
                                initial_protect = greet_ms
                    except Exception:
                        pass
                    if tts_elapsed_ms < initial_protect:
                        return
                    try:
                        energy = audioop.rms(pcm_bytes, 2)
                    except Exception:
                        energy = 0
                    threshold = int(getattr(cfg, "pipeline_energy_threshold", 0) or getattr(cfg, "energy_threshold", 1000))
                    try:
                        frame_ms = int((len(pcm_bytes) / float(2 * max(1, int(pcm_rate)))) * 1000)
                        if frame_ms <= 0:
                            frame_ms = 20
                    except Exception:
                        frame_ms = 20
                    if energy >= threshold:
                        if int(getattr(session, "barge_in_candidate_ms", 0)) == 0:
                            try:
                                session.barge_start_ts = now
                            except Exception:
                                session.barge_start_ts = 0.0
                        session.barge_in_candidate_ms = int(getattr(session, "barge_in_candidate_ms", 0)) + frame_ms
                    else:
                        session.barge_in_candidate_ms = 0

                    # Debug monitor (rate-limited) so we can see why pipeline barge-in is/isn't firing.
                    try:
                        mon = session.vad_state.setdefault("pipeline_barge_mon", {})
                        last = float(mon.get("last_ts", 0.0) or 0.0)
                        if now - last >= 1.0:
                            mon["last_ts"] = now
                            logger.debug(
                                "Pipeline barge-in monitor (AudioSocket)",
                                call_id=caller_channel_id,
                                tts_elapsed_ms=tts_elapsed_ms,
                                energy=energy,
                                threshold=threshold,
                                candidate_ms=int(getattr(session, "barge_in_candidate_ms", 0) or 0),
                                audio_capture_enabled=session.audio_capture_enabled,
                            )
                    except Exception:
                        pass

                    cooldown_ms = int(getattr(cfg, "cooldown_ms", 500))
                    last_barge_in_ts = float(getattr(session, "last_barge_in_ts", 0.0) or 0.0)
                    in_cooldown = (now - last_barge_in_ts) * 1000 < cooldown_ms if last_barge_in_ts else False
                    min_ms = int(getattr(cfg, "pipeline_min_ms", 0) or getattr(cfg, "min_ms", 250))
                    if not in_cooldown and int(getattr(session, "barge_in_candidate_ms", 0)) >= min_ms:
                        try:
                            try:
                                if float(getattr(session, "barge_start_ts", 0.0) or 0.0) > 0.0:
                                    reaction_s = max(0.0, now - float(session.barge_start_ts))
                                    _BARGE_REACTION_SECONDS.observe(reaction_s)
                                    session.barge_start_ts = 0.0
                            except Exception:
                                pass
                            await self._apply_barge_in_action(
                                caller_channel_id,
                                source="local_vad",
                                reason="pipeline_tts_overlap",
                            )
                            session.audio_capture_enabled = True
                            logger.info("ðŸŽ§ BARGE-IN (AudioSocket/pipeline) triggered", call_id=caller_channel_id)
                        except Exception:
                            logger.error("Error triggering AudioSocket pipeline barge-in", call_id=caller_channel_id, exc_info=True)
                    else:
                        if energy > 0 and self.conversation_coordinator:
                            try:
                                self.conversation_coordinator.note_audio_during_tts(caller_channel_id)
                            except Exception:
                                pass
                        return
                
                q = self._pipeline_queues.get(caller_channel_id)
                if q:
                    try:
                        pcm16 = pcm_bytes
                        if pcm16 and pcm_rate != 16000:
                            try:
                                state = self._resample_state_pipeline16k.get(caller_channel_id)
                                pcm16, state = audioop.ratecv(pcm16, 2, 1, pcm_rate, 16000, state)
                                self._resample_state_pipeline16k[caller_channel_id] = state
                            except Exception:
                                pcm16 = pcm_bytes
                        if pcm16:
                            q.put_nowait(pcm16)
                        return
                    except asyncio.QueueFull:
                        logger.debug("Pipeline queue full; dropping AudioSocket frame", call_id=caller_channel_id)
                        return

            # Unconditional continuous-input forward: Deepgram/OpenAI Realtime expect raw audio flow
            # NOTE: Only applies to monolithic providers, not pipelines (handled above)
            try:
                provider_name = getattr(session, 'provider_name', None) or self.config.default_provider
                provider = self._call_providers.get(caller_channel_id)
                provider_caps_source = provider or self.providers.get(provider_name)
            except Exception:
                provider = None
                provider_caps_source = None
            continuous_input = False
            try:
                # Use provider capabilities instead of hardcoded names
                capabilities = None
                if provider_caps_source and hasattr(provider_caps_source, 'get_capabilities'):
                    try:
                        capabilities = provider_caps_source.get_capabilities()
                    except Exception:
                        pass
                
                if capabilities and capabilities.requires_continuous_audio:
                    continuous_input = True
                else:
                    # Fallback for legacy providers without capabilities
                    pcfg = getattr(provider, 'config', None)
                    if isinstance(pcfg, dict):
                        continuous_input = bool(pcfg.get('continuous_input', False))
                    else:
                        continuous_input = bool(getattr(pcfg, 'continuous_input', False))
            except Exception:
                continuous_input = False
            
            if continuous_input:
                # Ensure a per-call provider instance exists; never send on the global template.
                if not provider or not hasattr(provider, 'send_audio'):
                    if caller_channel_id not in self._provider_start_tasks and not getattr(session, "provider_session_active", False):
                        self._kickoff_provider_session_start(caller_channel_id)
                    return
                if not getattr(session, "provider_session_active", False):
                    return
                # CRITICAL FIX: Google Live needs gating, but OpenAI/Deepgram don't
                # - Google Live: Bidirectional audio, NO server-side echo cancellation â†’ NEEDS gating
                # - OpenAI Realtime: Server-side AEC â†’ gating harmful
                # - Deepgram: Text-based output â†’ no echo risk
                needs_gating = provider_name == "google_live"
                
                if needs_gating and not session.audio_capture_enabled:
                    # CRITICAL: Google Live requires continuous audio stream (like WebRTC)
                    # Send SILENCE frames instead of blocking to maintain stream continuity
                    # This prevents echo while keeping VAD healthy
                    logger.debug(
                        "ðŸ”‡ GATING ACTIVE - Sending silence frame for Google Live (TTS playing)",
                        call_id=caller_channel_id,
                        audio_capture_enabled=session.audio_capture_enabled,
                    )
                    # Replace audio with silence (zero-filled PCM16)
                    pcm_bytes = b'\x00' * len(pcm_bytes)
                
                # Forward to provider
                logger.info(
                    "ðŸ“¤ CONTINUOUS INPUT - Forwarding frame to provider",
                    call_id=caller_channel_id,
                    provider=provider_name,
                    frame_bytes=len(audio_bytes),
                    pcm_bytes=len(pcm_bytes),
                    gating_active=needs_gating and not session.audio_capture_enabled,
                    is_silence=needs_gating and not session.audio_capture_enabled,
                )
                try:
                    self._update_audio_diagnostics(session, "provider_in", pcm_bytes, "slin16", pcm_rate)
                except Exception:
                    logger.debug("Provider input diagnostics update failed (unconditional)", call_id=caller_channel_id, exc_info=True)
                try:
                    prov_payload, prov_enc, prov_rate = self._encode_for_provider(
                        session.call_id,
                        provider_name,
                        provider,
                        pcm_bytes,
                        pcm_rate,
                    )
                    logger.info(
                        "ðŸ“¤ CONTINUOUS INPUT - Encoded for provider",
                        call_id=caller_channel_id,
                        provider=provider_name,
                        prov_payload_bytes=len(prov_payload),
                        prov_enc=prov_enc,
                        prov_rate=prov_rate,
                    )
                    try:
                        self.audio_capture.append_encoded(
                            session.call_id,
                            "caller_to_provider",
                            prov_payload,
                            prov_enc,
                            prov_rate,
                        )
                    except Exception:
                        logger.debug(
                            "Provider input capture failed (unconditional)",
                            call_id=session.call_id,
                            exc_info=True,
                        )

                    # CRITICAL: Pass sample_rate and encoding to prevent double resampling
                    # Google Live needs to know audio is already at provider_rate to skip resampling
                    try:
                        await provider.send_audio(prov_payload, prov_rate, prov_enc)
                        logger.info(
                            "âœ… CONTINUOUS INPUT - Frame sent to provider successfully",
                            call_id=caller_channel_id,
                            provider=provider_name,
                        )
                    except TypeError:
                        # Fallback for providers with old signature (audio_chunk only)
                        await provider.send_audio(prov_payload)
                        logger.info(
                            "âœ… CONTINUOUS INPUT - Frame sent to provider (legacy signature)",
                            call_id=caller_channel_id,
                            provider=provider_name,
                        )
                except Exception as e:
                    logger.error(
                        "âŒ CONTINUOUS INPUT - Provider forward error",
                        call_id=caller_channel_id,
                        provider=provider_name,
                        error=str(e),
                        exc_info=True,
                    )
                # Provider-owned mode: local VAD fallback may flush local output (never cancels provider).
                try:
                    await self._maybe_provider_barge_in_fallback(
                        session,
                        pcm16=pcm_bytes,
                        pcm_rate_hz=pcm_rate,
                        audiosocket_wire=audio_bytes,
                        source="audiosocket",
                    )
                except Exception:
                    logger.debug("Provider barge-in fallback check failed (AudioSocket)", call_id=caller_channel_id, exc_info=True)
                return
            else:
                logger.info(
                    "âš ï¸ CONTINUOUS INPUT - Block skipped",
                    call_id=caller_channel_id,
                    continuous_input=continuous_input,
                    provider_found=provider is not None,
                    has_send_audio=hasattr(provider, 'send_audio') if provider else False,
                    provider_name=provider_name,
                )

            # Post-TTS end protection: drop inbound briefly after gating clears to avoid agent echo re-capture
            try:
                cfg = getattr(self.config, 'barge_in', None)
                post_guard_ms = int(getattr(cfg, 'post_tts_end_protection_ms', 0)) if cfg else 0
            except Exception:
                post_guard_ms = 0
            if post_guard_ms and getattr(session, 'tts_ended_ts', 0.0) and session.audio_capture_enabled:
                try:
                    elapsed_ms = int((time.time() - float(session.tts_ended_ts)) * 1000)
                except Exception:
                    elapsed_ms = post_guard_ms
                if elapsed_ms < post_guard_ms:
                    logger.debug(
                        "Dropping inbound during post-TTS protection window",
                        call_id=caller_channel_id,
                        elapsed_ms=elapsed_ms,
                        protect_ms=post_guard_ms,
                    )
                    return

            vad_result: Optional[VADResult] = None
            if self.vad_manager:
                try:
                    vad_result = await self._run_enhanced_vad(session, audio_bytes)
                except Exception:
                    logger.debug(
                        "Enhanced VAD processing error",
                        call_id=caller_channel_id,
                        exc_info=True,
                    )

            # Self-echo mitigation and barge-in/continuous-input handling during TTS playback
            if hasattr(session, 'audio_capture_enabled') and not session.audio_capture_enabled:
                cfg = getattr(self.config, 'barge_in', None)
                
                # AAVA-28: Pipelines now respect gating - no special bypass during TTS
                # Drop audio for pipelines during TTS playback (handled by earlier gating check)
                if self._pipeline_forced.get(caller_channel_id):
                    # Audio already dropped by gating check above (line 2059)
                    return
                
                # Determine provider and continuous-input capability FIRST to allow forwarding during greeting guard
                try:
                    provider_name = getattr(session, 'provider_name', None) or self.config.default_provider
                    provider = self._call_providers.get(caller_channel_id)
                    provider_caps_source = provider or self.providers.get(provider_name)
                except Exception:
                    provider = None
                    provider_caps_source = None
                continuous_input = False
                try:
                    # CRITICAL: Use provider capabilities to determine continuous audio requirement
                    # Providers with native VAD (full agents) need continuous audio stream
                    # Pipeline providers use engine-side VAD (gated audio)
                    capabilities = None
                    if provider_caps_source and hasattr(provider_caps_source, 'get_capabilities'):
                        try:
                            capabilities = provider_caps_source.get_capabilities()
                        except Exception:
                            pass
                    
                    if capabilities and capabilities.requires_continuous_audio:
                        # Provider declares it needs continuous audio (e.g., for native VAD)
                        continuous_input = True
                    else:
                        # Fallback: check config for legacy providers
                        pcfg = getattr(provider, 'config', None)
                        if isinstance(pcfg, dict):
                            continuous_input = bool(pcfg.get('continuous_input', False))
                        else:
                            continuous_input = bool(getattr(pcfg, 'continuous_input', False))
                except Exception:
                    continuous_input = False
                # If provider supports continuous input, forward provider-encoded PCM immediately (during TTS guard)
                if continuous_input:
                    if not provider or not hasattr(provider, 'send_audio'):
                        if caller_channel_id not in self._provider_start_tasks and not getattr(session, "provider_session_active", False):
                            self._kickoff_provider_session_start(caller_channel_id)
                        return
                    if not getattr(session, "provider_session_active", False):
                        return
                    try:
                        # Diagnostics on the PCM payload we are about to send
                        self._update_audio_diagnostics(session, "provider_in", pcm_bytes, "slin16", pcm_rate)
                    except Exception:
                        logger.debug("Provider input diagnostics update failed (continuous-input)", call_id=caller_channel_id, exc_info=True)
                    try:
                        prov_payload, prov_enc, prov_rate = self._encode_for_provider(
                            session.call_id,
                            provider_name,
                            provider,
                            pcm_bytes,
                            pcm_rate,
                        )
                        try:
                            self.audio_capture.append_encoded(
                                session.call_id,
                                "caller_to_provider",
                                prov_payload,
                                prov_enc,
                                prov_rate,
                            )
                        except Exception:
                            logger.debug("Provider input capture failed (continuous-input)", call_id=session.call_id, exc_info=True)
                        # CRITICAL: Pass encoding and sample_rate to provider
                        # Google Live needs these to correctly interpret audio format
                        # Other providers with single-param signature will ignore extras
                        logger.debug(
                            "Sending audio to provider",
                            call_id=session.call_id,
                            provider=provider_name,
                            encoding=prov_enc,
                            sample_rate=prov_rate,
                            payload_bytes=len(prov_payload),
                        )
                        try:
                            await provider.send_audio(prov_payload, prov_rate, prov_enc)
                        except TypeError as e:
                            logger.warning(
                                "Provider send_audio TypeError - falling back to old signature",
                                call_id=session.call_id,
                                provider=provider_name,
                                error=str(e),
                            )
                            # Fallback for providers with old signature (audio_chunk only)
                            await provider.send_audio(prov_payload)
                    except Exception:
                        logger.debug("Provider continuous-input forward error", call_id=caller_channel_id, exc_info=True)
                    return
                # Protection window from TTS start to avoid initial self-echo (applies when not using continuous-input)
                now = time.time()
                tts_elapsed_ms = 0
                try:
                    if getattr(session, 'tts_started_ts', 0.0) > 0:
                        tts_elapsed_ms = int((now - session.tts_started_ts) * 1000)
                except Exception:
                    tts_elapsed_ms = 0
                initial_protect = int(getattr(cfg, 'initial_protection_ms', 200)) if cfg else 200
                
                # CRITICAL FIX #3: Extended protection for OpenAI Realtime (echo prevention)
                # OpenAI's VAD is highly sensitive and detects agent's own audio as "user speech"
                # This causes 20+ false speech_started events, creating response cancellation loop
                # 5 seconds ensures complete greeting plays before accepting any input
                # Other providers unaffected: Deepgram uses continuous_input path (line 2204 early return)
                # CRITICAL: Only apply if TTS has actually started (not during pre-TTS initialization)
                try:
                    if provider_name == "openai_realtime" and getattr(session, 'tts_started_ts', 0.0) > 0.0:
                        initial_protect = 5000  # 5 seconds to prevent echo feedback loop
                        logger.debug(
                            "Extended TTS protection for OpenAI Realtime (echo prevention)",
                            call_id=caller_channel_id,
                            protect_ms=initial_protect,
                            tts_started_ts=session.tts_started_ts
                        )
                except Exception:
                    pass
                
                # Greeting-specific extra protection
                try:
                    if getattr(session, 'conversation_state', None) == 'greeting' and cfg:
                        greet_ms = int(getattr(cfg, 'greeting_protection_ms', 0))
                        if greet_ms > initial_protect:
                            initial_protect = greet_ms
                except Exception:
                    pass
                if tts_elapsed_ms < initial_protect:
                    logger.debug("Dropping inbound during initial TTS protection window",
                                 conn_id=conn_id, caller_channel_id=caller_channel_id,
                                 tts_elapsed_ms=tts_elapsed_ms, protect_ms=initial_protect)
                    return
                # If barge-in disabled and no continuous-input path, drop
                if not cfg or not getattr(cfg, 'enabled', True):
                    logger.debug("Dropping inbound AudioSocket audio during TTS playback (barge-in disabled)",
                                 conn_id=conn_id, caller_channel_id=caller_channel_id, bytes=len(audio_bytes))
                    return
                # Barge-in detection: accumulate candidate window based on multi-criteria (VAD + energy)
                threshold = int(getattr(cfg, 'energy_threshold', 1000))
                frame_ms = 20
                energy = 0
                confidence = 0.0
                vad_speech = False
                webrtc_positive = False

                if vad_result:
                    frame_ms = max(vad_result.frame_duration_ms, 1)
                    energy = vad_result.energy_level
                    confidence = vad_result.confidence
                    vad_speech = vad_result.is_speech
                    webrtc_positive = vad_result.webrtc_result
                    try:
                        session.vad_state['last_vad_result'] = {
                            'is_speech': vad_speech,
                            'confidence': confidence,
                            'energy': energy,
                            'webrtc': webrtc_positive,
                        }
                    except Exception:
                        pass
                else:
                    try:
                        pcm16_frame = pcm_bytes
                        energy = audioop.rms(pcm16_frame, 2) if pcm16_frame else 0
                    except Exception:
                        energy = 0

                criteria_met = 0
                if vad_speech:
                    criteria_met += 1
                if energy >= threshold:
                    criteria_met += 1
                if vad_result and confidence >= getattr(self.vad_manager, 'confidence_threshold', 0.6):
                    criteria_met += 1
                if webrtc_positive:
                    criteria_met += 1

                if vad_result:
                    if criteria_met >= 2:
                        if int(getattr(session, 'barge_in_candidate_ms', 0)) == 0:
                            try:
                                session.barge_start_ts = now
                            except Exception:
                                session.barge_start_ts = 0.0
                        session.barge_in_candidate_ms = int(getattr(session, 'barge_in_candidate_ms', 0)) + frame_ms
                    else:
                        session.barge_in_candidate_ms = 0
                else:
                    if energy >= threshold:
                        if int(getattr(session, 'barge_in_candidate_ms', 0)) == 0:
                            try:
                                session.barge_start_ts = now
                            except Exception:
                                session.barge_start_ts = 0.0
                        session.barge_in_candidate_ms = int(getattr(session, 'barge_in_candidate_ms', 0)) + frame_ms
                    else:
                        session.barge_in_candidate_ms = 0

                # Cooldown check to avoid flapping
                cooldown_ms = int(getattr(cfg, 'cooldown_ms', 500))
                last_barge_in_ts = float(getattr(session, 'last_barge_in_ts', 0.0) or 0.0)
                in_cooldown = (now - last_barge_in_ts) * 1000 < cooldown_ms if last_barge_in_ts else False

                min_ms = int(getattr(cfg, 'min_ms', 250))
                should_trigger = not in_cooldown and session.barge_in_candidate_ms >= min_ms
                
                # CRITICAL FIX #2: Skip engine-level barge-in for OpenAI Realtime
                # OpenAI Realtime handles turn-taking/interruption internally via its own VAD
                # Engine-level barge-in causes double-cancellation (both systems fighting)
                provider_name = getattr(session, 'provider_name', None)
                if should_trigger and provider_name == 'openai_realtime':
                    logger.debug(
                        "Local barge-in detected for OpenAI Realtime - sending cancellation to server",
                        call_id=caller_channel_id,
                        energy=energy,
                        criteria_met=criteria_met,
                    )
                    # Notify OpenAI to cancel any in-progress response generation
                    try:
                        provider = self._call_providers.get(caller_channel_id)
                        if provider and hasattr(provider, 'cancel_response'):
                            await provider.cancel_response()
                    except Exception:
                        logger.debug("Failed to cancel OpenAI response", call_id=caller_channel_id, exc_info=True)
                    
                    # Reset candidate counter but don't trigger local playback stops
                    session.barge_in_candidate_ms = 0
                    # Continue forwarding audio to provider (OpenAI will handle the rest)
                    should_trigger = False

                if should_trigger:
                    # Trigger barge-in: flush local output and continue forwarding audio to provider
                    try:
                        # Observe reaction latency if we captured onset
                        try:
                            if float(getattr(session, 'barge_start_ts', 0.0) or 0.0) > 0.0:
                                reaction_s = max(0.0, now - float(session.barge_start_ts))
                                _BARGE_REACTION_SECONDS.observe(reaction_s)
                                session.barge_start_ts = 0.0
                        except Exception:
                            pass
                        await self._apply_barge_in_action(
                            caller_channel_id,
                            source="local_vad",
                            reason="tts_overlap",
                        )
                        
                        # Notify VAD manager of barge-in event for adaptive learning
                        if self.vad_manager and vad_result:
                            self.vad_manager.notify_call_event(
                                caller_channel_id, 
                                "barge_in", 
                                {"confidence": confidence, "energy": energy, "criteria_met": criteria_met}
                            )
                        
                        logger.info(
                            "ðŸŽ§ BARGE-IN triggered",
                            call_id=caller_channel_id,
                            energy=energy,
                            criteria_met=criteria_met,
                            confidence=confidence,
                            vad_speech=vad_speech,
                            webrtc=webrtc_positive,
                        )
                    except Exception:
                        logger.error("Error triggering barge-in", call_id=caller_channel_id, exc_info=True)
                    # After barge-in, fall through to forward this frame to provider
                else:
                    # Not yet triggered; drop inbound frame while TTS is active
                    if energy > 0 and self.conversation_coordinator:
                        try:
                            self.conversation_coordinator.note_audio_during_tts(caller_channel_id)
                        except Exception:
                            pass
                    logger.debug(
                        "Dropping inbound during TTS",
                        call_id=caller_channel_id,
                        candidate_ms=session.barge_in_candidate_ms,
                        energy=energy,
                        criteria_met=criteria_met,
                        confidence=confidence,
                    )
                    return

            # If pipeline execution is forced, route to pipeline queue after converting to PCM16 @ 16 kHz
            if self._pipeline_forced.get(caller_channel_id):
                q = self._pipeline_queues.get(caller_channel_id)
                if q:
                    try:
                        pcm16 = pcm_bytes
                        if pcm16 and pcm_rate != 16000:
                            try:
                                state = self._resample_state_pipeline16k.get(caller_channel_id)
                                pcm16, state = audioop.ratecv(pcm16, 2, 1, pcm_rate, 16000, state)
                                self._resample_state_pipeline16k[caller_channel_id] = state
                            except Exception:
                                pcm16 = pcm_bytes
                        if pcm16:
                            q.put_nowait(pcm16)
                        return
                    except asyncio.QueueFull:
                        logger.debug("Pipeline queue full; dropping AudioSocket frame", call_id=caller_channel_id)
                        return

            # Enhanced VAD Audio Filtering with continuous delivery
            forward_original_audio = True
            pcm_payload = pcm_bytes
            payload_rate = pcm_rate

            # Pre-guard RMS for instrumentation
            try:
                pre_guard_rms = audioop.rms(pcm_bytes, 2) if pcm_bytes else 0
            except Exception:
                pre_guard_rms = 0

            if vad_result:
                now = time.time()
                state = session.vad_state

                # Initialize VAD state if needed
                if 'vad_start_time' not in state:
                    state['vad_start_time'] = now
                    state['last_speech_time'] = now
                    state['frames_since_speech'] = 0

                frames_since_speech = int(state.get('frames_since_speech', 0))
                call_duration = now - float(state.get('vad_start_time', now))

                if call_duration >= 2.0:
                    forward_original_audio = (
                        vad_result.is_speech
                        or vad_result.confidence > 0.3
                        or frames_since_speech < 25
                        or self._should_use_vad_fallback(session)
                    )

                if vad_result.is_speech:
                    state['last_speech_time'] = now
                    state['frames_since_speech'] = 0
                else:
                    state['frames_since_speech'] = frames_since_speech + 1

                if not forward_original_audio:
                    # During greeting, avoid zeroing frames; allow audio to pass to provider
                    if getattr(session, 'conversation_state', None) == 'greeting':
                        pcm_payload = pcm_bytes
                        forward_original_audio = True
                    else:
                        silence_len = len(pcm_bytes) if pcm_bytes else len(audio_bytes) * 2
                        pcm_payload = b"\x00" * silence_len
                        logger.debug(
                            "ðŸŽ¤ VAD - Replacing frame with silence",
                            call_id=caller_channel_id,
                            confidence=f"{vad_result.confidence:.2f}",
                            energy=vad_result.energy_level,
                            is_speech=vad_result.is_speech,
                            frames_since_speech=state.get('frames_since_speech', 0),
                        )

            # Post-guard RMS instrumentation
            try:
                post_guard_rms = audioop.rms(pcm_payload, 2) if pcm_payload else 0
            except Exception:
                post_guard_rms = 0
            try:
                logger.info(
                    "Inbound PCM guard RMS",
                    call_id=caller_channel_id,
                    pre_guard_pcm_rms=pre_guard_rms,
                    post_guard_pcm_rms=post_guard_rms,
                )
            except Exception:
                pass

            # DEBUG: Audio routing state (OpenAI troubleshooting)
            provider_name = session.provider_name or self.config.default_provider
            if provider_name == "openai_realtime":
                logger.debug(
                    "ðŸŽ¤ AUDIO ROUTING - Ready to forward",
                    call_id=caller_channel_id,
                    audio_capture_enabled=getattr(session, 'audio_capture_enabled', None),
                    audio_bytes=len(audio_bytes),
                    pcm_payload_bytes=len(pcm_payload) if pcm_payload else 0,
                )
            
            provider = self._call_providers.get(caller_channel_id)
            if not provider:
                if caller_channel_id not in self._provider_start_tasks and not getattr(session, "provider_session_active", False):
                    self._kickoff_provider_session_start(caller_channel_id)
                return
            if not hasattr(provider, 'send_audio'):
                logger.warning(
                    "Provider missing send_audio method!",
                    provider_name=provider_name,
                    call_id=caller_channel_id,
                )
                return
            if not getattr(session, "provider_session_active", False):
                return
            
            # DEBUG: Provider ready check (OpenAI troubleshooting)
            if provider_name == "openai_realtime":
                logger.debug(
                    "ðŸŽ¤ AUDIO ROUTING - Provider ready",
                    call_id=caller_channel_id,
                    provider_name=provider_name,
                )
            try:
                self._update_audio_diagnostics(session, "provider_in", pcm_payload, "slin16", payload_rate)
            except Exception:
                logger.debug("Provider input diagnostics update failed", call_id=caller_channel_id, exc_info=True)

            provider_payload, provider_encoding, provider_rate = self._encode_for_provider(
                session.call_id,
                provider_name,
                provider,
                pcm_payload,
                payload_rate,
            )

            # Preserve original Î¼-law frames for Deepgram when the payload was replaced with silence
            if (
                provider_name == "deepgram"
                and provider_encoding in ("ulaw", "mulaw", "g711_ulaw", "mu-law")
                and provider_payload
                and not any(provider_payload)
            ):
                provider_payload = audio_bytes
                provider_rate = 8000
            try:
                self.audio_capture.append_encoded(
                    session.call_id,
                    "caller_to_provider",
                    provider_payload,
                    provider_encoding,
                    provider_rate,
                )
            except Exception:
                logger.debug("Provider input capture failed", call_id=session.call_id, exc_info=True)
            await provider.send_audio(provider_payload)
            
            # DEBUG: Confirm audio sent (OpenAI troubleshooting)
            if provider_name == "openai_realtime":
                logger.debug(
                    "ðŸŽ¤ AUDIO ROUTING - Sent to provider",
                    call_id=caller_channel_id,
                    provider_name=provider_name,
                    bytes_sent=len(provider_payload) if provider_payload else 0,
                )
        except Exception as exc:
            logger.error("Error handling AudioSocket audio", conn_id=conn_id, error=str(exc), exc_info=True)

    async def _run_enhanced_vad(self, session: CallSession, audio_bytes: bytes) -> Optional[VADResult]:
        """Normalize inbound AudioSocket audio to PCM16 @ 8 kHz 20 ms frames and run enhanced VAD."""
        if not self.vad_manager or not audio_bytes:
            return None

        try:
            # Detect AudioSocket wire format from session first (actual negotiated),
            # then fall back to YAML. Map 'slin' (Asterisk) to PCM16 @ 8 kHz.
            try:
                fmt_token = (session.transport_profile.format or '').lower()
            except Exception:
                fmt_token = ''
            if not fmt_token:
                try:
                    fmt_token = (getattr(self.config, 'audiosocket', None).format or 'ulaw').lower()
                except Exception:
                    fmt_token = 'ulaw'

            # Determine source rate preference from session profile when available
            try:
                prof_rate = int(session.transport_profile.sample_rate or 0)
            except Exception:
                prof_rate = 0

            if fmt_token in ('ulaw', 'mulaw', 'g711_ulaw', 'mu-law'):
                pcm_src = EnhancedVADManager.mu_law_to_pcm16(audio_bytes)
                src_rate = 8000
            elif fmt_token in ('slin', 'slin8', 'linear16_8k', 'pcm16_8k'):
                # Asterisk 'slin' is 8 kHz PCM16
                pcm_src = audio_bytes
                src_rate = 8000
            else:
                # Generic PCM16: prefer session sample rate, default to 16000 only if unknown
                pcm_src = audio_bytes
                src_rate = prof_rate if prof_rate > 0 else 16000
                # Normalize endian if probe indicated swap
                try:
                    if bool(session.vad_state.get('pcm16_inbound_swap', False)):
                        pcm_src = audioop.byteswap(pcm_src, 2)
                except Exception:
                    pass
            if src_rate != 8000:
                try:
                    state = self._resample_state_vad8k.get(session.call_id)
                    pcm16, state = audioop.ratecv(pcm_src, 2, 1, src_rate, 8000, state)
                    self._resample_state_vad8k[session.call_id] = state
                except Exception:
                    pcm16 = pcm_src
            else:
                pcm16 = pcm_src
        except Exception:
            logger.debug(
                "Enhanced VAD conversion failed",
                call_id=session.call_id,
                exc_info=True,
            )
            return None

        if not pcm16:
            return None

        vad_state = session.vad_state.setdefault("enhanced_vad", {})
        frame_buffer: bytearray = vad_state.setdefault("frame_buffer", bytearray())
        frame_buffer.extend(pcm16)

        result: Optional[VADResult] = None
        stats = vad_state.setdefault("stats", {"frames": 0, "speech_frames": 0})

        while len(frame_buffer) >= 320:
            frame = bytes(frame_buffer[:320])
            del frame_buffer[:320]
            result = await self.vad_manager.process_frame(session.call_id, frame)
            stats["frames"] = stats.get("frames", 0) + 1
            if result.is_speech:
                stats["speech_frames"] = stats.get("speech_frames", 0) + 1

        if result:
            try:
                total = max(stats.get("frames", 0), 1)
                speech_ratio = stats.get("speech_frames", 0) / total
                session.vad_state["enhanced_summary"] = {
                    "frames": stats.get("frames", 0),
                    "speech_frames": stats.get("speech_frames", 0),
                    "speech_ratio": speech_ratio,
                    "last_confidence": result.confidence,
                    "last_energy": result.energy_level,
                }
            except Exception:
                pass

        return result

    async def _run_enhanced_vad_pcm16(self, session: CallSession, pcm16_bytes: bytes, src_rate_hz: int) -> Optional[VADResult]:
        """Run enhanced VAD on known PCM16 input (used by ExternalMedia RTP path)."""
        if not self.vad_manager or not pcm16_bytes:
            return None

        try:
            src_rate = int(src_rate_hz or 0) or 16000
        except Exception:
            src_rate = 16000

        try:
            if src_rate != 8000:
                state = self._resample_state_vad8k.get(session.call_id)
                pcm16_8k, state = audioop.ratecv(pcm16_bytes, 2, 1, src_rate, 8000, state)
                self._resample_state_vad8k[session.call_id] = state
            else:
                pcm16_8k = pcm16_bytes
        except Exception:
            pcm16_8k = pcm16_bytes

        if not pcm16_8k:
            return None

        vad_state = session.vad_state.setdefault("enhanced_vad", {})
        frame_buffer: bytearray = vad_state.setdefault("frame_buffer", bytearray())
        frame_buffer.extend(pcm16_8k)

        result: Optional[VADResult] = None
        stats = vad_state.setdefault("stats", {"frames": 0, "speech_frames": 0})

        while len(frame_buffer) >= 320:
            frame = bytes(frame_buffer[:320])
            del frame_buffer[:320]
            result = await self.vad_manager.process_frame(session.call_id, frame)
            stats["frames"] = stats.get("frames", 0) + 1
            if result.is_speech:
                stats["speech_frames"] = stats.get("speech_frames", 0) + 1

        if result:
            try:
                total = max(stats.get("frames", 0), 1)
                speech_ratio = stats.get("speech_frames", 0) / total
                session.vad_state["enhanced_summary"] = {
                    "frames": stats.get("frames", 0),
                    "speech_frames": stats.get("speech_frames", 0),
                    "speech_ratio": speech_ratio,
                    "last_confidence": result.confidence,
                    "last_energy": result.energy_level,
                }
            except Exception:
                pass

        return result

    async def _is_inbound_isolated_for_barge_in_fallback(self, session: CallSession) -> bool:
        """Best-effort check that inbound audio is caller-isolated (safe to run local VAD for barge-in)."""
        try:
            import time

            now = time.time()
            state = session.vad_state.setdefault("barge_in_fallback", {})
            last_ts = float(state.get("iso_check_ts", 0.0) or 0.0)
            # Cache for 200ms to avoid per-frame lock contention in SessionStore.
            if last_ts and (now - last_ts) < 0.2:
                return bool(state.get("iso_ok", False))

            playback_ids = []
            try:
                playback_ids = await self.session_store.list_playbacks_for_call(session.call_id)
            except Exception:
                playback_ids = []

            has_playback = bool(playback_ids)
            has_bridge_moh = False
            try:
                mid = getattr(session, "music_snoop_channel_id", None)
                has_bridge_moh = bool(mid and str(mid).startswith("bridge-moh:"))
            except Exception:
                has_bridge_moh = False

            ok = (not has_playback) and (not has_bridge_moh)
            state["iso_check_ts"] = now
            state["iso_ok"] = ok
            state["iso_has_playback"] = has_playback
            state["iso_has_bridge_moh"] = has_bridge_moh
            return ok
        except Exception:
            return False

    async def _maybe_provider_barge_in_fallback(
        self,
        session: CallSession,
        *,
        pcm16: bytes,
        pcm_rate_hz: int,
        audiosocket_wire: Optional[bytes],
        source: str,
    ) -> None:
        """Local VAD fallback for provider-owned mode (flush-only, no provider cancellation)."""
        try:
            cfg = getattr(self.config, "barge_in", None)
            if not cfg or not bool(getattr(cfg, "enabled", True)):
                return
            if not bool(getattr(cfg, "provider_fallback_enabled", True)):
                return

            call_id = session.call_id
            provider_name = getattr(session, "provider_name", None) or getattr(self.config, "default_provider", "")
            allow = set((getattr(cfg, "provider_fallback_providers", None) or []) or [])
            if allow and provider_name not in allow:
                return

            # Only relevant while streaming playback is active (agent is speaking).
            try:
                if not self.streaming_playback_manager.is_stream_active(call_id):
                    return
            except Exception:
                return

            # Only when inbound media path is confirmed.
            if not bool(getattr(session, "media_rx_confirmed", False)):
                return

            # Only when we can reasonably assume inbound is caller-isolated.
            if not await self._is_inbound_isolated_for_barge_in_fallback(session):
                return

            import time

            now = time.time()
            vad_result: Optional[VADResult] = None
            if self.vad_manager:
                try:
                    if source == "audiosocket":
                        vad_result = await self._run_enhanced_vad(session, audiosocket_wire or b"")
                    else:
                        vad_result = await self._run_enhanced_vad_pcm16(session, pcm16, int(pcm_rate_hz or 0) or 16000)
                except Exception:
                    vad_result = None

            # Energy fallback
            try:
                energy = int(vad_result.energy_level) if vad_result else int(audioop.rms(pcm16, 2) if pcm16 else 0)
            except Exception:
                energy = 0

            frame_ms = 20
            confidence = 0.0
            vad_speech = False
            webrtc_positive = False
            if vad_result:
                frame_ms = max(int(getattr(vad_result, "frame_duration_ms", 20) or 20), 1)
                confidence = float(getattr(vad_result, "confidence", 0.0) or 0.0)
                vad_speech = bool(getattr(vad_result, "is_speech", False))
                webrtc_positive = bool(getattr(vad_result, "webrtc_result", False))

            threshold = int(getattr(cfg, "energy_threshold", 1000))
            criteria_met = 0
            if vad_speech:
                criteria_met += 1
            if energy >= threshold:
                criteria_met += 1
            try:
                if vad_result and confidence >= float(getattr(self.vad_manager, "confidence_threshold", 0.6)):
                    criteria_met += 1
            except Exception:
                pass
            if webrtc_positive:
                criteria_met += 1

            # In provider-fallback mode, require energy above threshold to avoid false positives on near-silence
            # (webrtc-vad can occasionally fire "speech" on low-energy telephony noise).
            if energy < threshold:
                session.barge_in_candidate_ms = 0
                return

            if criteria_met >= (2 if vad_result else 1):
                if int(getattr(session, "barge_in_candidate_ms", 0) or 0) == 0:
                    session.barge_start_ts = now
                session.barge_in_candidate_ms = int(getattr(session, "barge_in_candidate_ms", 0) or 0) + frame_ms
            else:
                session.barge_in_candidate_ms = 0

            # If a barge-in already happened (output suppression active), keep suppression alive while caller speaks.
            try:
                sup = session.vad_state.get("output_suppression") or {}
                until_ts = float(sup.get("until_ts", 0.0) or 0.0)
                # Only extend on real speech energy (avoid prolonging suppression on silence).
                if until_ts > now and energy >= threshold:
                    extend_ms = int(getattr(cfg, "provider_output_suppress_extend_ms", 600))
                    sup["until_ts"] = max(until_ts, now + (extend_ms / 1000.0))
                    sup["active"] = True
                    session.vad_state["output_suppression"] = sup
            except Exception:
                pass

            cooldown_ms = int(getattr(cfg, "cooldown_ms", 500))
            last_barge_in_ts = float(getattr(session, "last_barge_in_ts", 0.0) or 0.0)
            in_cooldown = (now - last_barge_in_ts) * 1000 < cooldown_ms if last_barge_in_ts else False

            min_ms = int(getattr(cfg, "min_ms", 250))
            should_trigger = (not in_cooldown) and (int(getattr(session, "barge_in_candidate_ms", 0) or 0) >= min_ms)
            if not should_trigger:
                return

            try:
                if float(getattr(session, "barge_start_ts", 0.0) or 0.0) > 0.0:
                    reaction_s = max(0.0, now - float(session.barge_start_ts))
                    _BARGE_REACTION_SECONDS.observe(reaction_s)
                    session.barge_start_ts = 0.0
            except Exception:
                pass

            await self._apply_barge_in_action(
                call_id,
                source="local_vad_fallback",
                reason=f"{provider_name}:{source}",
            )
            logger.info(
                "ðŸŽ§ BARGE-IN (provider fallback) triggered",
                call_id=call_id,
                provider=provider_name,
                source=source,
                energy=energy,
                criteria_met=criteria_met,
                confidence=round(confidence, 3),
            )
        except Exception:
            logger.debug("Provider barge-in fallback failed", call_id=getattr(session, "call_id", None), exc_info=True)

    def _should_use_vad_fallback(self, session: CallSession) -> bool:
        """Determine if we should use fallback audio forwarding when VAD doesn't detect speech."""
        try:
            vad_config = getattr(self.config, 'vad', None)
            if not vad_config or not getattr(vad_config, 'fallback_enabled', True):
                return False
            
            now = time.time()
            last_speech_time = session.vad_state.get('last_speech_time')
            if not last_speech_time:
                session.vad_state['last_speech_time'] = now
                return False

            silence_duration = (now - float(last_speech_time)) * 1000
            fallback_interval = getattr(vad_config, 'fallback_interval_ms', 1500)
            if silence_duration < fallback_interval:
                return False

            fallback_state = session.vad_state.setdefault('fallback_state', {
                'last_fallback_ts': 0.0,
            })

            last_fallback_ts = float(fallback_state.get('last_fallback_ts', 0.0) or 0.0)
            fallback_period_ms = 200  # Forward real audio every 200 ms during extended silence

            if (now - last_fallback_ts) * 1000 >= fallback_period_ms:
                fallback_state['last_fallback_ts'] = now
                logger.debug(
                    "ðŸŽ¤ VAD - Periodic fallback forwarding original audio",
                    call_id=session.call_id,
                    silence_duration_ms=int(silence_duration),
                    fallback_interval_ms=fallback_interval,
                )
                return True

            return False
            
        except Exception as e:
            logger.debug("VAD fallback logic error", call_id=session.call_id, error=str(e))
            return True  # Default to allowing audio through on error

    @staticmethod
    def _ulaw_silence(length: int) -> bytes:
        if length <= 0:
            return b""
        return bytes([0xFF]) * length

    def _silence_for_format(self, length: int) -> bytes:
        """Generate silence matching the negotiated AudioSocket format (Î¼-law or PCM16)."""
        if length <= 0:
            return b""
        try:
            as_fmt = (getattr(self.config, 'audiosocket', None).format or 'ulaw').lower()
        except Exception:
            as_fmt = 'ulaw'
        if as_fmt in ('ulaw', 'mulaw', 'g711_ulaw', 'mu-law'):
            return bytes([0xFF]) * length  # Î¼-law silence
        return b"\x00" * length  # PCM16 silence (zeroed samples)

    async def _apply_barge_in_action(self, call_id: str, *, source: str, reason: str) -> None:
        """Apply platform-owned barge-in actions (flush local output only).

        Contract (Option 2):
        - Stop/flush local playback immediately (stream + ARI playback).
        - Do NOT stop provider sessions or pause inbound audio to providers.
        - Gate on first inbound audio frame so we don't trigger during setup.
        """
        try:
            session = await self.session_store.get_by_call_id(call_id)
            if not session:
                return

            if not bool(getattr(session, "media_rx_confirmed", False)):
                logger.debug(
                    "Barge-in ignored (media not confirmed)",
                    call_id=call_id,
                    source=source,
                    reason=reason,
                )
                return

            # Stop/flush streaming playback first (prevents tail audio).
            try:
                await self.streaming_playback_manager.stop_streaming_playback(call_id)
            except Exception:
                logger.debug("Streaming playback stop failed during barge-in", call_id=call_id, exc_info=True)
            # Ensure subsequent provider audio can restart playback cleanly.
            # If we keep the old queue, on_provider_event will continue enqueueing but never restart streaming.
            try:
                self._provider_stream_queues.pop(call_id, None)
                self._provider_stream_formats.pop(call_id, None)
                self._provider_coalesce_buf.pop(call_id, None)
            except Exception:
                logger.debug("Failed to clear provider stream buffers during barge-in", call_id=call_id, exc_info=True)

            # Stop any active ARI playbacks (file playback and edge cases).
            try:
                playback_ids = await self.session_store.list_playbacks_for_call(call_id)
                for pid in playback_ids:
                    try:
                        await self.ari_client.stop_playback(pid)
                    except Exception:
                        logger.debug("Playback stop error during barge-in", playback_id=pid, exc_info=True)
            except Exception:
                logger.debug("Failed to enumerate playbacks during barge-in", call_id=call_id, exc_info=True)

            # Clear any platform gating tokens (pipelines/file playback only).
            try:
                tokens = list(getattr(session, "tts_tokens", set()) or [])
                for token in tokens:
                    try:
                        if self.conversation_coordinator:
                            await self.conversation_coordinator.on_tts_end(call_id, token, reason="barge-in")
                        else:
                            await self.session_store.clear_gating_token(call_id, token)
                    except Exception:
                        logger.debug("Failed to clear gating token during barge-in", token=token, exc_info=True)
            except Exception:
                logger.debug("Failed to clear gating tokens during barge-in", call_id=call_id, exc_info=True)

            # Reset candidate window and record observability.
            try:
                import time
                now = time.time()
                session.barge_in_candidate_ms = 0
                session.last_barge_in_ts = now
                session.barge_in_count = int(getattr(session, "barge_in_count", 0) or 0) + 1
                session.audio_diagnostics["barge_in_last_source"] = source
                session.audio_diagnostics["barge_in_last_reason"] = reason
                session.audio_diagnostics["barge_in_last_ts"] = float(session.last_barge_in_ts)

                # Provider-owned mode: suppress outbound provider audio briefly so flush isn't immediately undone
                # by continued provider streaming of the previous sentence.
                try:
                    cfg = getattr(self.config, "barge_in", None)
                    suppress_ms = int(getattr(cfg, "provider_output_suppress_ms", 0)) if cfg else 0
                    if suppress_ms > 0:
                        sup = session.vad_state.setdefault("output_suppression", {})
                        prev_until = float(sup.get("until_ts", 0.0) or 0.0)
                        until_ts = max(prev_until, now + (suppress_ms / 1000.0))
                        sup["until_ts"] = until_ts
                        sup["active"] = True
                        sup["source"] = source
                        sup["reason"] = reason
                        sup["set_ts"] = now
                except Exception:
                    logger.debug("Failed to set output suppression during barge-in", call_id=call_id, exc_info=True)
                await self._save_session(session)
            except Exception:
                logger.debug("Failed to record barge-in state", call_id=call_id, exc_info=True)

            logger.info("ðŸŽ§ BARGE-IN action applied", call_id=call_id, source=source, reason=reason)
        except Exception:
            logger.error("Barge-in action failed", call_id=call_id, source=source, reason=reason, exc_info=True)

    async def _export_config_metrics(self, call_id: str) -> None:
        """Expose configured knobs as Prometheus gauges (aggregate, no per-call labels)."""
        try:
            b = getattr(self.config, 'barge_in', None)
            if b:
                _CFG_BARGE_MS.labels("initial_protection_ms").set(int(getattr(b, 'initial_protection_ms', 0)))
                _CFG_BARGE_MS.labels("min_ms").set(int(getattr(b, 'min_ms', 0)))
                _CFG_BARGE_MS.labels("post_tts_end_protection_ms").set(int(getattr(b, 'post_tts_end_protection_ms', 0)))
                _CFG_BARGE_MS.labels("greeting_protection_ms").set(int(getattr(b, 'greeting_protection_ms', 0)))
                _CFG_BARGE_THRESHOLD.set(int(getattr(b, 'energy_threshold', 0)))
        except Exception:
            pass
        try:
            s = getattr(self.config, 'streaming', None)
            if s:
                _CFG_STREAM_MS.labels("min_start_ms").set(int(getattr(s, 'min_start_ms', 0)))
                _CFG_STREAM_MS.labels("greeting_min_start_ms").set(int(getattr(s, 'greeting_min_start_ms', 0)))
                _CFG_STREAM_MS.labels("low_watermark_ms").set(int(getattr(s, 'low_watermark_ms', 0)))
                _CFG_STREAM_MS.labels("jitter_buffer_ms").set(int(getattr(s, 'jitter_buffer_ms', 0)))
                _CFG_STREAM_MS.labels("fallback_timeout_ms").set(int(getattr(s, 'fallback_timeout_ms', 0)))
        except Exception:
            pass
        try:
            pblock = (getattr(self.config, 'providers', {}) or {}).get('openai_realtime', {})
            td = (pblock or {}).get('turn_detection') or {}
            if td:
                _CFG_TD_MS.labels("silence_duration_ms").set(int(td.get('silence_duration_ms', 0)))
                _CFG_TD_MS.labels("prefix_padding_ms").set(int(td.get('prefix_padding_ms', 0)))
                try:
                    _CFG_TD_THRESHOLD.set(float(td.get('threshold', 0.0)))
                except Exception:
                    pass
        except Exception:
            pass

    async def _audiosocket_handle_disconnect(self, conn_id: str) -> None:
        """Cleanup mappings when an AudioSocket connection disconnects."""
        try:
            caller_channel_id = self.conn_to_channel.pop(conn_id, None)
            if caller_channel_id:
                conns = self.channel_to_conns.get(caller_channel_id, set())
                conns.discard(conn_id)
                if not conns:
                    self.channel_to_conns.pop(caller_channel_id, None)
                # Reset primary if needed
                if self.audiosocket_primary_conn.get(caller_channel_id) == conn_id:
                    self.audiosocket_primary_conn.pop(caller_channel_id, None)
                    if conns:
                        self.audiosocket_primary_conn[caller_channel_id] = next(iter(conns))
                # Clear audiosocket_conn_id on session if it matched
                try:
                    sess = await self.session_store.get_by_call_id(caller_channel_id)
                    if sess and getattr(sess, 'audiosocket_conn_id', None) == conn_id:
                        sess.audiosocket_conn_id = None
                        await self._save_session(sess)
                except Exception:
                    pass
            logger.info("AudioSocket connection disconnected", conn_id=conn_id, caller_channel_id=caller_channel_id)
        except Exception as exc:
            logger.error("Error during AudioSocket disconnect cleanup", conn_id=conn_id, error=str(exc), exc_info=True)

    async def _audiosocket_handle_dtmf(self, conn_id: str, digit: str) -> None:
        """Handle DTMF received over AudioSocket (informational)."""
        try:
            caller_channel_id = self.conn_to_channel.get(conn_id)
            logger.info("AudioSocket DTMF received", conn_id=conn_id, caller_channel_id=caller_channel_id, digit=digit)
        except Exception as exc:
            logger.error("Error handling AudioSocket DTMF", conn_id=conn_id, error=str(exc), exc_info=True)

    async def _on_rtp_audio(self, caller_channel_id: str, ssrc: int, pcm_16k: bytes) -> None:
        """Route inbound ExternalMedia RTP audio to the active provider.

        IMPORTANT: `caller_channel_id` must be provided by RTPServer (per-session context).
        Do not infer SSRCâ†’call mappings in the engine; that is not concurrency-safe.
        """
        try:
            session = await self.session_store.get_by_call_id(caller_channel_id)
            if not session:
                logger.debug(
                    "No session for call; dropping RTP audio",
                    caller_channel_id=caller_channel_id,
                    ssrc=ssrc,
                    bytes=len(pcm_16k),
                )
                return

            # Record SSRC on the session for diagnostics (RTPServer maintains SSRC mapping internally).
            try:
                if not getattr(session, "ssrc", None):
                    session.ssrc = ssrc
                    await self._save_session(session)
            except Exception:
                pass

            # Media-path confirmation: first inbound audio frame observed.
            # Used to gate barge-in actions so we don't trigger during setup races.
            try:
                if not bool(getattr(session, "media_rx_confirmed", False)):
                    session.media_rx_confirmed = True
                    session.first_media_rx_ts = time.time()
                    await self._save_session(session)
                    logger.info("Media RX confirmed (ExternalMedia)", call_id=caller_channel_id)
            except Exception:
                logger.debug("Failed to set media_rx_confirmed (ExternalMedia)", call_id=caller_channel_id, exc_info=True)

            # Check for pipeline mode FIRST (before continuous_input provider routing)
            # Pipeline adapters need audio in their queue, not sent to monolithic providers
            pipeline_forced = self._pipeline_forced.get(caller_channel_id)
            logger.debug(
                "RTP audio routing check",
                call_id=caller_channel_id,
                pipeline_forced=pipeline_forced,
                audio_capture_enabled=session.audio_capture_enabled,
                has_queue=caller_channel_id in self._pipeline_queues,
            )
            if pipeline_forced:
                # AAVA-28: Check gating to prevent agent from hearing its own TTS output
                if not session.audio_capture_enabled:
                    # Pipelines: allow barge-in detection during TTS gating, but do not forward audio until triggered.
                    cfg = getattr(self.config, "barge_in", None)
                    if not cfg or not getattr(cfg, "enabled", True):
                        return
                    # If TALK_DETECT is enabled for this pipeline, prefer it over local energy checks.
                    try:
                        td = (session.vad_state or {}).get("pipeline_talk_detect", {}) or {}
                        if bool(td.get("enabled", False)):
                            return
                    except Exception:
                        pass
                    now = time.time()
                    tts_elapsed_ms = 0
                    try:
                        if getattr(session, "tts_started_ts", 0.0) > 0:
                            tts_elapsed_ms = int((now - float(session.tts_started_ts)) * 1000)
                    except Exception:
                        tts_elapsed_ms = 0
                    initial_protect = int(getattr(cfg, "initial_protection_ms", 200))
                    try:
                        if getattr(session, "conversation_state", None) == "greeting":
                            greet_ms = int(getattr(cfg, "greeting_protection_ms", 0))
                            if greet_ms > initial_protect:
                                initial_protect = greet_ms
                    except Exception:
                        pass
                    if tts_elapsed_ms < initial_protect:
                        return
                    try:
                        energy = audioop.rms(pcm_16k, 2)
                    except Exception:
                        energy = 0
                    threshold = int(getattr(cfg, "pipeline_energy_threshold", 0) or getattr(cfg, "energy_threshold", 1000))
                    frame_ms = 20
                    if energy >= threshold:
                        if int(getattr(session, "barge_in_candidate_ms", 0)) == 0:
                            try:
                                session.barge_start_ts = now
                            except Exception:
                                session.barge_start_ts = 0.0
                        session.barge_in_candidate_ms = int(getattr(session, "barge_in_candidate_ms", 0)) + frame_ms
                    else:
                        session.barge_in_candidate_ms = 0

                    # Debug monitor (rate-limited) so we can see why pipeline barge-in is/isn't firing.
                    try:
                        mon = session.vad_state.setdefault("pipeline_barge_mon", {})
                        last = float(mon.get("last_ts", 0.0) or 0.0)
                        if now - last >= 1.0:
                            mon["last_ts"] = now
                            logger.debug(
                                "Pipeline barge-in monitor (RTP)",
                                call_id=caller_channel_id,
                                tts_elapsed_ms=tts_elapsed_ms,
                                energy=energy,
                                threshold=threshold,
                                candidate_ms=int(getattr(session, "barge_in_candidate_ms", 0) or 0),
                                audio_capture_enabled=session.audio_capture_enabled,
                            )
                    except Exception:
                        pass

                    cooldown_ms = int(getattr(cfg, "cooldown_ms", 500))
                    last_barge_in_ts = float(getattr(session, "last_barge_in_ts", 0.0) or 0.0)
                    in_cooldown = (now - last_barge_in_ts) * 1000 < cooldown_ms if last_barge_in_ts else False
                    min_ms = int(getattr(cfg, "pipeline_min_ms", 0) or getattr(cfg, "min_ms", 250))
                    if not in_cooldown and int(getattr(session, "barge_in_candidate_ms", 0)) >= min_ms:
                        try:
                            try:
                                if float(getattr(session, "barge_start_ts", 0.0) or 0.0) > 0.0:
                                    reaction_s = max(0.0, now - float(session.barge_start_ts))
                                    _BARGE_REACTION_SECONDS.observe(reaction_s)
                                    session.barge_start_ts = 0.0
                            except Exception:
                                pass
                            await self._apply_barge_in_action(
                                caller_channel_id,
                                source="local_vad",
                                reason="pipeline_tts_overlap",
                            )
                            session.audio_capture_enabled = True
                            logger.info("ðŸŽ§ BARGE-IN (RTP/pipeline) triggered", call_id=caller_channel_id)
                        except Exception:
                            logger.error("Error triggering RTP pipeline barge-in", call_id=caller_channel_id, exc_info=True)
                    else:
                        if energy > 0 and self.conversation_coordinator:
                            try:
                                self.conversation_coordinator.note_audio_during_tts(caller_channel_id)
                            except Exception:
                                pass
                        return
                
                q = self._pipeline_queues.get(caller_channel_id)
                if q:
                    try:
                        q.put_nowait(pcm_16k)  # Pipeline expects PCM16@16kHz
                        logger.debug("RTP audio routed to pipeline queue", call_id=caller_channel_id, bytes=len(pcm_16k))
                    except Exception as exc:
                        logger.warning("Pipeline queue full or unavailable (RTP)", call_id=caller_channel_id, error=str(exc))
                    return  # Done - don't route to monolithic provider
                else:
                    logger.warning("Pipeline mode active but no queue found (RTP)", call_id=caller_channel_id)

            # Check if provider requires continuous audio input using capabilities
            # Full agents with native VAD need uninterrupted audio flow for turn-taking
            provider_name = getattr(session, 'provider_name', None) or self.config.default_provider
            provider = self._call_providers.get(caller_channel_id)
            provider_caps_source = provider or self.providers.get(provider_name)
            continuous_input = False
            try:
                capabilities = None
                if provider_caps_source and hasattr(provider_caps_source, 'get_capabilities'):
                    try:
                        capabilities = provider_caps_source.get_capabilities()
                    except Exception:
                        pass
                
                if capabilities and capabilities.requires_continuous_audio:
                    continuous_input = True
                else:
                    pcfg = getattr(provider_caps_source, 'config', None)
                    if isinstance(pcfg, dict):
                        continuous_input = bool(pcfg.get('continuous_input', False))
                    else:
                        continuous_input = bool(getattr(pcfg, 'continuous_input', False))
            except Exception:
                continuous_input = False

            # For continuous-input providers, forward audio (but respect gating during TTS playback)
            # OpenAI Realtime has server-side echo cancellation, but we still need to gate during TTS
            # to prevent the provider from hearing its own audio as "user speech"
            if continuous_input:
                if not provider or not hasattr(provider, 'send_audio'):
                    if caller_channel_id not in self._provider_start_tasks and not getattr(session, "provider_session_active", False):
                        self._kickoff_provider_session_start(caller_channel_id)
                    return
                
                # Preserve original inbound audio for local barge-in fallback checks (never run VAD on silence-substituted frames).
                pcm_for_barge_in = pcm_16k

                # CRITICAL: Check if audio capture is disabled (TTS playing)
                # For Google Live: Send silence frames to maintain stream continuity (like AudioSocket)
                # For OpenAI/Deepgram: Can drop audio (they handle gaps gracefully)
                needs_gating = provider_name == "google_live"
                
                if needs_gating and not session.audio_capture_enabled:
                    # Send SILENCE instead of dropping to maintain Google Live's stream
                    logger.debug(
                        "ðŸ”‡ GATING ACTIVE - Sending silence frame for Google Live (TTS playing)",
                        call_id=caller_channel_id,
                        provider=provider_name,
                    )
                    # Replace audio with silence (zero-filled PCM16)
                    pcm_16k = b'\x00' * len(pcm_16k)
                elif not needs_gating and not session.audio_capture_enabled:
                    # For other providers, can safely drop audio during TTS
                    logger.debug(
                        "Dropping RTP audio for continuous provider during TTS playback",
                        call_id=caller_channel_id,
                        provider=provider_name,
                    )
                    return
                if not getattr(session, "provider_session_active", False):
                    return
                # Encode audio for provider (same as AudioSocket path)
                try:
                    # Get RTP server's configured sample rate (no longer hardcoded)
                    rtp_rate = getattr(self.rtp_server, 'sample_rate', 16000) if self.rtp_server else 16000
                    
                    prov_payload, prov_enc, prov_rate = self._encode_for_provider(
                        session.call_id,
                        provider_name,
                        provider,
                        pcm_16k,
                        rtp_rate,  # Use configured rate from RTP server
                    )
                    try:
                        self.audio_capture.append_encoded(
                            session.call_id,
                            "caller_to_provider",
                            prov_payload,
                            prov_enc,
                            prov_rate,
                        )
                    except Exception:
                        logger.debug("Provider input capture failed (continuous-input RTP)", call_id=session.call_id, exc_info=True)
                    # CRITICAL: Pass sample_rate and encoding to provider
                    # Google Live needs these to avoid double resampling
                    await provider.send_audio(prov_payload, sample_rate=prov_rate, encoding=prov_enc)
                except Exception as exc:
                    logger.debug("Continuous-input RTP forward error", call_id=caller_channel_id, error=str(exc))

                # Provider-owned mode: local VAD fallback may flush local output (never cancels provider).
                try:
                    await self._maybe_provider_barge_in_fallback(
                        session,
                        pcm16=pcm_for_barge_in,
                        pcm_rate_hz=int(getattr(self.rtp_server, 'sample_rate', 16000) if self.rtp_server else 16000),
                        audiosocket_wire=None,
                        source="externalmedia",
                    )
                except Exception:
                    logger.debug("Provider barge-in fallback check failed (ExternalMedia/continuous)", call_id=caller_channel_id, exc_info=True)
                return

            # Below: standard gating/barge-in logic for hybrid (P2) providers only
            
            # Post-TTS end guard to avoid self-echo re-capture
            try:
                cfg = getattr(self.config, 'barge_in', None)
                post_guard_ms = int(getattr(cfg, 'post_tts_end_protection_ms', 0)) if cfg else 0
            except Exception:
                post_guard_ms = 0
            if post_guard_ms and getattr(session, 'tts_ended_ts', 0.0) and session.audio_capture_enabled:
                try:
                    elapsed_ms = int((time.time() - float(session.tts_ended_ts)) * 1000)
                except Exception:
                    elapsed_ms = post_guard_ms
                if elapsed_ms < post_guard_ms:
                    logger.debug(
                        "Dropping inbound RTP during post-TTS protection window",
                        call_id=caller_channel_id,
                        elapsed_ms=elapsed_ms,
                        protect_ms=post_guard_ms,
                    )
                    return

            # If TTS is playing (capture disabled), decide whether to drop or barge-in
            if hasattr(session, 'audio_capture_enabled') and not session.audio_capture_enabled:
                cfg = getattr(self.config, 'barge_in', None)
                if not cfg or not getattr(cfg, 'enabled', True):
                    logger.debug("Dropping inbound RTP during TTS playback (barge-in disabled)",
                                 ssrc=ssrc, caller_channel_id=caller_channel_id, bytes=len(pcm_16k))
                    return

                now = time.time()
                tts_elapsed_ms = 0
                try:
                    if getattr(session, 'tts_started_ts', 0.0) > 0:
                        tts_elapsed_ms = int((now - session.tts_started_ts) * 1000)
                except Exception:
                    tts_elapsed_ms = 0

                initial_protect = int(getattr(cfg, 'initial_protection_ms', 200))
                try:
                    if getattr(session, 'conversation_state', None) == 'greeting':
                        greet_ms = int(getattr(cfg, 'greeting_protection_ms', 0))
                        if greet_ms > initial_protect:
                            initial_protect = greet_ms
                except Exception:
                    pass
                if tts_elapsed_ms < initial_protect:
                    logger.debug("Dropping inbound RTP during initial TTS protection window",
                                 ssrc=ssrc, caller_channel_id=caller_channel_id,
                                 tts_elapsed_ms=tts_elapsed_ms, protect_ms=initial_protect)
                    return

                # Barge-in detection on PCM16 energy
                try:
                    energy = audioop.rms(pcm_16k, 2)
                except Exception:
                    energy = 0
                threshold = int(getattr(cfg, 'energy_threshold', 1000))
                frame_ms = 20
                if energy >= threshold:
                    if int(getattr(session, 'barge_in_candidate_ms', 0)) == 0:
                        try:
                            session.barge_start_ts = now
                        except Exception:
                            session.barge_start_ts = 0.0
                    session.barge_in_candidate_ms = int(getattr(session, 'barge_in_candidate_ms', 0)) + frame_ms
                else:
                    session.barge_in_candidate_ms = 0

                cooldown_ms = int(getattr(cfg, 'cooldown_ms', 500))
                last_barge_in_ts = float(getattr(session, 'last_barge_in_ts', 0.0) or 0.0)
                in_cooldown = (now - last_barge_in_ts) * 1000 < cooldown_ms if last_barge_in_ts else False

                min_ms = int(getattr(cfg, 'min_ms', 250))
                if not in_cooldown and session.barge_in_candidate_ms >= min_ms:
                    try:
                        try:
                            if float(getattr(session, 'barge_start_ts', 0.0) or 0.0) > 0.0:
                                reaction_s = max(0.0, now - float(session.barge_start_ts))
                                _BARGE_REACTION_SECONDS.observe(reaction_s)
                                session.barge_start_ts = 0.0
                        except Exception:
                            pass
                        await self._apply_barge_in_action(
                            caller_channel_id,
                            source="local_vad",
                            reason="tts_overlap",
                        )
                        logger.info("ðŸŽ§ BARGE-IN (RTP) triggered", call_id=caller_channel_id)
                    except Exception:
                        logger.error("Error triggering RTP barge-in", call_id=caller_channel_id, exc_info=True)
                else:
                    # Not yet triggered; drop inbound frame while TTS is active
                    if energy > 0 and self.conversation_coordinator:
                        try:
                            self.conversation_coordinator.note_audio_during_tts(caller_channel_id)
                        except Exception:
                            pass
                    logger.debug("Dropping inbound RTP during TTS (candidate_ms=%d, energy=%d)",
                                 session.barge_in_candidate_ms, energy)
                    return

            # If a pipeline was explicitly requested for this call, route to pipeline queue
            if self._pipeline_forced.get(caller_channel_id):
                # AAVA-28: Check gating to prevent agent from hearing its own TTS output
                if not session.audio_capture_enabled:
                    # Drop audio during TTS playback (gating active)
                    return
                
                q = self._pipeline_queues.get(caller_channel_id)
                if q:
                    try:
                        q.put_nowait(pcm_16k)
                        return
                    except asyncio.QueueFull:
                        logger.debug("Pipeline queue full; dropping RTP frame", call_id=caller_channel_id)
                        return

            provider_name = session.provider_name or self.config.default_provider
            provider = self._call_providers.get(caller_channel_id)
            if not provider or not hasattr(provider, 'send_audio'):
                if not provider and caller_channel_id not in self._provider_start_tasks and not getattr(session, "provider_session_active", False):
                    self._kickoff_provider_session_start(caller_channel_id)
                logger.debug("Provider unavailable for RTP audio", provider=provider_name)
                return
            if not getattr(session, "provider_session_active", False):
                return

            # Forward PCM16 16k frames to provider
            await provider.send_audio(pcm_16k)
            # Provider-owned mode: local VAD fallback may flush local output (never cancels provider).
            try:
                await self._maybe_provider_barge_in_fallback(
                    session,
                    pcm16=pcm_16k,
                    pcm_rate_hz=16000,
                    audiosocket_wire=None,
                    source="externalmedia",
                )
            except Exception:
                logger.debug("Provider barge-in fallback check failed (ExternalMedia)", call_id=caller_channel_id, exc_info=True)
        except Exception as exc:
            logger.error("Error handling RTP audio", ssrc=ssrc, error=str(exc), exc_info=True)

    def _build_deepgram_config(self, provider_cfg: Dict[str, Any]) -> Optional[DeepgramProviderConfig]:
        """Construct a DeepgramProviderConfig from raw provider settings with validation."""
        try:
            # SECURITY: API keys ONLY from environment variables, never from YAML
            merged = dict(provider_cfg)
            merged['api_key'] = os.getenv('DEEPGRAM_API_KEY') or ''  # Force from .env only
            
            cfg = DeepgramProviderConfig(**merged)
            # Note: Don't return None for missing API key - let is_ready() handle it
            # This allows the provider to appear in health status as "Not Ready"
            if not cfg.api_key:
                logger.warning("Deepgram provider API key missing (DEEPGRAM_API_KEY) - provider will show as Not Ready")
            return cfg
        except Exception as exc:
            logger.error("Failed to build DeepgramProviderConfig", error=str(exc), exc_info=True)
            return None

    def _build_openai_realtime_config(self, provider_cfg: Dict[str, Any]) -> Optional[OpenAIRealtimeProviderConfig]:
        """Construct an OpenAIRealtimeProviderConfig from raw provider settings."""
        try:
            # Respect provider overrides; only fill when missing/empty
            merged = dict(provider_cfg)
            
            # SECURITY: API key ONLY from environment variables, never from YAML
            merged['api_key'] = os.getenv('OPENAI_API_KEY')  # Force from .env only
            
            try:
                instr = (merged.get("instructions") or "").strip()
            except Exception:
                instr = ""
            if not instr:
                merged["instructions"] = getattr(self.config.llm, "prompt", None)
            try:
                greet = (merged.get("greeting") or "").strip()
            except Exception:
                greet = ""
            if not greet:
                merged["greeting"] = getattr(self.config.llm, "initial_greeting", None)

            cfg = OpenAIRealtimeProviderConfig(**merged)
            if not cfg.enabled:
                logger.info("OpenAI Realtime provider disabled in configuration; skipping initialization.")
                return None
            # Note: Don't return None for missing API key - let is_ready() handle it
            if not cfg.api_key:
                logger.warning("OpenAI Realtime provider API key missing (OPENAI_API_KEY) - provider will show as Not Ready")
            return cfg
        except Exception as exc:
            logger.error("Failed to build OpenAIRealtimeProviderConfig", error=str(exc), exc_info=True)
            return None

    def _build_elevenlabs_config(self, provider_cfg: Dict[str, Any]) -> Optional[ElevenLabsAgentConfig]:
        """Construct an ElevenLabsAgentConfig from raw provider settings."""
        try:
            merged = dict(provider_cfg)
            
            # SECURITY: API keys ONLY from environment variables, never from YAML
            merged['api_key'] = os.getenv('ELEVENLABS_API_KEY')
            merged['agent_id'] = os.getenv('ELEVENLABS_AGENT_ID', merged.get('agent_id', ''))
            
            # Fill in defaults from llm config if not provided
            try:
                instr = (merged.get("instructions") or "").strip()
            except Exception:
                instr = ""
            if not instr:
                merged["instructions"] = getattr(self.config.llm, "prompt", None)
            try:
                greet = (merged.get("greeting") or "").strip()
            except Exception:
                greet = ""
            if not greet:
                merged["greeting"] = getattr(self.config.llm, "initial_greeting", None)

            cfg = ElevenLabsAgentConfig.from_dict(merged)
            if not cfg.enabled:
                logger.info("ElevenLabs provider disabled in configuration; skipping initialization.")
                return None
            # Note: Don't return None for missing API key/agent_id - let is_ready() handle it
            if not cfg.api_key:
                logger.warning("ElevenLabs provider API key missing (ELEVENLABS_API_KEY) - provider will show as Not Ready")
            if not cfg.agent_id:
                logger.warning("ElevenLabs provider agent ID missing (ELEVENLABS_AGENT_ID) - provider will show as Not Ready")
            return cfg
        except Exception as exc:
            logger.error("Failed to build ElevenLabsAgentConfig", error=str(exc), exc_info=True)
            return None

    def _audit_provider_config(self, name: str, provider_cfg: Dict[str, Any]) -> List[str]:
        """Static sanity checks for provider/audio format alignment.

        Returns a list of descriptive issue strings when mismatches are detected."""
        issues: List[str] = []
        try:
            audiosocket_format = "ulaw"
            try:
                if getattr(self.config, "audiosocket", None):
                    audiosocket_format = (self.config.audiosocket.format or "ulaw").lower()
            except Exception:
                audiosocket_format = "ulaw"
            audiosocket_canon = self._canonicalize_encoding(audiosocket_format)

            if name == "deepgram":
                enc = (provider_cfg.get("input_encoding") or "linear16").lower()
                enc_canon = self._canonicalize_encoding(enc)
                if enc_canon in {"slin16", "linear16", "pcm16"} and audiosocket_canon not in {"slin", "slin16"}:
                    issues.append(
                        f"Deepgram expects PCM input but audiosocket.format={audiosocket_format}; "
                        "set audiosocket.format=slin16 or change deepgram.input_encoding to ulaw."
                    )
                if enc_canon in {"ulaw", "mulaw", "g711_ulaw", "mu-law"} and audiosocket_canon not in {"ulaw", "mulaw"}:
                    # Allow intentional bridge: audiosocket carries PCM16 while provider works in Î¼-law
                    if audiosocket_canon not in {"slin", "slin16"}:
                        issues.append(
                            f"Deepgram expects Î¼-law input but audiosocket.format={audiosocket_format}; "
                            "set audiosocket.format=ulaw or change deepgram.input_encoding to linear16."
                        )

            if name == "openai_realtime":
                provider_rate = int(provider_cfg.get("provider_input_sample_rate_hz") or 0)
                output_rate = int(provider_cfg.get("output_sample_rate_hz") or 0)
                if provider_rate and provider_rate < 24000:
                    issues.append(
                        f"OpenAI Realtime provider_input_sample_rate_hz={provider_rate}; "
                        "set to 24000 for correct streaming."
                    )
                if output_rate and output_rate < 24000:
                    issues.append(
                        f"OpenAI Realtime output_sample_rate_hz={output_rate}; "
                        "set to 24000 so downstream audio plays at the correct speed."
                    )

                # Check target encoding vs audiosocket format
                # NOTE: Intentional transcoding is supported - system handles conversion
                target_encoding = (provider_cfg.get("target_encoding") or "ulaw").lower()
                if target_encoding in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                    if audiosocket_format in ("ulaw", "mulaw"):
                        # Perfect alignment
                        pass
                    elif audiosocket_format in ("slin", "slin16", "linear16", "pcm16"):
                        # Intentional transcoding: AudioSocket PCM â†’ Provider Î¼-law (system handles this)
                        pass
                    else:
                        issues.append(
                            f"OpenAI Realtime target_encoding={target_encoding} but audiosocket.format={audiosocket_format}; "
                            "set audiosocket.format=ulaw or adjust provider target encoding."
                        )
                if target_encoding in ("slin16", "linear16", "pcm16") and audiosocket_format not in ("slin", "slin16", "linear16", "pcm16"):
                    issues.append(
                        f"OpenAI Realtime target_encoding={target_encoding} but audiosocket.format={audiosocket_format}; "
                        "set audiosocket.format=slin16 or change provider target encoding."
                    )
        except Exception:
            logger.debug("Provider configuration audit failed", provider=name, exc_info=True)
        return issues

    def _describe_provider_alignment(self, name: str, provider: AIProviderInterface) -> List[str]:
        issues: List[str] = []
        try:
            audiosocket_format = "ulaw"
            try:
                if getattr(self.config, "audiosocket", None):
                    audiosocket_format = (self.config.audiosocket.format or "ulaw").lower()
            except Exception:
                audiosocket_format = "ulaw"
            audiosocket_canon = self._canonicalize_encoding(audiosocket_format)

            streaming_encoding = getattr(self.streaming_playback_manager, "audiosocket_format", None)
            if streaming_encoding:
                streaming_encoding = streaming_encoding.lower()
            else:
                streaming_encoding = audiosocket_format
            streaming_canon = self._canonicalize_encoding(streaming_encoding) or audiosocket_canon

            try:
                streaming_rate = int(getattr(self.streaming_playback_manager, "sample_rate", 8000) or 8000)
            except Exception:
                streaming_rate = 8000

            describe_method = getattr(provider, "describe_alignment", None)
            if callable(describe_method):
                issues.extend(
                    describe_method(
                        audiosocket_format=audiosocket_canon,
                        streaming_encoding=streaming_canon,
                        streaming_sample_rate=streaming_rate,
                    )
                )
        except Exception:
            logger.debug("Provider alignment description failed", provider=name, exc_info=True)
        return issues

    def _audit_transport_alignment(self) -> None:
        """Log a pre-call summary of transport settings and warn on misalignment.

        YAML is the source of truth. We check:
        - audiosocket.format vs streaming.sample_rate
        - provider target vs audiosocket.format
        - OpenAI Realtime provider input/output sample rates
        """
        try:
            # Gather core transport settings
            as_fmt = "ulaw"
            if getattr(self.config, "audiosocket", None):
                try:
                    as_fmt = (self.config.audiosocket.format or "ulaw").lower()
                except Exception:
                    as_fmt = "ulaw"
            try:
                streaming_rate = int(getattr(self.streaming_playback_manager, "sample_rate", 8000) or 8000)
            except Exception:
                streaming_rate = 8000

            # Provider configs (raw YAML dicts)
            providers_cfg = getattr(self.config, "providers", {}) or {}
            oair_cfg = providers_cfg.get("openai_realtime", {}) or {}
            dg_cfg = providers_cfg.get("deepgram", {}) or {}

            # Normalize key fields
            def _lower_str(d: dict, key: str, default: str = "") -> str:
                val = d.get(key, default)
                if isinstance(val, str):
                    return val.lower()
                return str(val).lower()

            oair_target_enc = _lower_str(oair_cfg, "target_encoding", "ulaw")
            oair_target_rate = int(oair_cfg.get("target_sample_rate_hz") or 8000)
            oair_in_rate = int(oair_cfg.get("provider_input_sample_rate_hz") or 24000)
            oair_out_rate = int(oair_cfg.get("output_sample_rate_hz") or 24000)

            dg_in_enc = _lower_str(dg_cfg, "input_encoding", "linear16")
            try:
                dg_in_rate = int(dg_cfg.get("input_sample_rate_hz") or 8000)
            except Exception:
                dg_in_rate = 8000

            # Info summary
            streaming_target_fmt = (getattr(self.streaming_playback_manager, "audiosocket_format", None) or as_fmt).lower()
            streaming_swap_mode = getattr(self.streaming_playback_manager, "egress_swap_mode", "auto")
            streaming_force_mulaw = bool(getattr(self.streaming_playback_manager, "egress_force_mulaw", False))

            dg_out_enc = _lower_str(dg_cfg, "output_encoding", "")
            try:
                dg_out_rate = int(dg_cfg.get("output_sample_rate_hz") or 0)
            except Exception:
                dg_out_rate = 0

            summary = {
                "audiosocket_format": as_fmt,
                "streaming_target_encoding": streaming_target_fmt,
                "streaming_sample_rate_hz": streaming_rate,
                "streaming_egress_swap_mode": streaming_swap_mode,
                "streaming_egress_force_mulaw": streaming_force_mulaw,
                "openai_realtime_input_encoding": _lower_str(oair_cfg, "input_encoding", ""),
                "openai_realtime_input_sample_rate_hz": int(oair_cfg.get("input_sample_rate_hz") or 0),
                "openai_realtime_provider_input_sample_rate_hz": oair_in_rate,
                "openai_realtime_output_sample_rate_hz": oair_out_rate,
                "openai_realtime_target_encoding": oair_target_enc,
                "openai_realtime_target_sample_rate_hz": oair_target_rate,
                "deepgram_input_encoding": dg_in_enc,
                "deepgram_input_sample_rate_hz": dg_in_rate,
                "deepgram_output_encoding": dg_out_enc,
                "deepgram_output_sample_rate_hz": dg_out_rate,
            }

            logger.info("Transport alignment summary", **summary)

            # Expected streaming rate from audiosocket format
            expected_rate = None
            if as_fmt in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                expected_rate = 8000
            elif as_fmt in ("slin16", "linear16", "pcm16"):
                expected_rate = 16000

            # Warn on streaming rate mismatch
            if expected_rate and streaming_rate != expected_rate:
                logger.warning(
                    "Streaming sample rate misaligned with audiosocket.format",
                    audiosocket_format=as_fmt,
                    streaming_sample_rate=streaming_rate,
                    expected_sample_rate=expected_rate,
                    suggestion=(
                        "Set streaming.sample_rate to %d or change audiosocket.format to match"
                        % expected_rate
                    ),
                )

            # Provider target vs audiosocket.format
            if as_fmt in ("ulaw", "mulaw", "g711_ulaw", "mu-law") and oair_target_enc not in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                logger.warning(
                    "OpenAI target encoding misaligned with audiosocket.format",
                    audiosocket_format=as_fmt,
                    openai_target_encoding=oair_target_enc,
                    suggestion="Set providers.openai_realtime.target_encoding to 'ulaw' or change audiosocket.format",
                )
            if as_fmt in ("slin16", "linear16", "pcm16") and oair_target_enc not in ("slin16", "linear16", "pcm16"):
                logger.warning(
                    "OpenAI target encoding misaligned with audiosocket.format",
                    audiosocket_format=as_fmt,
                    openai_target_encoding=oair_target_enc,
                    suggestion="Set providers.openai_realtime.target_encoding to 'slin16' or change audiosocket.format",
                )

            # OpenAI provider IO rates
            if oair_in_rate and oair_in_rate < 24000:
                logger.warning(
                    "OpenAI provider_input_sample_rate_hz suboptimal",
                    value=oair_in_rate,
                    suggestion="Set providers.openai_realtime.provider_input_sample_rate_hz to 24000",
                )
            if oair_out_rate and oair_out_rate < 24000:
                logger.warning(
                    "OpenAI output_sample_rate_hz suboptimal",
                    value=oair_out_rate,
                    suggestion="Set providers.openai_realtime.output_sample_rate_hz to 24000",
                )

            # Deepgram input encoding vs audiosocket (suppress intentional PCMâ†”Î¼-law bridge)
            try:
                as_canon = self._canonicalize_encoding(as_fmt)
            except Exception:
                as_canon = as_fmt
            try:
                dg_in_canon = self._canonicalize_encoding(dg_in_enc)
            except Exception:
                dg_in_canon = dg_in_enc

            if dg_in_canon in ("ulaw",) and as_canon in ("slin", "slin16"):
                # Intentional bridge: audiosocket carries PCM16 (slin/slin16) while Deepgram ingests Î¼-law
                # System transcodes between them - this is the golden baseline configuration
                pass
            elif dg_in_enc in ("ulaw", "mulaw", "g711_ulaw", "mu-law") and as_fmt not in ("ulaw", "mulaw", "g711_ulaw", "mu-law", "slin", "slin16"):
                logger.warning(
                    "Deepgram input encoding expects Î¼-law but audiosocket is PCM",
                    audiosocket_format=as_fmt,
                    deepgram_input_encoding=dg_in_enc,
                    suggestion="Set audiosocket.format to 'ulaw' or change deepgram.input_encoding to 'linear16'",
                )
            if dg_in_enc in ("slin16", "linear16", "pcm16") and as_fmt not in ("slin16", "linear16", "pcm16"):
                logger.warning(
                    "Deepgram input encoding expects PCM16 but audiosocket is Î¼-law",
                    audiosocket_format=as_fmt,
                    deepgram_input_encoding=dg_in_enc,
                    suggestion="Set audiosocket.format to 'slin16' or change deepgram.input_encoding to 'ulaw'",
                )
        except Exception:
            logger.debug("Transport audit encountered an error", exc_info=True)

    async def on_provider_event(self, event: Dict[str, Any]):
        """Handle async events from the active provider (Deepgram/OpenAI/local).

        For file-based downstream (current default), buffer AgentAudio bytes until
        AgentAudioDone, then play the accumulated audio via PlaybackManager.
        """
        try:
            etype = event.get("type")
            call_id = event.get("call_id")
            if not call_id:
                return

            session = await self.session_store.get_by_call_id(call_id)
            if not session:
                logger.warning("Provider event for unknown call", event_type=etype, call_id=call_id)
                return

            # Option 2: Provider-owned VAD/barge-in. Provider signals interruption; platform flushes local output only.
            # - OpenAI Realtime emits `ProviderBargeIn` on `input_audio_buffer.speech_started` cancellation.
            # - ElevenLabs emits `interruption` when it detects barge-in.
            if etype in ("ProviderBargeIn", "interruption"):
                try:
                    # Guard against provider VAD noise when we're not actually outputting audio.
                    # This matters for OpenAI AudioSocket: `input_audio_buffer.speech_started` can occur
                    # even when there is no cancellable response, while local output may or may not be active.
                    try:
                        cfg = getattr(self.config, "barge_in", None)
                        cooldown_ms = int(getattr(cfg, "cooldown_ms", 500)) if cfg else 500
                        import time
                        now = time.time()
                        last_barge_in_ts = float(getattr(session, "last_barge_in_ts", 0.0) or 0.0)
                        if last_barge_in_ts and (now - last_barge_in_ts) * 1000 < cooldown_ms:
                            return
                    except Exception:
                        pass

                    output_active = False
                    try:
                        output_active = bool(self.streaming_playback_manager.is_stream_active(call_id))
                    except Exception:
                        output_active = False
                    if not output_active:
                        try:
                            playback_ids = await self.session_store.list_playbacks_for_call(call_id)
                            output_active = bool(playback_ids)
                        except Exception:
                            output_active = False
                    if not output_active and not bool(getattr(session, "tts_playing", False)):
                        # No local output to flush; ignore noisy provider barge-in signals.
                        return

                    provider_evt = event.get("event") or event.get("reason") or ""
                    reason = provider_evt if etype == "ProviderBargeIn" else (provider_evt or etype)
                    await self._apply_barge_in_action(
                        call_id,
                        source="provider_event",
                        reason=str(reason or etype),
                    )
                except Exception:
                    logger.error("Failed to apply provider barge-in", call_id=call_id, event_type=etype, exc_info=True)
                return

            # Provider requests early TTS gating clear (e.g., OpenAI greeting complete)
            if etype == "ClearTtsGating":
                try:
                    tokens = list(getattr(session, "tts_tokens", set()) or [])
                except Exception:
                    tokens = []
                if not tokens:
                    logger.info(
                        "ClearTtsGating received but no active TTS tokens",
                        call_id=call_id,
                        reason=event.get("reason"),
                    )
                    return

                logger.info(
                    "Processing ClearTtsGating event",
                    call_id=call_id,
                    reason=event.get("reason"),
                    token_count=len(tokens),
                )
                for token in tokens:
                    try:
                        if self.conversation_coordinator:
                            await self.conversation_coordinator.on_tts_end(call_id, token, reason=event.get("reason") or "provider-request")
                    except Exception:
                        logger.debug(
                            "Failed to clear gating token from ClearTtsGating",
                            call_id=call_id,
                            token=token,
                            exc_info=True,
                        )
                return

            # Provider announced its audio format before first audio chunk
            if etype == "ProviderAudioFormat":
                encoding = event.get("encoding")
                if isinstance(encoding, bytes):
                    try:
                        encoding = encoding.decode("utf-8", "ignore")
                    except Exception:
                        encoding = None
                if isinstance(encoding, str):
                    encoding = encoding.lower().strip() or None
                sr_val = event.get("sample_rate")
                try:
                    sample_rate = int(sr_val) if sr_val is not None else None
                except (TypeError, ValueError):
                    sample_rate = None

                # Persist as the stream's expected source format so streaming manager can align
                fmt_entry = self._provider_stream_formats.get(call_id, {}).copy()
                if encoding is not None:
                    fmt_entry["encoding"] = encoding
                if sample_rate is not None:
                    fmt_entry["sample_rate"] = sample_rate
                if fmt_entry:
                    self._provider_stream_formats[call_id] = fmt_entry

                # Update transport profile early (source="provider") for downstream alignment
                try:
                    await self._update_transport_profile(session, fmt=encoding, sample_rate=sample_rate, source="provider")
                except Exception:
                    logger.debug("ProviderAudioFormat profile update failed", call_id=call_id, exc_info=True)

                logger.info("Provider audio format announced", call_id=call_id, encoding=encoding, sample_rate=sample_rate)
                return

            # Downstream strategy: stream provider audio in near-real time via StreamingPlaybackManager
            if etype == "AgentAudio":
                chunk: bytes = event.get("data") or b""
                if not chunk:
                    return
                # If barge-in fired, suppress provider audio locally for a short window so streaming
                # doesn't immediately restart with the remainder of the previous sentence.
                try:
                    import time

                    now = time.time()
                    sup = session.vad_state.get("output_suppression") or {}
                    until_ts = float(sup.get("until_ts", 0.0) or 0.0)
                    if until_ts and now < until_ts:
                        # Keep suppression alive while chunks keep arriving so we don't unmute mid-tail.
                        try:
                            cfg = getattr(self.config, "barge_in", None)
                            extend_ms = int(getattr(cfg, "provider_output_suppress_chunk_extend_ms", 0)) if cfg else 0
                            if extend_ms > 0:
                                sup["until_ts"] = max(until_ts, now + (extend_ms / 1000.0))
                                until_ts = float(sup.get("until_ts", until_ts) or until_ts)
                        except Exception:
                            pass
                        sup["active"] = True
                        sup["dropped_chunks"] = int(sup.get("dropped_chunks", 0) or 0) + 1
                        sup["dropped_bytes"] = int(sup.get("dropped_bytes", 0) or 0) + len(chunk)
                        last_log = float(sup.get("last_log_ts", 0.0) or 0.0)
                        if (now - last_log) > 0.75:
                            remaining_ms = int(max(0.0, (until_ts - now)) * 1000)
                            logger.info(
                                "ðŸ”‡ OUTPUT SUPPRESSED - Dropping provider audio",
                                call_id=call_id,
                                provider=getattr(session, "provider_name", None),
                                remaining_ms=remaining_ms,
                                dropped_chunks=sup.get("dropped_chunks"),
                                dropped_bytes=sup.get("dropped_bytes"),
                            )
                            sup["last_log_ts"] = now
                        session.vad_state["output_suppression"] = sup
                        return
                    if until_ts and now >= until_ts and bool(sup.get("active", False)):
                        sup["active"] = False
                        sup["until_ts"] = 0.0
                        session.vad_state["output_suppression"] = sup
                        logger.info(
                            "ðŸ”ˆ OUTPUT SUPPRESSION ended",
                            call_id=call_id,
                            provider=getattr(session, "provider_name", None),
                            dropped_chunks=sup.get("dropped_chunks"),
                            dropped_bytes=sup.get("dropped_bytes"),
                        )
                except Exception:
                    logger.debug("Output suppression check failed", call_id=call_id, exc_info=True)
                encoding = event.get("encoding")
                if isinstance(encoding, bytes):
                    try:
                        encoding = encoding.decode("utf-8", "ignore")
                    except Exception:
                        encoding = None
                if isinstance(encoding, str):
                    encoding = encoding.lower().strip()
                    if not encoding:
                        encoding = None
                sample_rate_val = event.get("sample_rate")
                sample_rate_int: Optional[int]
                try:
                    sample_rate_int = int(sample_rate_val) if sample_rate_val is not None else None
                except (TypeError, ValueError):
                    sample_rate_int = None
                # Persist latest provider format hints per call
                fmt_entry = self._provider_stream_formats.get(call_id, {}).copy()
                if encoding is not None:
                    fmt_entry["encoding"] = encoding
                if sample_rate_int is not None:
                    fmt_entry["sample_rate"] = sample_rate_int
                if fmt_entry:
                    self._provider_stream_formats[call_id] = fmt_entry
                # Initialize diag vars outside try block to avoid UnboundLocalError
                diag_encoding = encoding or ""
                diag_rate = sample_rate_int or 0
                try:
                    diag_encoding = fmt_entry.get("encoding") or encoding or (session.transport_profile.format if session.transport_profile else "")
                    diag_rate = int(fmt_entry.get("sample_rate") or sample_rate_int or (session.transport_profile.sample_rate if session.transport_profile else 0))
                    self._update_audio_diagnostics(session, "provider_out", chunk, diag_encoding, diag_rate)
                except Exception:
                    logger.debug("Provider audio diagnostics update failed", call_id=call_id, exc_info=True)
                try:
                    if diag_encoding and diag_rate:
                        self.audio_capture.append_encoded(
                            call_id,
                            "agent_from_provider",
                            chunk,
                            diag_encoding,
                            diag_rate,
                        )
                except Exception:
                    logger.debug("Provider audio capture failed", call_id=call_id, exc_info=True)
                # Log provider AgentAudio chunk metrics for RCA
                try:
                    rate = int(sample_rate_int or diag_rate or 0)
                except Exception:
                    rate = 0
                try:
                    enc = (encoding or diag_encoding or "").lower()
                except Exception:
                    enc = encoding or ""
                bps = 2 if enc in ("linear16", "pcm16", "slin", "slin16") else 1
                duration_ms = 0.0
                try:
                    if rate and bps:
                        duration_ms = round((len(chunk) / float(bps * rate)) * 1000.0, 3)
                except Exception:
                    duration_ms = 0.0
                seq = self._provider_chunk_seq.get(call_id, 0) + 1
                self._provider_chunk_seq[call_id] = seq
                try:
                    logger.info(
                        "PROVIDER CHUNK",
                        call_id=call_id,
                        seq=seq,
                        size_bytes=len(chunk),
                        encoding=enc,
                        sample_rate_hz=rate,
                        approx_duration_ms=duration_ms,
                    )
                except Exception:
                    pass
                # Use streaming config rate for provider audio, not transport_profile which can be
                # corrupted by inbound audio detection (user's 8kHz vs provider's 16kHz)
                wire_rate = getattr(self.config.streaming, "sample_rate", 16000) or rate or 16000
                try:
                    transport_encoding = self._canonicalize_encoding(session.transport_profile.format)
                except Exception:
                    transport_encoding = ""
                out_chunk = chunk
                if enc in ("linear16", "pcm16", "slin", "slin16") and rate and wire_rate and rate != wire_rate:
                    try:
                        out_chunk, _ = audioop.ratecv(chunk, 2, 1, rate, wire_rate, None)
                        seq = self._provider_chunk_seq.get(call_id, 0) + 1
                        self._provider_chunk_seq[call_id] = seq
                        logger.info(
                            "PROVIDER CHUNK",
                            call_id=call_id,
                            seq=seq,
                            size_bytes=len(chunk),
                            encoding=enc,
                            sample_rate_hz=rate,
                            approx_duration_ms=duration_ms,
                        )
                    except Exception:
                        logger.debug("Provider chunk resample failed; passing original", call_id=call_id, exc_info=True)
                # Do not slice Î¼-law in engine; StreamingPlaybackManager handles segmentation/pacing

                # Coalescing settings
                coalesce_enabled = bool(getattr(getattr(self.config, 'streaming', {}), 'coalesce_enabled', False))
                try:
                    coalesce_min_ms = int(getattr(self.config.streaming, 'coalesce_min_ms', 600))
                except Exception:
                    coalesce_min_ms = 600
                try:
                    micro_fallback_ms = int(getattr(self.config.streaming, 'micro_fallback_ms', 300))
                except Exception:
                    micro_fallback_ms = 300

                q = self._provider_stream_queues.get(call_id)
                # In continuous-stream mode, ensure per-segment gating is active
                try:
                    if getattr(self.streaming_playback_manager, 'continuous_stream', False):
                        if call_id not in self._segment_tts_active:
                            await self.streaming_playback_manager.start_segment_gating(call_id)
                            self._segment_tts_active.add(call_id)
                except Exception:
                    logger.debug("Failed to start segment gating", call_id=call_id, exc_info=True)
                if coalesce_enabled and q is None and not isinstance(out_chunk, list):
                    buf = self._provider_coalesce_buf.setdefault(call_id, bytearray())
                    buf.extend(out_chunk)
                    try:
                        # Respect Î¼-law 1 byte/sample vs PCM16 2 bytes/sample
                        fmt = self._canonicalize_encoding(session.transport_profile.format)
                        bps = 1 if fmt == "mulaw" or fmt == "ulaw" else 2
                        buf_ms = round((len(buf) / float(max(1, bps * max(1, wire_rate)))) * 1000.0, 3)
                    except Exception:
                        buf_ms = 0.0
                    logger.info("PROVIDER COALESCE BUFFER", call_id=call_id, buf_ms=buf_ms, bytes=len(buf))
                    if buf_ms < coalesce_min_ms:
                        # Count provider bytes even while buffering prior to stream start
                        try:
                            self._provider_bytes[call_id] = int(self._provider_bytes.get(call_id, 0)) + (len(chunk) if isinstance(chunk, (bytes, bytearray)) else len(out_chunk))
                        except Exception:
                            pass
                        # Keep buffering until threshold
                        return
                    # Start streaming now with coalesced buffer
                    try:
                        q = asyncio.Queue(maxsize=256)
                        self._provider_stream_queues[call_id] = q
                        playback_type = "greeting" if getattr(session, "conversation_state", "") == "greeting" else "streaming-response"
                        fmt_info = self._provider_stream_formats.get(call_id, {})
                        provider_name = getattr(session, "provider_name", None) or self.config.default_provider
                        alignment_issues = self.provider_alignment_issues.get(provider_name, [])
                        if alignment_issues and call_id not in self._runtime_alignment_logged:
                            for detail in alignment_issues:
                                logger.warning("Provider codec/sample alignment issue persists during streaming", call_id=call_id, provider=provider_name, detail=detail)
                            self._runtime_alignment_logged.add(call_id)
                        target_encoding, target_sample_rate, remediation = self._resolve_stream_targets(session, session.provider_name)
                        if target_sample_rate <= 0:
                            target_sample_rate = session.transport_profile.wire_sample_rate
                        if remediation:
                            session.audio_diagnostics["codec_remediation"] = remediation
                        
                        # Get source sample rate with fallback to provider's configured output rate
                        source_sample_rate = fmt_info.get("sample_rate")
                        if not source_sample_rate:
                            # Fallback: use provider's configured output rate (prevents 8kHz default)
                            try:
                                provider = self._call_providers.get(call_id) or self.providers.get(session.provider_name)
                                if provider and hasattr(provider, '_dg_output_rate'):
                                    source_sample_rate = provider._dg_output_rate
                                    logger.debug(
                                        "Using provider configured output rate as source_sample_rate fallback",
                                        call_id=call_id,
                                        rate=source_sample_rate,
                                        reason="fmt_info empty",
                                    )
                            except Exception:
                                pass
                        # Final fallback to streaming config
                        if not source_sample_rate:
                            source_sample_rate = self.config.streaming.sample_rate
                        
                        # DOWNSTREAM_MODE GATING: Check if streaming playback is allowed
                        # downstream_mode="file" forces file-based playback (useful for debugging/testing)
                        # downstream_mode="stream" allows streaming playback (default for full agents)
                        use_streaming = self.config.downstream_mode != "file"
                        
                        if use_streaming:
                            await self.streaming_playback_manager.start_streaming_playback(
                                call_id,
                                q,
                                playback_type=playback_type,
                                source_encoding=fmt_info.get("encoding"),
                                source_sample_rate=source_sample_rate,
                                target_encoding=target_encoding,
                                target_sample_rate=target_sample_rate,
                            )
                        else:
                            # downstream_mode="file" - use file playback instead of streaming
                            logger.info("Using file playback (downstream_mode=file)", call_id=call_id)
                            try:
                                playback_id = await self.playback_manager.play_audio(call_id, bytes(buf), "streaming-response")
                                logger.info("File playback started (forced by downstream_mode)", 
                                           call_id=call_id, playback_id=playback_id, buf_ms=buf_ms)
                            except Exception:
                                logger.error("File playback failed (downstream_mode=file)", call_id=call_id, exc_info=True)
                            self._provider_coalesce_buf.pop(call_id, None)
                            return
                        self._emit_transport_card(
                            call_id,
                            session,
                            source_encoding=fmt_info.get("encoding") or encoding,
                            source_sample_rate=source_sample_rate,
                            target_encoding=target_encoding,
                            target_sample_rate=target_sample_rate,
                        )
                        logger.info("COALESCE START", call_id=call_id, coalesced_ms=buf_ms, coalesced_bytes=len(buf))
                        try:
                            q.put_nowait(bytes(buf))
                            # Account for the initial coalesced enqueue
                            try:
                                self._enqueued_bytes[call_id] = int(self._enqueued_bytes.get(call_id, 0)) + len(buf)
                            except Exception:
                                pass
                        except asyncio.QueueFull:
                            logger.debug("Coalesced enqueue dropped (queue full)", call_id=call_id)
                        self._provider_coalesce_buf.pop(call_id, None)
                        return
                    except Exception:
                        logger.error("File fallback failed after coalesce start error", call_id=call_id, exc_info=True)
                        self._provider_coalesce_buf.pop(call_id, None)
                        return
                else:
                    # Normal path: ensure stream and enqueue
                    if q is None:
                        # No existing queue - create new one
                        q = asyncio.Queue(maxsize=256)
                        self._provider_stream_queues[call_id] = q
                        try:
                            playback_type = "greeting" if getattr(session, "conversation_state", "") == "greeting" else "streaming-response"
                            fmt_info = self._provider_stream_formats.get(call_id, {})
                            provider_name = getattr(session, "provider_name", None) or self.config.default_provider
                            alignment_issues = self.provider_alignment_issues.get(provider_name, [])
                            if alignment_issues and call_id not in self._runtime_alignment_logged:
                                for detail in alignment_issues:
                                    logger.warning("Provider codec/sample alignment issue persists during streaming", call_id=call_id, provider=provider_name, detail=detail)
                                self._runtime_alignment_logged.add(call_id)
                            target_encoding, target_sample_rate, remediation = self._resolve_stream_targets(session, session.provider_name)
                            if target_sample_rate <= 0:
                                target_sample_rate = session.transport_profile.wire_sample_rate
                            if remediation:
                                session.audio_diagnostics["codec_remediation"] = remediation
                            src_encoding = fmt_info.get("encoding") or encoding
                            provider_obj = self._call_providers.get(call_id) or self.providers.get(session.provider_name)
                            src_rate = fmt_info.get("sample_rate") or sample_rate_int or (
                                getattr(provider_obj, "_dg_output_rate", None) if provider_obj else None
                            )
                            
                            # DOWNSTREAM_MODE GATING: Check if streaming playback is allowed
                            use_streaming = self.config.downstream_mode != "file"
                            
                            if use_streaming:
                                await self.streaming_playback_manager.start_streaming_playback(
                                    call_id,
                                    q,
                                    playback_type=playback_type,
                                    source_encoding=src_encoding,
                                    source_sample_rate=src_rate,
                                    target_encoding=target_encoding,
                                    target_sample_rate=target_sample_rate,
                                )
                            else:
                                # downstream_mode="file" - use file playback instead of streaming
                                logger.info("Using file playback (downstream_mode=file)", call_id=call_id)
                                try:
                                    playback_id = await self.playback_manager.play_audio(call_id, out_chunk, "streaming-response")
                                    if playback_id:
                                        logger.info("File playback started (forced by downstream_mode)", 
                                                   call_id=call_id, playback_id=playback_id)
                                    else:
                                        logger.error("File playback failed (downstream_mode=file)", call_id=call_id)
                                except Exception:
                                    logger.error("File playback exception (downstream_mode=file)", call_id=call_id, exc_info=True)
                                return
                            self._emit_transport_card(
                                call_id,
                                session,
                                source_encoding=src_encoding,
                                source_sample_rate=src_rate,
                                target_encoding=target_encoding,
                                target_sample_rate=target_sample_rate,
                            )
                            logger.info("Streaming playback started", call_id=call_id)
                        except Exception:
                            logger.error("Failed to start streaming playback", call_id=call_id, exc_info=True)
                            # CRITICAL: Remove orphan queue so subsequent chunks trigger fresh playback
                            self._provider_stream_queues.pop(call_id, None)
                            try:
                                playback_id = await self.playback_manager.play_audio(call_id, out_chunk, "streaming-response")
                                if not playback_id:
                                    logger.error("Fallback file playback failed", call_id=call_id, size=len(out_chunk))
                            except Exception:
                                logger.error("Fallback file playback exception", call_id=call_id, exc_info=True)
                            return
                    try:
                        # Track provider bytes
                        self._provider_bytes[call_id] = int(self._provider_bytes.get(call_id, 0)) + (len(chunk) if isinstance(chunk, (bytes, bytearray)) else sum(len(f) for f in (out_chunk if isinstance(out_chunk, list) else [out_chunk])))
                        if isinstance(out_chunk, list):
                            for frame in out_chunk:
                                q.put_nowait(frame)
                                self._enqueued_bytes[call_id] = int(self._enqueued_bytes.get(call_id, 0)) + len(frame)
                        else:
                            q.put_nowait(out_chunk)
                            self._enqueued_bytes[call_id] = int(self._enqueued_bytes.get(call_id, 0)) + len(out_chunk)
                    except asyncio.QueueFull:
                        logger.debug("Provider streaming queue full; dropping chunk", call_id=call_id)
            elif etype == "AgentAudioDone":
                # If we were suppressing output due to barge-in, end suppression at a segment boundary.
                # This prevents cutting into the next (new) response once the provider finishes the interrupted one.
                try:
                    sup = session.vad_state.get("output_suppression") or {}
                    if bool(sup.get("active", False)) or float(sup.get("until_ts", 0.0) or 0.0) > 0.0:
                        sup["active"] = False
                        sup["until_ts"] = 0.0
                        session.vad_state["output_suppression"] = sup
                        logger.info(
                            "ðŸ”ˆ OUTPUT SUPPRESSION cleared on AgentAudioDone",
                            call_id=call_id,
                            provider=getattr(session, "provider_name", None),
                            dropped_chunks=sup.get("dropped_chunks"),
                            dropped_bytes=sup.get("dropped_bytes"),
                        )
                except Exception:
                    logger.debug("Failed clearing output suppression on AgentAudioDone", call_id=call_id, exc_info=True)
                continuous = bool(getattr(self.streaming_playback_manager, 'continuous_stream', False))
                q = self._provider_stream_queues.get(call_id)
                if continuous:
                    # Do NOT end the stream; mark boundary and end per-segment gating
                    try:
                        await self.streaming_playback_manager.mark_segment_boundary(call_id)
                    except Exception:
                        logger.debug("Failed to mark segment boundary", call_id=call_id, exc_info=True)
                    try:
                        await self.streaming_playback_manager.end_segment_gating(call_id)
                    except Exception:
                        logger.debug("Failed to end segment gating", call_id=call_id, exc_info=True)
                    # CRITICAL FIX #1: Do NOT discard call_id for continuous streams
                    # Discarding causes subsequent chunks to re-trigger gating, interrupting playback
                    # For OpenAI greeting: 20+ interruptions in 86s call (gating every 3-5s)
                    # Keep call_id in set so subsequent chunks don't re-gate
                    # try:
                    #     self._segment_tts_active.discard(call_id)
                    # except Exception:
                    #     pass
                else:
                    if q is not None:
                        # Signal end of stream (per-segment mode)
                        try:
                            q.put_nowait(None)  # sentinel for StreamingPlaybackManager
                        except asyncio.QueueFull:
                            asyncio.create_task(q.put(None))
                        # Clear queue reference so next chunk creates new queue/stream
                        self._provider_stream_queues.pop(call_id, None)
                    else:
                        logger.debug("AgentAudioDone with no active stream queue", call_id=call_id)
                    self._provider_stream_formats.pop(call_id, None)
                
                # Signal farewell done event if we're waiting for hangup
                farewell_key = f"farewell_done_{call_id}"
                if hasattr(self, '_farewell_done_events') and farewell_key in self._farewell_done_events:
                    self._farewell_done_events[farewell_key].set()
                    logger.info("âœ… Farewell audio done - signaling hangup", call_id=call_id)
                
                # Log provider segment wall duration
                try:
                    start_ts = self._provider_segment_start_ts.pop(call_id, None)
                    if start_ts is not None:
                        wall = max(0.0, time.time() - float(start_ts))
                        logger.info(
                            "PROVIDER SEGMENT END",
                            call_id=call_id,
                            segment_wall_seconds=round(wall, 3),
                        )
                    # Segment byte accounting summary
                    prov = int(self._provider_bytes.pop(call_id, 0))
                    enq = int(self._enqueued_bytes.pop(call_id, 0))
                    try:
                        ratio = 0.0 if prov <= 0 else (enq / float(prov))
                    except Exception:
                        ratio = 0.0
                    logger.info("PROVIDER SEGMENT BYTES",
                                call_id=call_id,
                                provider_bytes=prov,
                                enqueued_bytes=enq,
                                enqueued_ratio=round(ratio, 3))
                    try:
                        if hasattr(self, 'streaming_playback_manager') and self.streaming_playback_manager:
                            self.streaming_playback_manager.record_provider_bytes(call_id, int(prov))
                    except Exception:
                        logger.debug("Failed to propagate provider_bytes to streaming manager",
                                     call_id=call_id, exc_info=True)
                    # Reset chunk sequence at segment end
                    self._provider_chunk_seq.pop(call_id, None)
                except Exception:
                    pass
                # Experimental: if coalescing buffer exists but stream never started, play or stream it now
                try:
                    coalesce_enabled = bool(getattr(getattr(self.config, 'streaming', {}), 'coalesce_enabled', False))
                except Exception:
                    coalesce_enabled = False
                if coalesce_enabled and call_id in self._provider_coalesce_buf:
                    buf = self._provider_coalesce_buf.pop(call_id, bytearray())
                    try:
                        wire_rate = int(getattr(self.config.streaming, 'sample_rate', 16000))
                    except Exception:
                        wire_rate = 16000
                    try:
                        buf_ms = round((len(buf) / float(2 * max(1, wire_rate))) * 1000.0, 3)
                    except Exception:
                        buf_ms = 0.0
                    micro_fallback_ms = int(getattr(self.config.streaming, 'micro_fallback_ms', 300)) if hasattr(self.config, 'streaming') else 300
                    if buf and buf_ms < micro_fallback_ms:
                        try:
                            playback_id = await self.playback_manager.play_audio(call_id, bytes(buf), "streaming-response")
                            logger.info("MICRO SEGMENT FILE FALLBACK (end)", call_id=call_id, buf_ms=buf_ms, playback_id=playback_id)
                        except Exception:
                            logger.error("File fallback failed at segment end", call_id=call_id, exc_info=True)
                    elif buf:
                        # Stream coalesced buffer now as a short segment
                        try:
                            q2 = asyncio.Queue(maxsize=256)
                            self._provider_stream_queues[call_id] = q2
                            playback_type = "streaming-response"
                            fmt_info = self._provider_stream_formats.get(call_id, {})
                            target_encoding, target_sample_rate, remediation = self._resolve_stream_targets(session, session.provider_name)
                            if target_sample_rate <= 0:
                                target_sample_rate = session.transport_profile.wire_sample_rate
                            await self.streaming_playback_manager.start_streaming_playback(
                                call_id,
                                q2,
                                playback_type=playback_type,
                                source_encoding=fmt_info.get("encoding"),
                                source_sample_rate=fmt_info.get("sample_rate"),
                                target_encoding=target_encoding,
                                target_sample_rate=target_sample_rate,
                            )
                            self._emit_transport_card(
                                call_id,
                                session,
                                source_encoding=fmt_info.get("encoding"),
                                source_sample_rate=fmt_info.get("sample_rate"),
                                target_encoding=target_encoding,
                                target_sample_rate=target_sample_rate,
                            )
                            logger.info("COALESCE START (end)", call_id=call_id, coalesced_ms=buf_ms, coalesced_bytes=len(buf))
                            try:
                                q2.put_nowait(bytes(buf))
                                # Account for the coalesced enqueue at segment end
                                try:
                                    self._enqueued_bytes[call_id] = int(self._enqueued_bytes.get(call_id, 0)) + len(buf)
                                except Exception:
                                    pass
                                q2.put_nowait(None)
                            except asyncio.QueueFull:
                                logger.debug("Coalesced enqueue dropped at end (queue full)", call_id=call_id)
                        except Exception:
                            logger.error("Coalesced streaming failed at segment end", call_id=call_id, exc_info=True)
                
                # Check if hangup was requested after TTS completion
                # Only check when streaming_done is True (complete response ended, not just segment boundary)
                streaming_done = event.get("streaming_done", False)
                if streaming_done:
                    try:
                        session = await self.session_store.get_by_call_id(call_id)
                        if session and getattr(session, 'cleanup_after_tts', False):
                            logger.info("ðŸ”š Cleanup after TTS requested - hanging up call", call_id=call_id)
                            # Give a small delay for audio to finish playing
                            await asyncio.sleep(0.5)
                            try:
                                await self.ari_client.hangup_channel(session.caller_channel_id)
                                logger.info("âœ… Call hung up successfully", call_id=call_id, channel_id=session.caller_channel_id)
                            except Exception as e:
                                logger.error("Failed to hang up call", call_id=call_id, error=str(e), exc_info=True)
                    except Exception as e:
                        logger.debug("Error checking cleanup_after_tts flag", call_id=call_id, error=str(e))
            
            elif etype == "HangupReady":
                # Hangup triggered by farewell response completion (Option C implementation)
                # This ensures hangup happens even if farewell response produces no audio
                call_id = event.get("call_id")
                reason = event.get("reason", "unknown")
                had_audio = event.get("had_audio", False)
                
                logger.info(
                    "ðŸ”š HangupReady event received - executing hangup",
                    call_id=call_id,
                    reason=reason,
                    had_audio=had_audio
                )
                
                # Delay to ensure audio completes through RTP pipeline
                # Accounts for: RTP transmission, jitter buffer, and playback
                # Check provider-specific delay first, then fall back to global config
                hangup_delay = getattr(self.config, 'farewell_hangup_delay_sec', 2.5)
                try:
                    session = await self.session_store.get_by_call_id(call_id)
                    if session:
                        provider_name = getattr(session, 'provider', None)
                        if provider_name and provider_name in self.config.providers:
                            provider_cfg = self.config.providers.get(provider_name, {})
                            provider_delay = provider_cfg.get('farewell_hangup_delay_sec') if isinstance(provider_cfg, dict) else getattr(provider_cfg, 'farewell_hangup_delay_sec', None)
                            if provider_delay is not None:
                                hangup_delay = provider_delay
                                logger.debug(
                                    "Using provider-specific farewell delay",
                                    call_id=call_id,
                                    provider=provider_name,
                                    delay=hangup_delay
                                )
                except Exception as e:
                    logger.debug(f"Could not get provider delay, using global: {e}")
                
                await asyncio.sleep(hangup_delay)
                
                try:
                    session = await self.session_store.get_by_call_id(call_id)
                    if session:
                        await self.ari_client.hangup_channel(session.caller_channel_id)
                        logger.info(
                            "âœ… Call hung up successfully (farewell completed)",
                            call_id=call_id,
                            channel_id=session.caller_channel_id
                        )
                    else:
                        logger.warning("No session found for HangupReady", call_id=call_id)
                except Exception as e:
                    logger.error(
                        "Failed to hangup after farewell",
                        call_id=call_id,
                        error=str(e),
                        exc_info=True
                    )
            
            elif etype == "function_call":
                # Handle tool/function calls from providers (ElevenLabs, etc.)
                function_name = event.get("function_name")
                function_call_id = event.get("function_call_id")
                parameters = event.get("parameters", {})
                
                logger.info(
                    "ðŸ”§ Function call received from provider",
                    call_id=call_id,
                    function_name=function_name,
                    function_call_id=function_call_id,
                )
                
                # Execute tool using tool registry
                try:
                    result = await self._execute_provider_tool(
                        call_id=call_id,
                        function_name=function_name,
                        function_call_id=function_call_id,
                        parameters=parameters,
                        session=session,
                    )
                    logger.info(
                        "âœ… Tool execution complete",
                        call_id=call_id,
                        function_name=function_name,
                        status=result.get("status"),
                    )
                except Exception as e:
                    logger.error(
                        "âŒ Tool execution failed",
                        call_id=call_id,
                        function_name=function_name,
                        error=str(e),
                        exc_info=True,
                    )
            
            elif etype == "ToolCall":
                # Handle tool calls from local LLM (parsed from text response)
                tool_calls = event.get("tool_calls", [])
                text_response = event.get("text")
                
                logger.info(
                    "ðŸ”§ Tool calls parsed from local LLM",
                    call_id=call_id,
                    tools=[tc.get("name") for tc in tool_calls],
                    has_text=bool(text_response),
                )
                
                # Execute each tool call
                for tool_call in tool_calls:
                    tool_name = tool_call.get("name")
                    parameters = tool_call.get("parameters", {})
                    
                    try:
                        result = await self._execute_provider_tool(
                            call_id=call_id,
                            function_name=tool_name,
                            function_call_id=f"local-{tool_name}",
                            parameters=parameters,
                            session=session,
                        )
                        logger.info(
                            "âœ… Local tool execution complete",
                            call_id=call_id,
                            tool_name=tool_name,
                            status=result.get("status"),
                        )
                        
                        # Handle terminal tools (hangup, transfer)
                        if result.get("will_hangup"):
                            # For local provider, we need to synthesize farewell via TTS
                            farewell = "Goodbye"  # Keep it simple and short
                            provider_name = getattr(session, 'provider_name', None)
                            local_provider = self._call_providers.get(call_id) if provider_name else None
                            
                            logger.info(
                                "ðŸŽ¤ Preparing farewell TTS",
                                call_id=call_id,
                                provider_name=provider_name,
                                has_provider=bool(local_provider),
                                has_tts_method=hasattr(local_provider, 'text_to_speech') if local_provider else False,
                            )
                            
                            # Get farewell mode from config
                            farewell_mode = "asterisk"  # default
                            farewell_timeout = 30.0
                            try:
                                local_config = self.config.providers.get("local")
                                if local_config:
                                    farewell_mode = getattr(local_config, 'farewell_mode', 'asterisk') or 'asterisk'
                                    farewell_timeout = float(getattr(local_config, 'farewell_timeout_sec', 30.0) or 30.0)
                            except Exception:
                                pass
                            
                            logger.info(
                                "ðŸŽ¤ Farewell mode",
                                call_id=call_id,
                                mode=farewell_mode,
                                timeout_sec=farewell_timeout if farewell_mode == "tts" else "N/A",
                            )
                            
                            if farewell_mode == "tts":
                                # Use TTS farewell - best for fast hardware
                                # Wait for TTS from LLM response to complete
                                logger.info(
                                    "â³ Waiting for TTS farewell",
                                    call_id=call_id,
                                    timeout_sec=farewell_timeout,
                                )
                                await asyncio.sleep(farewell_timeout)
                            else:
                                # Use Asterisk's built-in goodbye sound - reliable for slow hardware
                                try:
                                    await self.ari_client.play_media(
                                        session.caller_channel_id,
                                        "sound:goodbye"
                                    )
                                    # Wait for the sound to play (~2 seconds)
                                    await asyncio.sleep(3.0)
                                    logger.info("âœ… Goodbye sound played", call_id=call_id)
                                except Exception as sound_err:
                                    logger.warning(
                                        "âš ï¸ Failed to play goodbye sound",
                                        call_id=call_id,
                                        error=str(sound_err),
                                    )
                                    await asyncio.sleep(1.0)
                            
                            logger.info("âœ… Farewell wait complete", call_id=call_id)
                            
                            # Explicitly hang up after farewell TTS
                            try:
                                await self.ari_client.hangup_channel(session.caller_channel_id)
                                logger.info("âœ… Call hung up after farewell", call_id=call_id)
                            except Exception:
                                logger.debug("Hangup after farewell failed (may already be hung up)", call_id=call_id)
                            break
                        elif result.get("transferred"):
                            # Transfer already handled
                            break
                    except Exception as e:
                        logger.error(
                            "âŒ Local tool execution failed",
                            call_id=call_id,
                            tool_name=tool_name,
                            error=str(e),
                            exc_info=True,
                        )
            
            elif etype == "transcript":
                # User speech transcript from provider (ElevenLabs, etc.)
                text = event.get("text", "").strip()
                if text and text != "...":
                    # Add to conversation history
                    if not hasattr(session, 'conversation_history') or session.conversation_history is None:
                        session.conversation_history = []
                    session.conversation_history.append({"role": "user", "content": text})
                    await self.session_store.upsert_call(session)
                    logger.debug("Added user transcript to history", call_id=call_id, text_preview=text[:50])
            
            elif etype == "agent_transcript":
                # Agent speech transcript from provider (ElevenLabs, etc.)
                text = event.get("text", "").strip()
                if text and text != "...":
                    # Add to conversation history
                    if not hasattr(session, 'conversation_history') or session.conversation_history is None:
                        session.conversation_history = []
                    session.conversation_history.append({"role": "assistant", "content": text})
                    await self.session_store.upsert_call(session)
                    logger.debug("Added agent transcript to history", call_id=call_id, text_preview=text[:50])
            
            else:
                # Log control/JSON events at debug for now
                logger.debug("Provider control event", provider_event=event)

        except Exception as exc:
            logger.error("Error handling provider event", error=str(exc), exc_info=True)

    def _as_to_pcm16_16k(self, audio_bytes: bytes) -> bytes:
        """Convert AudioSocket inbound bytes to PCM16 @ 16 kHz for pipeline STT.

        Assumes AudioSocket format is 8 kHz Î¼-law (default) or PCM16.
        """
        try:
            fmt = None
            try:
                if self.config and getattr(self.config, 'audiosocket', None):
                    fmt = (self.config.audiosocket.format or 'ulaw').lower()
            except Exception:
                fmt = 'ulaw'
            if fmt in ('ulaw', 'mulaw', 'g711_ulaw'):
                pcm8k = audioop.ulaw2lin(audio_bytes, 2)
            else:
                # Treat as PCM16 8 kHz
                pcm8k = audio_bytes
            try:
                # Use pipeline16k resample state under synthetic key 'pipeline'
                state = self._resample_state_pipeline16k.get('pipeline')
                pcm16, state = audioop.ratecv(pcm8k, 2, 1, 8000, 16000, state)
                self._resample_state_pipeline16k['pipeline'] = state
            except Exception:
                pcm16 = pcm8k
            return pcm16
        except Exception:
            logger.debug("AudioSocket -> PCM16 16k conversion failed", exc_info=True)
            return audio_bytes

    async def _ensure_pipeline_runner(self, session: CallSession, *, forced: bool = False) -> None:
        """Create per-call queue and start pipeline runner if not already started."""
        call_id = session.call_id
        if call_id in self._pipeline_tasks:
            if forced:
                self._pipeline_forced[call_id] = True
            return
        # Require orchestrator enabled and a selected pipeline
        if not getattr(self, 'pipeline_orchestrator', None) or not self.pipeline_orchestrator.enabled:
            return
        if not getattr(session, 'pipeline_name', None):
            return
        # Create queue and start task
        q: asyncio.Queue = asyncio.Queue(maxsize=200)
        self._pipeline_queues[call_id] = q
        self._pipeline_forced[call_id] = bool(forced)
        # Pipelines: enable Asterisk talk detection so barge-in can trigger even when
        # ExternalMedia RTP delivery is paused/altered during channel playback.
        try:
            await self._enable_pipeline_talk_detect(session)
        except Exception:
            logger.debug("Pipeline talk detect enable failed", call_id=call_id, exc_info=True)
        task = asyncio.create_task(self._pipeline_runner(call_id))
        self._pipeline_tasks[call_id] = task
        logger.info("Pipeline runner started", call_id=call_id, pipeline=session.pipeline_name)

    async def _pipeline_runner(self, call_id: str) -> None:
        """Minimal adapter-driven loop: STT -> LLM -> TTS -> file playback.

        Designed to be opt-in (forced via AI_PROVIDER=pipeline_name) to avoid
        impacting the tested ExternalMedia + Local full-agent path.
        """
        try:
            session = await self.session_store.get_by_call_id(call_id)
            if not session:
                return
            pipeline = self.pipeline_orchestrator.get_pipeline(call_id, getattr(session, 'pipeline_name', None))
            if not pipeline:
                logger.debug("Pipeline runner: no pipeline resolved", call_id=call_id)
                return
            # Inject context prompt into LLM options with fallback chain
            # Fallback chain: AI_CONTEXT â†’ pipeline default â†’ global llm_config
            llm_options = pipeline.llm_options or {}
            prompt_source = "pipeline_default"
            try:
                # Priority 1: Check if context has a custom prompt
                # Use session.context_name (persisted string) instead of transport_profile.context (object may not persist)
                context_prompt_injected = False
                context_name = getattr(session, 'context_name', None)
                if context_name:
                    context_config = self.transport_orchestrator.get_context_config(context_name)
                    if context_config and context_config.prompt:
                            # Create a copy to avoid mutating the pipeline's original options
                            llm_options = dict(llm_options)
                            llm_options['system_prompt'] = context_config.prompt
                            prompt_source = "context_injection"
                            context_prompt_injected = True
                            logger.info(
                                "Pipeline LLM prompt resolved from context",
                                call_id=call_id,
                                context=context_name,
                                prompt_length=len(context_config.prompt),
                                prompt_preview=context_config.prompt[:80] + "..." if len(context_config.prompt) > 80 else context_config.prompt,
                            )
                
                # Priority 2: If no context prompt, check if pipeline has default or use global
                if not context_prompt_injected:
                    # Check if system_prompt already in llm_options (pipeline default)
                    if llm_options.get('system_prompt'):
                        prompt_source = "pipeline_default"
                        logger.info(
                            "Pipeline LLM prompt using pipeline default",
                            call_id=call_id,
                            prompt_length=len(llm_options['system_prompt']),
                        )
                    else:
                        # Priority 3: Fall back to global llm_config
                        global_prompt = getattr(self.config.llm, 'prompt', None)
                        if global_prompt:
                            llm_options = dict(llm_options)
                            llm_options['system_prompt'] = global_prompt
                            prompt_source = "global_llm_config"
                            logger.info(
                                "Pipeline LLM prompt resolved from global config",
                                call_id=call_id,
                                prompt_length=len(global_prompt),
                            )
            except Exception as exc:
                logger.error(
                    "Failed to inject context prompt into pipeline LLM options",
                    call_id=call_id,
                    error=str(exc),
                    exc_info=True,
                )
                prompt_source = "error"
            
            # Open per-call state for adapters (best-effort)
            try:
                await pipeline.stt_adapter.open_call(call_id, pipeline.stt_options)
            except Exception:
                logger.debug("STT open_call failed", call_id=call_id, exc_info=True)
            else:
                logger.info("Pipeline STT adapter session opened", call_id=call_id)
            try:
                await pipeline.llm_adapter.open_call(call_id, llm_options)
            except Exception:
                logger.debug("LLM open_call failed", call_id=call_id, exc_info=True)
            else:
                logger.info("Pipeline LLM adapter session opened", call_id=call_id)
            try:
                await pipeline.tts_adapter.open_call(call_id, pipeline.tts_options)
            except Exception:
                logger.debug("TTS open_call failed", call_id=call_id, exc_info=True)
            else:
                logger.info("Pipeline TTS adapter session opened", call_id=call_id)

            # Pipeline-managed initial greeting (optional)
            # Fallback chain: AI_CONTEXT â†’ global llm_config â†’ empty
            greeting = ""
            greeting_source = "none"
            try:
                # Priority 1: Check if context has a custom greeting
                # Use session.context_name (persisted string) instead of transport_profile.context
                context_name = getattr(session, 'context_name', None)
                if context_name:
                    context_config = self.transport_orchestrator.get_context_config(context_name)
                    if context_config and context_config.greeting:
                        greeting = context_config.greeting.strip()
                        greeting_source = "context_injection"
                        logger.info(
                            "Pipeline greeting resolved from context",
                            call_id=call_id,
                            context=context_name,
                            greeting_length=len(greeting),
                        )
                
                # Priority 2: Fall back to global config greeting
                if not greeting:
                    global_greeting = (getattr(self.config.llm, "initial_greeting", None) or "").strip()
                    if global_greeting:
                        greeting = global_greeting
                        greeting_source = "global_llm_config"
                        logger.info(
                            "Pipeline greeting resolved from global config",
                            call_id=call_id,
                            greeting_length=len(greeting),
                        )
                
                # Log if no greeting found
                if not greeting:
                    logger.info(
                        "Pipeline greeting not configured (no greeting will be played)",
                        call_id=call_id,
                    )
            except Exception as exc:
                logger.error(
                    "Pipeline greeting resolution failed",
                    call_id=call_id,
                    error=str(exc),
                    exc_info=True,
                )
                greeting = ""
                greeting_source = "error"
            
            # Apply template substitution for personalized greetings
            if greeting:
                try:
                    caller_name = getattr(session, 'caller_name', None) or "there"
                    caller_number = getattr(session, 'caller_number', None) or "unknown"
                    greeting = greeting.format(
                        caller_name=caller_name,
                        caller_number=caller_number
                    )
                    logger.debug(
                        "Applied greeting template substitution",
                        call_id=call_id,
                        caller_name=caller_name,
                        greeting_length=len(greeting)
                    )
                except KeyError as e:
                    logger.warning(
                        "Greeting template has invalid placeholder",
                        call_id=call_id,
                        error=str(e)
                    )
                except Exception as e:
                    logger.warning(
                        "Failed to apply greeting template substitution",
                        call_id=call_id,
                        error=str(e)
                    )
            
            if greeting:
                max_attempts = 2
                for attempt in range(1, max_attempts + 1):
                    try:
                        tts_bytes = bytearray()
                        async for chunk in pipeline.tts_adapter.synthesize(call_id, greeting, pipeline.tts_options):
                            if chunk:
                                tts_bytes.extend(chunk)
                        if not tts_bytes:
                            logger.warning(
                                "Pipeline greeting produced no audio",
                                call_id=call_id,
                                attempt=attempt,
                            )
                        else:
                            await self.playback_manager.play_audio(call_id, bytes(tts_bytes), "pipeline-tts-greeting")
                            
                            # AAVA-85: Persist greeting to session history so it appears in email summary
                            try:
                                session.conversation_history.append({"role": "assistant", "content": greeting})
                                await self.session_store.upsert_call(session)
                                logger.info("Persisted initial greeting to session history", call_id=call_id)
                            except Exception as e:
                                logger.warning("Failed to persist greeting history", call_id=call_id, error=str(e))
                                
                        break
                    except RuntimeError as exc:
                        error_text = str(exc).lower()
                        if attempt < max_attempts and "session" in error_text:
                            logger.debug(
                                "Pipeline greeting retry after session error",
                                call_id=call_id,
                                attempt=attempt,
                                exc_info=True,
                            )
                            try:
                                await pipeline.tts_adapter.open_call(call_id, pipeline.tts_options)
                                continue
                            except Exception:
                                logger.debug(
                                    "Pipeline greeting re-open_call failed",
                                    call_id=call_id,
                                    attempt=attempt,
                                    exc_info=True,
                                )
                        logger.error(
                            "Pipeline greeting synthesis failed",
                            call_id=call_id,
                            attempt=attempt,
                            error=str(exc),
                            exc_info=True,
                        )
                        break
                    except Exception:
                        logger.error(
                            "Pipeline greeting unexpected failure",
                            call_id=call_id,
                            attempt=attempt,
                            exc_info=True,
                        )
                        break

            # Accumulate into ~160ms chunks for STT while keeping ingestion responsive
            bytes_per_ms = 32  # 16k Hz * 2 bytes / 1000 ms
            base_commit_ms = 160
            stt_chunk_ms = int(pipeline.stt_options.get("chunk_ms", base_commit_ms)) if pipeline.stt_options else base_commit_ms
            commit_ms = max(stt_chunk_ms, 80)
            commit_bytes = bytes_per_ms * commit_ms

            inbound_queue = self._pipeline_queues.get(call_id)
            if not inbound_queue:
                return

            buffer_queue: asyncio.Queue[Optional[bytes]] = asyncio.Queue(maxsize=200)
            transcript_queue: asyncio.Queue[Optional[str]] = asyncio.Queue(maxsize=8)

            use_streaming = bool((pipeline.stt_options or {}).get("streaming", False))
            if use_streaming:
                streaming_supported = all(
                    hasattr(pipeline.stt_adapter, attr)
                    for attr in ("start_stream", "send_audio", "iter_results", "stop_stream")
                )
                if not streaming_supported:
                    logger.warning(
                        "Streaming STT requested but adapter does not support streaming APIs; falling back to chunked mode",
                        call_id=call_id,
                        component=getattr(pipeline.stt_adapter, "component_key", "unknown"),
                    )
                    use_streaming = False
            stream_format = (pipeline.stt_options or {}).get("stream_format", "pcm16_16k")
            if use_streaming:
                try:
                    logger.info(
                        "Streaming STT enabled",
                        call_id=call_id,
                        commit_ms=commit_ms,
                        stream_format=stream_format,
                        buffer_max=getattr(buffer_queue, "_maxsize", 200) if hasattr(buffer_queue, "_maxsize") else 200,
                    )
                except Exception:
                    logger.debug("Streaming STT info log failed", exc_info=True)

            async def enqueue_buffer(item: Optional[bytes]) -> None:
                if item is None:
                    await buffer_queue.put(None)
                    return
                while True:
                    if buffer_queue.full():
                        dropped = await buffer_queue.get()
                        if dropped is not None:
                            logger.debug(
                                "Pipeline audio buffer overflow; dropping oldest frame",
                                call_id=call_id,
                            )
                        continue
                    await buffer_queue.put(item)
                    return

            async def ingest_audio() -> None:
                try:
                    while True:
                        chunk = await inbound_queue.get()
                        if chunk is None:
                            await enqueue_buffer(None)
                            break
                        await enqueue_buffer(chunk)
                except asyncio.CancelledError:
                    pass

            if not use_streaming:

                async def process_audio(audio_chunk: bytes) -> None:
                    transcript = ""
                    try:
                        transcript = await pipeline.stt_adapter.transcribe(
                            call_id,
                            audio_chunk,
                            16000,
                            pipeline.stt_options,
                        )
                    except Exception:
                        logger.debug("STT transcribe failed", call_id=call_id, exc_info=True)
                        return
                    transcript = (transcript or "").strip()
                    if not transcript:
                        return
                    # Record time when a final transcript is obtained
                    try:
                        self._last_transcript_ts[call_id] = time.time()
                    except Exception:
                        pass
                    try:
                        transcript_queue.put_nowait(transcript)
                    except asyncio.QueueFull:
                        try:
                            dropped = transcript_queue.get_nowait()
                            logger.warning(
                                "Pipeline transcript backlog full; dropping oldest transcript",
                                call_id=call_id,
                                dropped_preview=(dropped or "")[:80] if dropped else "",
                            )
                        except asyncio.QueueEmpty:
                            pass
                        await transcript_queue.put(transcript)

                async def stt_worker() -> None:
                    local_buf = bytearray()
                    try:
                        while True:
                            frame = await buffer_queue.get()
                            if frame is None:
                                if local_buf:
                                    await process_audio(bytes(local_buf))
                                await transcript_queue.put(None)
                                break
                            local_buf.extend(frame)
                            if len(local_buf) < commit_bytes:
                                continue
                            await process_audio(bytes(local_buf))
                            local_buf.clear()
                    except asyncio.CancelledError:
                        pass

            else:

                async def stt_sender() -> None:
                    local_buf = bytearray()
                    try:
                        while True:
                            frame = await buffer_queue.get()
                            if frame is None:
                                if local_buf:
                                    try:
                                        await pipeline.stt_adapter.send_audio(
                                            call_id,
                                            bytes(local_buf),
                                            fmt=stream_format,
                                        )
                                    except Exception:
                                        logger.debug(
                                            "Streaming STT final send failed",
                                            call_id=call_id,
                                            exc_info=True,
                                        )
                                    local_buf.clear()
                                break
                            local_buf.extend(frame)
                            if len(local_buf) < commit_bytes:
                                continue
                            chunk = bytes(local_buf)
                            local_buf.clear()
                            try:
                                await pipeline.stt_adapter.send_audio(
                                    call_id,
                                    chunk,
                                    fmt=stream_format,
                                )
                            except Exception:
                                logger.debug(
                                    "Streaming STT send failed",
                                    call_id=call_id,
                                    exc_info=True,
                                )
                    except asyncio.CancelledError:
                        pass

                async def stt_receiver() -> None:
                    try:
                        async for final in pipeline.stt_adapter.iter_results(call_id):
                            try:
                                # Record time when a final transcript arrives
                                self._last_transcript_ts[call_id] = time.time()
                                transcript_queue.put_nowait(final)
                            except asyncio.QueueFull:
                                try:
                                    transcript_queue.get_nowait()
                                except asyncio.QueueEmpty:
                                    pass
                                await transcript_queue.put(final)
                    except asyncio.CancelledError:
                        pass
                    except Exception:
                        logger.debug(
                            "Streaming STT receive loop error",
                            call_id=call_id,
                            exc_info=True,
                        )
                    finally:
                        try:
                            transcript_queue.put_nowait(None)
                        except asyncio.QueueFull:
                            pass

            async def dialog_worker() -> None:
                pending_segments: List[str] = []
                flush_task: Optional[asyncio.Task] = None
                accumulation_timeout = float(
                    (pipeline.llm_options or {}).get("aggregation_timeout_sec", 2.0)
                )
                # Track conversation history to include prior messages
                # AAVA-85 FIX: Initialize from session to preserve greeting
                conversation_history: List[Dict[str, str]] = list(session.conversation_history or [])

                async def cancel_flush() -> None:
                    nonlocal flush_task
                    if flush_task and not flush_task.done():
                        current = asyncio.current_task()
                        if flush_task is not current:
                            flush_task.cancel()
                    flush_task = None

                async def run_turn(transcript_text: str) -> None:
                    nonlocal conversation_history
                    response_text = ""
                    tool_calls = []
                    turn_start_time = time.time()  # Track turn latency for call history
                    
                    pipeline_label = getattr(session, 'pipeline_name', None) or 'none'
                    provider_label = getattr(session, 'provider_name', None) or 'unknown'
                    t_start = self._last_transcript_ts.get(call_id)
                    
                    # Build context with conversation history
                    # System prompt only in first turn (when history is empty)
                    context_for_llm = {"prior_messages": list(conversation_history)}
                    
                    try:
                        llm_result = await pipeline.llm_adapter.generate(
                            call_id,
                            transcript_text,
                            context_for_llm,  # Include conversation history
                            llm_options,  # Use context-injected options (includes system_prompt)
                        )
                    except Exception:
                        logger.debug("LLM generate failed", call_id=call_id, exc_info=True)
                        return

                    # Handle structured LLM response with tool calls
                    if isinstance(llm_result, LLMResponse):
                        response_text = (llm_result.text or "").strip()
                        tool_calls = llm_result.tool_calls
                    else:
                        response_text = (str(llm_result) or "").strip()
                        tool_calls = []

                    if not response_text and not tool_calls:
                        return
                    
                    # Update conversation history
                    conversation_history.append({"role": "user", "content": transcript_text})
                    if response_text:
                        conversation_history.append({"role": "assistant", "content": response_text})
                    elif tool_calls:
                        conversation_history.append({"role": "assistant", "content": "(tool execution)"})
                    
                    # AAVA-85: Persist session history so tools (email) can access it
                    session.conversation_history = list(conversation_history)
                    await self.session_store.upsert_call(session)

                    playback_id = None
                    
                    # 1. Synthesize and Play Text (if any)
                    if response_text:
                        tts_bytes = bytearray()
                        first_tts_ts: Optional[float] = None
                        try:
                            async for tts_chunk in pipeline.tts_adapter.synthesize(
                                call_id,
                                response_text,
                                pipeline.tts_options,
                            ):
                                if tts_chunk:
                                    if first_tts_ts is None:
                                        first_tts_ts = time.time()
                                        # Track turn latency for call history (Milestone 21)
                                        turn_latency_ms = (first_tts_ts - turn_start_time) * 1000
                                        session.turn_latencies_ms.append(turn_latency_ms)
                                        try:
                                            if t_start is not None:
                                                _TURN_STT_TO_TTS.labels(pipeline_label, provider_label).observe(max(0.0, first_tts_ts - t_start))
                                        except Exception:
                                            pass
                                    tts_bytes.extend(tts_chunk)
                        except Exception:
                            logger.debug("TTS synth failed", call_id=call_id, exc_info=True)
                            # If TTS fails but we have tools, continue to tools
                            if not tool_calls:
                                return
                        
                        if tts_bytes:
                            try:
                                playback_id = await self.playback_manager.play_audio(
                                    call_id,
                                    bytes(tts_bytes),
                                    "pipeline-tts",
                                )
                                try:
                                    if playback_id and t_start is not None:
                                        _TURN_RESPONSE_SECONDS.labels(pipeline_label, provider_label).observe(max(0.0, time.time() - t_start))
                                except Exception:
                                    pass
                                if not playback_id:
                                    logger.error(
                                        "Pipeline playback failed",
                                        call_id=call_id,
                                        size=len(tts_bytes),
                                    )
                            except Exception:
                                logger.error("Pipeline playback exception", call_id=call_id, exc_info=True)

                    # 2. Execute Tools (if any)
                    if tool_calls:
                        # Respect global tools toggle
                        try:
                            if isinstance(self.config.tools, dict) and not bool(self.config.tools.get("enabled", True)):
                                logger.debug("Tools disabled; skipping pipeline tool execution", call_id=call_id)
                                return
                        except Exception:
                            pass

                        # Wait for playback to finish before executing tools (especially transfer/hangup)
                        if playback_id:
                            try:
                                # Best effort wait to let user hear the response
                                await asyncio.sleep(len(response_text) * 0.08)
                            except Exception:
                                pass

                        from src.tools.context import ToolExecutionContext
                        from src.tools.registry import tool_registry
                        
                        # Create execution context
                        tool_ctx = ToolExecutionContext(
                            call_id=call_id,
                            caller_channel_id=getattr(session, 'channel_id', call_id),
                            session_store=self.session_store,
                            ari_client=self.ari_client,
                            config=self.config.dict(),
                            provider_name="pipeline"
                        )

                        for tool_call in tool_calls:
                            try:
                                name = tool_call.get("name")
                                args = tool_call.get("parameters") or {}
                                tool = tool_registry.get(name)
                                
                                if tool:
                                    logger.info("Executing pipeline tool", tool=name, call_id=call_id)
                                    # Slow-response UX (pipeline only): speak a waiting message if the tool takes too long.
                                    slow_threshold_ms = int(getattr(tool, "slow_response_threshold_ms", 0) or 0)
                                    slow_message = str(getattr(tool, "slow_response_message", "") or "").strip()
                                    tool_task = asyncio.create_task(tool.execute(args, tool_ctx))
                                    if slow_threshold_ms > 0 and slow_message:
                                        done, _pending = await asyncio.wait(
                                            {tool_task},
                                            timeout=float(slow_threshold_ms) / 1000.0,
                                        )
                                        if not done:
                                            try:
                                                wait_bytes = bytearray()
                                                async for chunk in pipeline.tts_adapter.synthesize(call_id, slow_message, pipeline.tts_options):
                                                    if chunk:
                                                        wait_bytes.extend(chunk)
                                                if wait_bytes:
                                                    wait_pid = await self.playback_manager.play_audio(call_id, bytes(wait_bytes), "pipeline-wait")
                                                    if wait_pid:
                                                        await self.playback_manager.wait_for_playback_end(
                                                            call_id,
                                                            wait_pid,
                                                            timeout_sec=(len(wait_bytes) / 8000.0 + 3.0),
                                                        )
                                            except Exception:
                                                logger.debug("Failed to speak slow-response message", call_id=call_id, exc_info=True)
                                    result = await tool_task
                                    logger.info("Tool execution result", tool=name, result=result)
                                    
                                    # Handle Hangup (AAVA-85 Fix)
                                    if result.get("will_hangup"):
                                        farewell = result.get("message")
                                        if farewell:
                                            # Add farewell to conversation history for email
                                            conversation_history.append({"role": "assistant", "content": farewell})
                                            session.conversation_history = list(conversation_history)
                                            await self.session_store.upsert_call(session)
                                            logger.info("Farewell added to conversation history", call_id=call_id)
                                            
                                            # Speak farewell
                                            try:
                                                # Re-use TTS synthesis for farewell
                                                fw_bytes = bytearray()
                                                async for chunk in pipeline.tts_adapter.synthesize(call_id, farewell, pipeline.tts_options):
                                                    fw_bytes.extend(chunk)
                                                if fw_bytes:
                                                    pid = await self.playback_manager.play_audio(call_id, bytes(fw_bytes), "pipeline-farewell")
                                                    # Calculate actual duration: mulaw 8kHz = 8000 bytes/sec
                                                    duration_sec = len(fw_bytes) / 8000.0
                                                    # Wait for farewell (interruptible by barge-in) + small buffer
                                                    if pid:
                                                        await self.playback_manager.wait_for_playback_end(
                                                            call_id,
                                                            pid,
                                                            timeout_sec=(duration_sec + 3.0),
                                                        )
                                                    logger.info("Farewell playback completed", duration_sec=duration_sec, call_id=call_id)
                                            except Exception as e:
                                                logger.error("Farewell TTS failed", error=str(e))
                                        
                                        logger.info("Executing explicit hangup via ARI", call_id=call_id)
                                        try:
                                            channel_id = getattr(session, 'channel_id', call_id)
                                            await self.ari_client.hangup_channel(channel_id)
                                        except Exception as e:
                                            logger.error("ARI hangup failed", error=str(e))
                                        return

                                    # Handle Terminal Transfer
                                    if name in ["transfer"] and result.get("status") == "success":
                                        logger.info("Transfer successful, ending turn loop", tool=name)
                                        return
                                    
                                    # Handle non-terminal tools (e.g., request_transcript)
                                    # Feed result back to LLM for continuation
                                    if not result.get("will_hangup") and name not in ["transfer"]:
                                        tool_result_msg = result.get("message", f"Tool {name} executed successfully.")
                                        # Add tool result to conversation history
                                        conversation_history.append({
                                            "role": "assistant",
                                            "content": None,
                                            "tool_calls": [{"id": f"call_{name}", "type": "function", "function": {"name": name, "arguments": json.dumps(args)}}]
                                        })
                                        conversation_history.append({
                                            "role": "tool",
                                            "tool_call_id": f"call_{name}",
                                            "content": tool_result_msg
                                        })
                                        logger.info("Tool result added to conversation, triggering LLM continuation", tool=name, call_id=call_id)
                                        
                                        # Trigger LLM to generate follow-up response
                                        try:
                                            context_for_llm = {"prior_messages": list(conversation_history)}
                                            llm_response = await pipeline.llm_adapter.generate(
                                                call_id,
                                                "",  # Empty transcript - tool result already in context
                                                context_for_llm,
                                                pipeline.llm_options
                                            )
                                            if llm_response:
                                                # Handle text response if present
                                                if getattr(llm_response, 'text', None):
                                                    response_text = llm_response.text.strip()
                                                    if response_text:
                                                        conversation_history.append({"role": "assistant", "content": response_text})
                                                        logger.info("LLM continuation response", preview=response_text[:80], call_id=call_id)
                                                        
                                                        # Synthesize and play TTS
                                                        tts_bytes = bytearray()
                                                        async for chunk in pipeline.tts_adapter.synthesize(call_id, response_text, pipeline.tts_options):
                                                            if chunk:
                                                                tts_bytes.extend(chunk)
                                                        if tts_bytes:
                                                            pid = await self.playback_manager.play_audio(call_id, bytes(tts_bytes), "pipeline-tts")
                                                            duration_sec = len(tts_bytes) / 8000.0
                                                            if pid:
                                                                await self.playback_manager.wait_for_playback_end(
                                                                    call_id,
                                                                    pid,
                                                                    timeout_sec=(duration_sec + 3.0),
                                                                )
                                                
                                                # Handle tool calls (with or without text)
                                                if getattr(llm_response, 'tool_calls', None):
                                                    for next_tc in llm_response.tool_calls:
                                                        next_name = next_tc.get("name")
                                                        next_args = next_tc.get("parameters") or {}
                                                        next_tool = tool_registry.get(next_name)
                                                        if next_tool:
                                                            logger.info("Executing follow-up tool", tool=next_name, call_id=call_id)
                                                            slow_threshold_ms = int(getattr(next_tool, "slow_response_threshold_ms", 0) or 0)
                                                            slow_message = str(getattr(next_tool, "slow_response_message", "") or "").strip()
                                                            next_task = asyncio.create_task(next_tool.execute(next_args, tool_ctx))
                                                            if slow_threshold_ms > 0 and slow_message:
                                                                done, _pending = await asyncio.wait(
                                                                    {next_task},
                                                                    timeout=float(slow_threshold_ms) / 1000.0,
                                                                )
                                                                if not done:
                                                                    try:
                                                                        wait_bytes = bytearray()
                                                                        async for chunk in pipeline.tts_adapter.synthesize(call_id, slow_message, pipeline.tts_options):
                                                                            if chunk:
                                                                                wait_bytes.extend(chunk)
                                                                        if wait_bytes:
                                                                            wait_pid = await self.playback_manager.play_audio(call_id, bytes(wait_bytes), "pipeline-wait")
                                                                            if wait_pid:
                                                                                await self.playback_manager.wait_for_playback_end(
                                                                                    call_id,
                                                                                    wait_pid,
                                                                                    timeout_sec=(len(wait_bytes) / 8000.0 + 3.0),
                                                                                )
                                                                    except Exception:
                                                                        logger.debug("Failed to speak slow-response message", call_id=call_id, exc_info=True)
                                                            next_result = await next_task
                                                            if next_result.get("will_hangup"):
                                                                farewell = next_result.get("message", "Goodbye!")
                                                                conversation_history.append({"role": "assistant", "content": farewell})
                                                                session.conversation_history = list(conversation_history)
                                                                await self.session_store.upsert_call(session)
                                                                fw_bytes = bytearray()
                                                                async for chunk in pipeline.tts_adapter.synthesize(call_id, farewell, pipeline.tts_options):
                                                                    fw_bytes.extend(chunk)
                                                                if fw_bytes:
                                                                    fw_pid = await self.playback_manager.play_audio(call_id, bytes(fw_bytes), "pipeline-farewell")
                                                                    if fw_pid:
                                                                        await self.playback_manager.wait_for_playback_end(
                                                                            call_id,
                                                                            fw_pid,
                                                                            timeout_sec=(len(fw_bytes) / 8000.0 + 3.0),
                                                                        )
                                                                await self.ari_client.hangup_channel(getattr(session, 'channel_id', call_id))
                                                                return
                                        except Exception as e:
                                            logger.error("LLM continuation failed", error=str(e), exc_info=True)
                                else:
                                    logger.warning("Tool not found", tool=name)
                            except Exception as e:
                                logger.error("Tool execution failed", tool=name, error=str(e), exc_info=True)

                async def maybe_respond(force: bool, from_flush: bool = False) -> None:
                    nonlocal pending_segments, flush_task
                    if not pending_segments:
                        if from_flush:
                            flush_task = None
                        else:
                            await cancel_flush()
                        return
                    aggregated = " ".join(pending_segments).strip()
                    if not aggregated:
                        pending_segments.clear()
                        if from_flush:
                            flush_task = None
                        else:
                            await cancel_flush()
                        return
                    words = len([w for w in aggregated.split() if w])
                    chars = len(aggregated.replace(" ", ""))
                    threshold_met = words >= 3 or chars >= 12
                    if not threshold_met:
                        if force:
                            pending_segments.clear()
                            if from_flush:
                                flush_task = None
                            else:
                                await cancel_flush()
                        else:
                            logger.debug(
                                "Accumulating transcript before LLM",
                                call_id=call_id,
                                preview=aggregated[:80],
                                chars=chars,
                                words=words,
                            )
                        return
                    if from_flush:
                        flush_task = None
                    else:
                        await cancel_flush()
                    await run_turn(aggregated)
                    pending_segments.clear()

                async def schedule_flush() -> None:
                    nonlocal flush_task
                    await cancel_flush()

                    async def _flush() -> None:
                        try:
                            await asyncio.sleep(accumulation_timeout)
                            await maybe_respond(force=True, from_flush=True)
                        except asyncio.CancelledError:
                            pass

                    flush_task = asyncio.create_task(_flush())

                try:
                    while True:
                        transcript = await transcript_queue.get()
                        if transcript is None:
                            await maybe_respond(force=True)
                            break
                        normalized = (transcript or "").strip()
                        if not normalized:
                            if pending_segments and flush_task is None:
                                await schedule_flush()
                            continue
                        pending_segments.append(normalized)
                        await maybe_respond(force=False)
                        if pending_segments:
                            await schedule_flush()
                except asyncio.CancelledError:
                    pass
                finally:
                    await cancel_flush()

            ingest_task = asyncio.create_task(ingest_audio())

            if use_streaming:
                stt_send_task: Optional[asyncio.Task] = None
                stt_recv_task: Optional[asyncio.Task] = None
                dialog_task: Optional[asyncio.Task] = None
                stop_called = False

                try:
                    await pipeline.stt_adapter.start_stream(call_id, pipeline.stt_options or {})
                    stt_send_task = asyncio.create_task(stt_sender())
                    stt_recv_task = asyncio.create_task(stt_receiver())
                    dialog_task = asyncio.create_task(dialog_worker())

                    if stt_send_task:
                        await stt_send_task
                    await pipeline.stt_adapter.stop_stream(call_id)
                    stop_called = True
                    await asyncio.gather(
                        *(task for task in (stt_recv_task, dialog_task) if task is not None),
                        return_exceptions=True,
                    )
                finally:
                    ingest_task.cancel()
                    tasks_to_cancel = []
                    for task in (stt_send_task, stt_recv_task, dialog_task):
                        if task and not task.done():
                            task.cancel()
                            tasks_to_cancel.append(task)
                    await asyncio.gather(ingest_task, *tasks_to_cancel, return_exceptions=True)
                    if not stop_called:
                        await pipeline.stt_adapter.stop_stream(call_id)
            else:
                stt_task = asyncio.create_task(stt_worker())
                dialog_task = asyncio.create_task(dialog_worker())

                try:
                    await dialog_task
                finally:
                    ingest_task.cancel()
                    stt_task.cancel()
                    await asyncio.gather(ingest_task, stt_task, return_exceptions=True)
        except asyncio.CancelledError:
            pass
        except Exception:
            logger.error("Pipeline runner crashed", call_id=call_id, exc_info=True)

    async def _hydrate_transport_from_dialplan(self, session: CallSession, channel_id: str) -> None:
        """Load transport hints (format/rate) provided by the dialplan via channel vars."""
        fmt_token: Optional[str] = None
        rate_value: Optional[int] = None

        # Fetch AI_TRANSPORT_FORMAT (e.g., ulaw, slin16)
        try:
            resp = await self.ari_client.send_command(
                "GET",
                f"channels/{channel_id}/variable",
                params={"variable": "AI_TRANSPORT_FORMAT"},
            )
            if isinstance(resp, dict):
                value = (resp.get("value") or "").strip()
                if value:
                    fmt_token = value
        except Exception:
            logger.debug(
                "Dialplan transport format fetch failed",
                call_id=channel_id,
                exc_info=True,
            )

        # Fetch AI_TRANSPORT_RATE (integer Hz)
        try:
            resp = await self.ari_client.send_command(
                "GET",
                f"channels/{channel_id}/variable",
                params={"variable": "AI_TRANSPORT_RATE"},
            )
            if isinstance(resp, dict):
                raw = (resp.get("value") or "").strip()
                if raw:
                    rate_value = int(float(raw))
        except Exception:
            logger.debug(
                "Dialplan transport rate fetch failed",
                call_id=channel_id,
                exc_info=True,
            )

        if fmt_token is None and rate_value is None:
            return

        canonical_fmt: Optional[str] = None
        if fmt_token is not None:
            canonical_fmt = self._canonicalize_encoding(fmt_token)
            if canonical_fmt:
                session.caller_audio_format = canonical_fmt

        if rate_value is not None and rate_value > 0:
            session.caller_sample_rate = rate_value
        else:
            rate_value = None

        await self._update_transport_profile(
            session,
            fmt=canonical_fmt,
            sample_rate=rate_value,
            source="dialplan",
        )

        try:
            logger.info(
                "Hydrated transport profile from dialplan",
                call_id=session.call_id,
                transport_format=canonical_fmt,
                transport_rate=rate_value,
            )
        except Exception:
            pass

    async def _detect_caller_codec(self, session: CallSession, channel_id: str) -> None:
        """Inspect the caller channel via ARI and record its audio format/sample-rate."""
        preferred_fmt: Optional[str] = None
        variables = (
            "CHANNEL(audionativeformat)",
            "CHANNEL(audioreadformat)",
        )

        for variable in variables:
            try:
                resp = await self.ari_client.send_command(
                    "GET",
                    f"channels/{channel_id}/variable",
                    params={"variable": variable},
                )
            except Exception:
                logger.debug("Codec variable fetch failed", call_id=channel_id, variable=variable, exc_info=True)
                continue

            if isinstance(resp, dict):
                value = (resp.get("value") or "").strip()
                if value:
                    preferred_fmt = value
                    break

        canonical_fmt, sample_rate, reported = self._normalize_audio_format(preferred_fmt)

        await self._update_transport_profile(
            session,
            fmt=canonical_fmt,
            sample_rate=sample_rate,
            source="detected",
        )

        try:
            logger.info(
                "Detected caller codec",
                call_id=session.call_id,
                reported_format=reported,
                normalized_format=canonical_fmt,
                sample_rate=sample_rate,
            )
        except Exception:
            pass

    @staticmethod
    def _normalize_audio_format(raw_format: Optional[str]) -> Tuple[str, int, str]:
        """Map assorted codec tokens to canonical AudioSocket format + sample rate."""
        reported = (raw_format or "").strip()
        token = reported.lower()

        alias_map = {
            "mulaw": "ulaw",
            "mu-law": "ulaw",
            "g711_ulaw": "ulaw",
            "g711ulaw": "ulaw",
            "g711-ula": "ulaw",
            "g711_alaw": "alaw",
            "g711alaw": "alaw",
            "slin": "slin16",
            "slin12": "slin16",
            "slin16": "slin16",
            "linear16": "slin16",
            "pcm16": "slin16",
            "g722": "slin16",
        }

        canonical = alias_map.get(token, token if token else "ulaw")

        # We only stream Î¼-law or PCM16 internally; fall back to Î¼-law for others (e.g. alaw).
        if canonical not in {"ulaw", "slin16"}:
            canonical = "ulaw"

        sample_map = {
            "ulaw": 8000,
            "slin16": 16000,
        }
        sample_rate = sample_map.get(canonical, 8000)

        # If the original token hinted at 8 kHz PCM, honor it.
        if canonical == "slin16" and token in {"slin", "slin8"}:
            sample_rate = 8000

        return canonical, sample_rate, reported

    async def _resolve_audio_profile(self, session: CallSession, channel_id: str) -> None:
        """
        P1: Resolve audio profile using TransportOrchestrator.
        
        Reads channel variables (AI_PROVIDER, AI_AUDIO_PROFILE, AI_CONTEXT),
        negotiates with provider capabilities, and applies resolved transport to session.
        """
        # Read channel variables
        channel_vars = {}
        for var_name in ['AI_PROVIDER', 'AI_AUDIO_PROFILE', 'AI_CONTEXT']:
            try:
                resp = await self.ari_client.send_command(
                    "GET",
                    f"channels/{channel_id}/variable",
                    params={"variable": var_name},
                    tolerate_statuses=[404],  # 404 is expected when variable not set
                )
                if isinstance(resp, dict):
                    value = (resp.get("value") or "").strip()
                    if value:
                        channel_vars[var_name] = value
                        logger.debug(
                            f"Channel variable {var_name} read",
                            channel_id=channel_id,
                            variable=var_name,
                            value=value,
                        )
                    else:
                        logger.info(
                            f"Channel variable {var_name} not set (using defaults)",
                            channel_id=channel_id,
                            variable=var_name,
                        )
            except Exception as exc:
                # 404 is expected when variable not set - log as info, not error
                if "404" in str(exc) or "not found" in str(exc).lower():
                    logger.info(
                        f"Channel variable {var_name} not set (using defaults)",
                        channel_id=channel_id,
                        variable=var_name,
                    )
                else:
                    logger.debug(
                        f"Failed to read channel variable {var_name}",
                        channel_id=channel_id,
                        variable=var_name,
                        error=str(exc),
                        exc_info=True,
                    )
        
        # CRITICAL: Store context_name FIRST, before any early returns
        # This ensures pipeline mode gets the context even if provider lookup fails
        session.context_name = channel_vars.get('AI_CONTEXT')
        await self._save_session(session)
        logger.debug(
            "Stored context_name in session",
            call_id=session.call_id,
            context_name=session.context_name,
        )
        
        # Get provider name (precedence: AI_PROVIDER > context > session.provider_name)
        provider_name = channel_vars.get('AI_PROVIDER')
        if not provider_name:
            # Check if context specifies provider
            context_name = channel_vars.get('AI_CONTEXT')
            if context_name:
                context_config = self.transport_orchestrator.get_context_config(context_name)
                if context_config and context_config.provider:
                    provider_name = context_config.provider
        
        if not provider_name:
            provider_name = session.provider_name or self.config.default_provider
        
        # Get provider instance
        provider = self._call_providers.get(session.call_id) or self.providers.get(provider_name)
        if not provider:
            logger.warning(
                "Provider not found for audio profile resolution (pipeline mode will use context_name)",
                call_id=session.call_id,
                provider=provider_name,
                available=list(self.providers.keys()),
                context_name=session.context_name,
            )
            return
        
        # Get provider capabilities
        provider_caps = None
        try:
            if hasattr(provider, 'get_capabilities'):
                provider_caps = provider.get_capabilities()
        except Exception as exc:
            logger.debug(
                "Failed to get provider capabilities",
                call_id=session.call_id,
                provider=provider_name,
                error=str(exc),
            )
        
        # Resolve transport profile
        try:
            # Pass provider config so orchestrator can read actual provider requirements
            provider_cfg = getattr(provider, "config", None) if provider else None
            transport = self.transport_orchestrator.resolve_transport(
                provider_name=provider_name,
                provider_caps=provider_caps,
                channel_vars=channel_vars,
                provider_config=provider_cfg,
            )
            
            # Store transport in session (keep as object, not dict, for legacy code compatibility)
            session.transport_profile = transport
            
            # Note: context_name already stored earlier (before provider lookup)
            # so pipeline mode gets it even if provider not found
            
            await self._save_session(session)
            
            # Apply to streaming manager
            # CRITICAL: Do NOT set global sample_rate - it's shared across all calls!
            # Each call must pass target_sample_rate explicitly to start_streaming_playback()
            try:
                self.streaming_playback_manager.audiosocket_format = transport.wire_encoding
                # REMOVED: self.streaming_playback_manager.sample_rate = transport.wire_sample_rate
                # Global sample_rate causes race condition when multiple calls use different rates
                if hasattr(self.streaming_playback_manager, 'chunk_size_ms'):
                    self.streaming_playback_manager.chunk_size_ms = transport.chunk_ms
                if hasattr(self.streaming_playback_manager, 'idle_cutoff_ms'):
                    self.streaming_playback_manager.idle_cutoff_ms = transport.idle_cutoff_ms
            except Exception as exc:
                logger.warning(
                    "Failed to apply transport to streaming manager",
                    call_id=session.call_id,
                    error=str(exc),
                )
            
            # Store per-call provider overrides (do NOT mutate global provider templates).
            try:
                session.provider_overrides = dict(getattr(session, "provider_overrides", {}) or {})
                session.provider_overrides["target_encoding"] = transport.wire_encoding
                session.provider_overrides["target_sample_rate_hz"] = transport.wire_sample_rate
                await self._save_session(session)
            except Exception:
                logger.debug(
                    "Failed to store transport overrides on session",
                    call_id=session.call_id,
                    exc_info=True,
                )

            # Get context config for prompt/greeting and store as per-call overrides.
            context_config = None
            logger.debug(
                "Checking context config",
                call_id=session.call_id,
                transport_context=transport.context if hasattr(transport, "context") else None,
            )
            if transport.context:
                context_config = self.transport_orchestrator.get_context_config(transport.context)
                logger.debug(
                    "Context config loaded",
                    call_id=session.call_id,
                    context=transport.context,
                    has_config=context_config is not None,
                    has_greeting=context_config.greeting if context_config else None,
                    has_prompt=context_config.prompt if context_config else None,
                )
                if context_config:
                    try:
                        greeting_to_apply = context_config.greeting
                        if greeting_to_apply:
                            try:
                                caller_name = getattr(session, "caller_name", None) or "there"
                                caller_number = getattr(session, "caller_number", None) or "unknown"
                                greeting_to_apply = greeting_to_apply.format(
                                    caller_name=caller_name,
                                    caller_number=caller_number,
                                )
                                logger.debug(
                                    "Applied greeting template substitution for provider",
                                    call_id=session.call_id,
                                    caller_name=caller_name,
                                )
                            except (KeyError, ValueError) as e:
                                logger.warning(
                                    "Greeting template substitution failed for provider",
                                    call_id=session.call_id,
                                    error=str(e),
                                )

                        if greeting_to_apply:
                            session.provider_overrides["greeting"] = greeting_to_apply
                            logger.info(
                                "Stored context greeting for provider session",
                                call_id=session.call_id,
                                context=transport.context,
                                greeting_preview=(
                                    (greeting_to_apply[:50] + "...")
                                    if len(greeting_to_apply) > 50
                                    else greeting_to_apply
                                ),
                            )
                        if context_config.prompt:
                            session.provider_overrides["prompt"] = context_config.prompt
                            logger.info(
                                "Stored context prompt for provider session",
                                call_id=session.call_id,
                                context=transport.context,
                                prompt_length=len(context_config.prompt),
                            )
                        await self._save_session(session)
                    except Exception as exc:
                        logger.error(
                            "Failed to store context config for provider",
                            call_id=session.call_id,
                            context=transport.context,
                            error=str(exc),
                            exc_info=True,
                        )

                    # Start background music if configured for this context (AAVA-89)
                    if context_config.background_music:
                        await self._start_background_music(session, context_config.background_music)
            
            # Note: TransportCard will be emitted by legacy code path
            
            logger.info(
                "Audio profile resolved and applied",
                call_id=session.call_id,
                profile=transport.profile_name,
                provider=provider_name,
                context=transport.context,
                wire_format=f"{transport.wire_encoding}@{transport.wire_sample_rate}Hz",
            )
            
        except Exception as exc:
            logger.error(
                "Audio profile resolution failed",
                call_id=session.call_id,
                provider=provider_name,
                error=str(exc),
                exc_info=True,
            )
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Background Music (AAVA-89)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    async def _start_background_music(self, session, moh_class: str) -> None:
        """
        Start background music playback using bridge MOH.
        
        Uses Asterisk's bridge MOH feature to play music to all bridge participants.
        Note: The AI will hear the music (affects VAD). Use low-volume ambient music
        to minimize interference with speech detection.
        
        Args:
            session: CallSession with bridge_id
            moh_class: Music On Hold class name from musiconhold.conf
        """
        try:
            if not session.caller_channel_id:
                logger.warning(
                    "Cannot start background music - no caller channel",
                    call_id=session.call_id,
                    moh_class=moh_class
                )
                return
            
            # Use bridge's MOH - plays to all channels in bridge (including AI)
            # Note: At low volume, this shouldn't significantly impact VAD
            if not session.bridge_id:
                logger.warning(
                    "Cannot start background music - no bridge yet",
                    call_id=session.call_id,
                    moh_class=moh_class
                )
                return
            
            # Start MOH on the bridge itself
            response = await self.ari_client.send_command(
                "POST",
                f"bridges/{session.bridge_id}/moh",
                data={"mohClass": moh_class}
            )
            
            # Store that we're using bridge MOH (for cleanup)
            session.music_snoop_channel_id = f"bridge-moh:{session.bridge_id}"
            await self._save_session(session)
            
            logger.info(
                "ðŸŽµ Background music started (bridge MOH)",
                call_id=session.call_id,
                bridge_id=session.bridge_id,
                moh_class=moh_class
            )
            
        except Exception as e:
            logger.warning(
                "Background music failed to start",
                call_id=session.call_id,
                moh_class=moh_class,
                error=str(e),
                exc_info=True
            )
    
    async def _stop_background_music(self, session) -> None:
        """
        Stop background music.
        
        Handles both bridge MOH and snoop channel approaches.
        """
        music_id = getattr(session, 'music_snoop_channel_id', None)
        if not music_id:
            return
        
        try:
            if music_id.startswith("bridge-moh:"):
                # Bridge MOH - stop MOH on the bridge
                bridge_id = music_id.replace("bridge-moh:", "")
                await self.ari_client.send_command(
                    "DELETE",
                    f"bridges/{bridge_id}/moh"
                )
                logger.info(
                    "ðŸŽµ Background music stopped (bridge MOH)",
                    call_id=session.call_id,
                    bridge_id=bridge_id
                )
            else:
                # Snoop channel - hang up the channel
                await self.ari_client.hangup_channel(music_id)
                logger.info(
                    "ðŸŽµ Background music stopped",
                    call_id=session.call_id,
                    snoop_channel_id=music_id
                )
        except Exception:
            # Channel/bridge may already be gone
            logger.debug(
                "Background music already stopped",
                call_id=session.call_id,
                music_id=music_id
            )
        
        session.music_snoop_channel_id = None
    
    @staticmethod
    def _canonicalize_encoding(value: Optional[str]) -> str:
        """Normalize codec tokens to canonical engine values."""
        if not value:
            return ""
        token = value.lower().strip()
        mapping = {
            "mu-law": "ulaw",
            "mulaw": "ulaw",
            "g711_ulaw": "ulaw",
            "g711ulaw": "ulaw",
            "g711-ula": "ulaw",
            # Note: "slin" (8kHz PCM) and "slin16" (16kHz PCM) are distinct formats
            "slin": "slin",
            "slin12": "slin16",
            "slin16": "slin16",
        }
        return mapping.get(token, token)

    @staticmethod
    def _clone_config(obj: Any) -> Any:
        """Best-effort deep clone for provider config objects (Pydantic, dicts, dataclasses)."""
        try:
            copier = getattr(obj, "model_copy", None)
            if callable(copier):
                return copier(deep=True)
        except Exception:
            pass
        return copy.deepcopy(obj)

    @staticmethod
    def _should_force_mulaw(force_flag: bool, audiosocket_fmt: Optional[str]) -> bool:
        """Gate egress Î¼-law forcing to transports that actually expect Î¼-law frames."""
        if not force_flag:
            return False
        canonical = Engine._canonicalize_encoding(audiosocket_fmt)
        if canonical in ("", "ulaw", "mulaw", "g711_ulaw", "mu-law"):
            return True
        try:
            logger.info(
                "Disabling egress_force_mulaw for non-Î¼-law AudioSocket transport",
                audiosocket_format=audiosocket_fmt,
            )
        except Exception:
            pass
        return False

    @staticmethod
    def _infer_transport_from_frame(frame_len: int) -> Tuple[str, int]:
        """Infer transport format/sample-rate from canonical frame lengths."""
        mapping = {
            160: ("ulaw", 8000),   # 20ms @8k Î¼-law
            320: ("slin16", 8000), # 20ms @8k PCM16
            640: ("slin16", 16000),# 20ms @16k PCM16
            960: ("slin16", 24000),
        }
        fmt, rate = mapping.get(frame_len, ("slin16" if frame_len % 2 == 0 else "ulaw", 8000))
        return fmt, rate

    def _wire_to_pcm16(
        self,
        audio_bytes: bytes,
        wire_fmt: str,
        swap_needed: bool,
        wire_rate: int,
    ) -> Tuple[bytes, int]:
        """Convert wire-format audio to PCM16 little-endian."""
        canonical = self._canonicalize_encoding(wire_fmt) or "ulaw"
        rate = wire_rate or 0
        if rate <= 0:
            try:
                _, inferred_rate = self._infer_transport_from_frame(len(audio_bytes))
            except Exception:
                inferred_rate = 0
            rate = inferred_rate or 8000
        pcm = audio_bytes
        try:
            if canonical in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
                pcm = audioop.ulaw2lin(audio_bytes, 2)
                rate = 8000
            else:
                if swap_needed:
                    pcm = audioop.byteswap(audio_bytes, 2)
                else:
                    pcm = audio_bytes
        except Exception:
            pcm = b""
        return pcm or b"", rate

    def _encode_for_provider(
        self,
        call_id: str,
        provider_name: str,
        provider,
        pcm_bytes: bytes,
        pcm_rate: int,
    ) -> Tuple[bytes, str, int]:
        """Encode PCM audio based on provider configuration expectations."""
        if pcm_bytes is None:
            pcm_bytes = b""
        if pcm_rate <= 0:
            pcm_rate = 8000

        expected_enc = ""
        expected_rate = pcm_rate
        gain_target_rms = 0
        gain_max_db = 0.0
        try:
            provider_cfg = getattr(provider, "config", None)
            if provider_cfg is not None:
                # CRITICAL: Read provider-specific fields first (for real-time providers like Google Live, OpenAI)
                # Fall back to wire-format fields for backward compatibility (Deepgram Voice Agent)
                provider_enc = getattr(provider_cfg, "provider_input_encoding", None)
                wire_enc = getattr(provider_cfg, "input_encoding", None)
                expected_enc = self._canonicalize_encoding(provider_enc or wire_enc)
                
                provider_rate = getattr(provider_cfg, "provider_input_sample_rate_hz", None)
                wire_rate = getattr(provider_cfg, "input_sample_rate_hz", None)
                expected_rate = int(provider_rate or wire_rate or pcm_rate)

                # Optional inbound gain configuration (per-provider, disabled by default)
                try:
                    gain_target_rms = int(getattr(provider_cfg, "input_gain_target_rms", 0) or 0)
                except Exception:
                    gain_target_rms = 0
                try:
                    gain_max_db = float(getattr(provider_cfg, "input_gain_max_db", 0.0) or 0.0)
                except Exception:
                    gain_max_db = 0.0
                
                logger.info(
                    "ðŸ”§ ENCODE CONFIG - Reading provider config",
                    call_id=call_id,
                    provider=provider_name,
                    provider_enc=provider_enc,
                    wire_enc=wire_enc,
                    provider_rate=provider_rate,
                    wire_rate=wire_rate,
                    expected_enc=expected_enc,
                    expected_rate=expected_rate,
                    pcm_rate=pcm_rate,
                )
        except Exception as e:
            logger.error(
                "ðŸ”§ ENCODE CONFIG - Exception reading config",
                call_id=call_id,
                provider=provider_name,
                error=str(e),
                exc_info=True,
            )
            expected_enc = ""
            expected_rate = pcm_rate
            gain_target_rms = 0
            gain_max_db = 0.0

        # Prepare per-call/provider resample state holder
        prov_states = self._resample_state_provider_in.setdefault(call_id, {})
        state_key = f"{provider_name}:{expected_rate}"
        if expected_enc in ("slin16", "linear16", "pcm16", ""):
            if expected_rate <= 0:
                expected_rate = pcm_rate
            if pcm_rate != expected_rate and pcm_bytes:
                logger.info(
                    "ðŸ”§ ENCODE RESAMPLE - Resampling needed",
                    call_id=call_id,
                    provider=provider_name,
                    pcm_rate=pcm_rate,
                    expected_rate=expected_rate,
                    pcm_bytes=len(pcm_bytes),
                )
                try:
                    # CRITICAL FIX: audioop.ratecv() produces incorrect output sizes
                    # Example: 320 bytes @ 8kHz â†’ 638 bytes @ 16kHz (should be 640)
                    # This 2-byte misalignment corrupts streaming for Google Live
                    input_bytes = len(pcm_bytes)
                    pcm_bytes, _ = audioop.ratecv(pcm_bytes, 2, 1, pcm_rate, expected_rate, None)
                    
                    # Calculate expected output size based on sample rate ratio
                    # input_samples = input_bytes // 2 (2 bytes per sample)
                    # output_samples = input_samples * (expected_rate / pcm_rate)
                    # output_bytes = output_samples * 2
                    expected_bytes = int((input_bytes // 2) * (expected_rate / pcm_rate) * 2)
                    
                    # Force exact size by padding or trimming
                    if len(pcm_bytes) < expected_bytes:
                        # Pad with zeros (silence)
                        padding = expected_bytes - len(pcm_bytes)
                        pcm_bytes += b'\x00' * padding
                        logger.debug(
                            "ðŸ”§ ENCODE RESAMPLE - Padded to exact size",
                            call_id=call_id,
                            provider=provider_name,
                            before=len(pcm_bytes) - padding,
                            after=len(pcm_bytes),
                            padding_bytes=padding,
                        )
                    elif len(pcm_bytes) > expected_bytes:
                        # Trim excess
                        excess = len(pcm_bytes) - expected_bytes
                        pcm_bytes = pcm_bytes[:expected_bytes]
                        logger.debug(
                            "ðŸ”§ ENCODE RESAMPLE - Trimmed to exact size",
                            call_id=call_id,
                            provider=provider_name,
                            before=len(pcm_bytes) + excess,
                            after=len(pcm_bytes),
                            trimmed_bytes=excess,
                        )
                    
                    pcm_rate = expected_rate
                    logger.info(
                        "ðŸ”§ ENCODE RESAMPLE - Resampling completed (corrected)",
                        call_id=call_id,
                        provider=provider_name,
                        new_rate=pcm_rate,
                        new_bytes=len(pcm_bytes),
                        expected_bytes=expected_bytes,
                    )
                except Exception as e:
                    logger.error(
                        "ðŸ”§ ENCODE RESAMPLE - Resampling failed",
                        call_id=call_id,
                        provider=provider_name,
                        error=str(e),
                        exc_info=True,
                    )
            else:
                logger.info(
                    "ðŸ”§ ENCODE RESAMPLE - No resampling needed",
                    call_id=call_id,
                    provider=provider_name,
                    pcm_rate=pcm_rate,
                    expected_rate=expected_rate,
                )
            
            if provider_name == "google_live":
                return pcm_bytes, "slin16", pcm_rate
            
            # Re-enabled: Gain normalization required for low-volume audio
            # Root cause identified: Incoming audio had RMS=23 (needs ~1400)
            # Without normalization, Google Live cannot understand quiet audio
            # Silence frames during gating prevent echo while maintaining stream continuity
            #
            # NOTE: This is now gated by per-provider config:
            # - input_gain_target_rms <= 0 or input_gain_max_db <= 0.0  => gain disabled (default)
            # - both > 0 => enable normalization with configured target/max gain.
            if pcm_bytes and gain_target_rms > 0 and gain_max_db > 0.0:
                try:
                    # audioop already imported at module level - don't re-import here!
                    current_rms = audioop.rms(pcm_bytes, 2)
                    target_rms = gain_target_rms
                    max_gain_db = gain_max_db
                    
                    if current_rms > 10:  # Only apply if audio has some energy
                        gain_needed = target_rms / current_rms
                        max_gain = 10 ** (max_gain_db / 20.0)
                        gain = min(gain_needed, max_gain)
                        
                        if gain > 1.05:  # Apply if gain needed is >5%
                            pcm_bytes = audioop.mul(pcm_bytes, 2, gain)
                            actual_rms = audioop.rms(pcm_bytes, 2)
                            
                            # CRITICAL: Warn about excessive gain (indicates audio quality issues)
                            # High gain on low-quality audio causes distortion and speech recognition failures
                            if gain > 10.0:
                                logger.warning(
                                    "âš ï¸ AUDIO QUALITY ISSUE: Excessive gain required!",
                                    call_id=call_id,
                                    provider=provider_name,
                                    gain_multiplier=f"{gain:.1f}x",
                                    rms_before=current_rms,
                                    rms_target=target_rms,
                                    recommendation="Check SIP trunk rxgain configuration - incoming audio too quiet",
                                )
                            
                            logger.info(
                                "ðŸ”Š Provider input: Gain applied",
                                call_id=call_id,
                                provider=provider_name,
                                rms_before=current_rms,
                                rms_after=actual_rms,
                                rms_target=target_rms,
                                gain=f"{gain:.2f}",
                            )
                except Exception as e:
                    logger.error(f"Provider input normalization failed: {e}", call_id=call_id, exc_info=True)
            
            return pcm_bytes, "slin16", pcm_rate

        if expected_enc in ("ulaw", "mulaw", "g711_ulaw", "mu-law"):
            if expected_rate <= 0:
                expected_rate = 8000
            working = pcm_bytes
            if pcm_rate != expected_rate and working:
                try:
                    state = prov_states.get(state_key)
                    working, state = audioop.ratecv(working, 2, 1, pcm_rate, expected_rate, state)
                    prov_states[state_key] = state
                except Exception:
                    working = pcm_bytes
            try:
                encoded = audioop.lin2ulaw(working, 2)
            except Exception:
                encoded = b""
            return encoded, "ulaw", expected_rate

        # Fallback: return PCM as-is
        return pcm_bytes, "slin16", pcm_rate

    async def _update_transport_profile(self, session: CallSession, *, fmt: Optional[str], sample_rate: Optional[int], source: str) -> None:
        """Persist transport profile updates and sync preferences."""
        profile = session.transport_profile
        
        # Guard: Check if transport profile is initialized
        if profile is None:
            logger.warning(
                "Transport profile not initialized yet, skipping update",
                call_id=session.call_id,
                source=source,
                fmt=fmt,
                sample_rate=sample_rate
            )
            return
        
        # P1: Check if this is new TransportProfile (has wire_encoding) vs legacy (has format)
        if hasattr(profile, 'wire_encoding'):
            # New P1 TransportProfile - don't update, it's immutable per call
            logger.debug(
                "Skipping transport profile update for P1 TransportProfile",
                call_id=session.call_id,
                source=source,
            )
            return
        
        priority_order = {
            "config": 0,
            "dialplan": 1,
            "audiosocket": 2,
            # Provider can refine effective stream source format after transport is known
            "provider": 3,
            "detected": 4,
        }
        incoming_source = source or profile.source
        incoming_priority = priority_order.get(incoming_source, 0)
        current_priority = priority_order.get(profile.source, 0)

        if incoming_priority < current_priority and fmt is not None and sample_rate is not None:
            # Preserve higher-priority source; ignore lower-priority override.
            return
        if not fmt and not sample_rate:
            return
        canonical_fmt = self._canonicalize_encoding(fmt) or session.transport_profile.format
        final_rate = sample_rate or session.transport_profile.sample_rate
        changed = (
            profile.format != canonical_fmt
            or profile.sample_rate != final_rate
            or profile.source != incoming_source
        )
        profile.update(format=canonical_fmt, sample_rate=final_rate, source=incoming_source)
        session.caller_audio_format = canonical_fmt
        session.caller_sample_rate = final_rate
        self.call_audio_preferences[session.call_id] = {
            "format": canonical_fmt,
            "sample_rate": final_rate,
        }
        if changed:
            try:
                await self._save_session(session)
            except Exception:
                logger.debug("Failed to persist transport profile", call_id=session.call_id, exc_info=True)
            try:
                logger.info(
                    "Transport profile resolved",
                    call_id=session.call_id,
                    format=canonical_fmt,
                    sample_rate=final_rate,
                    source=source,
                )
            except Exception:
                pass

    def _update_audio_diagnostics(self, session: CallSession, stage: str, audio_bytes: bytes, encoding: str, sample_rate: int) -> None:
        """Track audio health metrics (RMS/DC offset) for observability."""
        try:
            canonical = self._canonicalize_encoding(encoding) or "slin16"
            if canonical == "ulaw":
                pcm = audioop.ulaw2lin(audio_bytes, 2)
            else:
                pcm = audio_bytes
            rms = audioop.rms(pcm, 2) if pcm else 0
            dc_offset = audioop.avg(pcm, 2) if pcm else 0
            session.audio_diagnostics[stage] = {
                "rms": rms,
                "dc_offset": dc_offset,
                "sample_rate": sample_rate,
                "updated": time.time(),
            }
            _AUDIO_RMS_GAUGE.labels(stage).set(rms)
            _AUDIO_DC_OFFSET.labels(stage).set(dc_offset)
            first_sample_key = f"{stage}_first_sample_logged"
            if not session.audio_diagnostics.get(first_sample_key):
                session.audio_diagnostics[first_sample_key] = True
                logger.info(
                    "Audio diagnostics sample captured",
                    call_id=session.call_id,
                    stage=stage,
                    format=canonical,
                    rms=rms,
                    dc_offset=dc_offset,
                    sample_rate=sample_rate,
                )
            rms_threshold = 50 if canonical == "ulaw" else 200
            alert_key = f"{stage}_low_rms_alerted"
            if rms < rms_threshold and not session.audio_diagnostics.get(alert_key):
                session.audio_diagnostics[alert_key] = True
                logger.warning(
                    "Low audio energy detected; degraded audio quality likely",
                    call_id=session.call_id,
                    stage=stage,
                    format=canonical,
                    rms=rms,
                    threshold=rms_threshold,
                )
            dc_threshold = 600
            dc_alert_key = f"{stage}_dc_alerted"
            if abs(dc_offset) > dc_threshold and not session.audio_diagnostics.get(dc_alert_key):
                session.audio_diagnostics[dc_alert_key] = True
                logger.warning(
                    "Significant DC offset detected in audio stream",
                    call_id=session.call_id,
                    stage=stage,
                    dc_offset=dc_offset,
                    threshold=dc_threshold,
                )
        except Exception:
            logger.debug("Audio diagnostics update failed", call_id=session.call_id, stage=stage, exc_info=True)

    async def _update_audio_diagnostics_by_call(
        self,
        call_id: str,
        stage: str,
        audio_bytes: bytes,
        encoding: str,
        sample_rate: int,
    ) -> None:
        session = await self.session_store.get_by_call_id(call_id)
        if not session:
            return
        self._update_audio_diagnostics(session, stage, audio_bytes, encoding, sample_rate)

    def _emit_transport_card(
        self,
        call_id: Optional[str],
        session: Optional[CallSession],
        *,
        source_encoding: Optional[Any],
        source_sample_rate: Optional[Any],
        target_encoding: Optional[Any],
        target_sample_rate: Optional[Any],
    ) -> None:
        if not call_id or call_id in self._transport_card_logged:
            return

        spm = getattr(self, "streaming_playback_manager", None)
        wire_encoding = None
        wire_rate: Optional[int] = None
        chunk_ms: Optional[int] = None
        idle_cutoff_ms: Optional[int] = None
        if spm is not None:
            try:
                wire_encoding = getattr(spm, "audiosocket_format", None)
            except Exception:
                wire_encoding = None
            try:
                rate_val = getattr(spm, "sample_rate", None)
                wire_rate = int(rate_val) if rate_val else None
            except Exception:
                wire_rate = None
            try:
                chunk_val = getattr(spm, "chunk_size_ms", None)
                chunk_ms = int(chunk_val) if chunk_val else None
            except Exception:
                chunk_ms = None
            try:
                idle_val = getattr(spm, "idle_cutoff_ms", None)
                idle_cutoff_ms = int(idle_val) if idle_val else None
            except Exception:
                idle_cutoff_ms = None

        provider_name = None
        transport_source = None
        transport_fmt = None
        transport_rate: Optional[int] = None
        if session is not None:
            provider_name = getattr(session, "provider_name", None) or getattr(session, "provider", None) or self.config.default_provider
            
            # P1: Handle both new TransportProfile and legacy transport_profile
            if hasattr(session.transport_profile, 'wire_encoding'):
                # New P1 TransportProfile
                transport_source = "p1_profile"
                transport_fmt = session.transport_profile.wire_encoding
                transport_rate = session.transport_profile.wire_sample_rate
            else:
                # Legacy transport_profile
                try:
                    transport_source = session.transport_profile.source
                except Exception:
                    transport_source = None
                try:
                    transport_fmt = session.transport_profile.format
                except Exception:
                    transport_fmt = None
                try:
                    rate = session.transport_profile.sample_rate
                    transport_rate = int(rate) if rate else None
                except Exception:
                    transport_rate = None

        def _canon_rate(value: Optional[Any]) -> Optional[int]:
            if value is None:
                return None
            try:
                return int(value)
            except (TypeError, ValueError):
                return None

        payload = {
            "call_id": call_id,
            "provider": provider_name,
            "transport_source": transport_source,
            "wire_encoding": self._canonicalize_encoding(wire_encoding) or None,
            "wire_sample_rate_hz": _canon_rate(wire_rate),
            "transport_encoding": self._canonicalize_encoding(transport_fmt) or None,
            "transport_sample_rate_hz": _canon_rate(transport_rate),
            "provider_encoding": self._canonicalize_encoding(source_encoding) or None,
            "provider_sample_rate_hz": _canon_rate(source_sample_rate),
            "target_encoding": self._canonicalize_encoding(target_encoding) or None,
            "target_sample_rate_hz": _canon_rate(target_sample_rate),
            "chunk_size_ms": _canon_rate(chunk_ms),
            "idle_cutoff_ms": _canon_rate(idle_cutoff_ms),
        }

        try:
            logger.info(
                "TransportCard",
                **{k: v for k, v in payload.items() if v is not None},
            )
            self._transport_card_logged.add(call_id)
        except Exception:
            logger.debug("TransportCard logging failed", call_id=call_id, exc_info=True)

    def _resolve_stream_targets(
        self,
        session: CallSession,
        provider_name: Optional[str],
    ) -> Tuple[str, int, Optional[str]]:
        provider_name = provider_name or getattr(session, "provider_name", None) or self.config.default_provider

        # CRITICAL: Use wire_encoding and wire_sample_rate from TransportProfile
        # TransportProfile (P1) uses wire_encoding/wire_sample_rate, not format/sample_rate
        transport_fmt = self._canonicalize_encoding(
            getattr(session.transport_profile, "wire_encoding", None) or 
            getattr(session.transport_profile, "format", None)
        ) or "ulaw"
        try:
            transport_rate = int(
                getattr(session.transport_profile, "wire_sample_rate", 0) or 
                getattr(session.transport_profile, "sample_rate", 0) or 0
            )
        except Exception:
            transport_rate = 0
        if transport_rate <= 0:
            transport_rate = 8000 if transport_fmt in {"ulaw", "mulaw", "g711_ulaw"} else 16000

        # Always refresh downstream preference view so playback manager aligns with transport
        self.call_audio_preferences[session.call_id] = {
            "format": transport_fmt,
            "sample_rate": transport_rate,
        }

        provider = self._call_providers.get(session.call_id) or self.providers.get(provider_name)
        
        # CRITICAL FIX: Read provider INPUT format (what provider receives)
        # NOT target format (what provider outputs)
        # TransportCard should show: provider receives X, wire expects Y
        provider_input_enc = None
        provider_input_rate = None
        provider_target_enc = None
        provider_target_rate = None
        try:
            provider_cfg = getattr(provider, "config", None)
            if provider_cfg:
                # Modern providers: read provider_input_* for what they receive
                provider_input_enc = self._canonicalize_encoding(
                    getattr(provider_cfg, "provider_input_encoding", None) or
                    getattr(provider_cfg, "input_encoding", None)
                )
                raw_input_rate = (
                    getattr(provider_cfg, "provider_input_sample_rate_hz", None) or
                    getattr(provider_cfg, "input_sample_rate_hz", None)
                )
                provider_input_rate = int(raw_input_rate) if raw_input_rate else None
                
                # Also read target for alignment validation
                provider_target_enc = self._canonicalize_encoding(getattr(provider_cfg, "target_encoding", None))
                raw_target_rate = getattr(provider_cfg, "target_sample_rate_hz", None)
                provider_target_rate = int(raw_target_rate) if raw_target_rate else None
        except Exception:
            provider_cfg = None

        # Validate outbound alignment (provider output vs wire expectations)
        remediation: Optional[str] = None
        aligned = True
        if provider_target_enc and provider_target_enc != transport_fmt:
            aligned = False
            remediation = (
                f"Provider target_encoding={provider_target_enc} but transport format={transport_fmt}. "
                f"Update providers.{provider_name}.target_encoding to '{transport_fmt}' in config/ai-agent.yaml."
            )
        if provider_target_rate and provider_target_rate != transport_rate:
            aligned = False
            extra = (
                f"Provider target_sample_rate_hz={provider_target_rate} but transport sample_rate={transport_rate}. "
                f"Update providers.{provider_name}.target_sample_rate_hz to {transport_rate}."
            )
            remediation = f"{remediation} {extra}".strip() if remediation else extra

        session.codec_alignment_ok = aligned
        session.codec_alignment_message = remediation
        try:
            _CODEC_ALIGNMENT.labels(provider_name).set(1 if aligned else 0)
        except Exception:
            pass

        if not aligned and remediation:
            logger.warning(
                "Codec/sample alignment degraded",
                call_id=session.call_id,
                provider=provider_name,
                remediation=remediation,
            )

        # CRITICAL FIX: TransportCard should show INBOUND encoding (what provider receives)
        self._emit_transport_card(
            session.call_id,
            session,
            source_encoding=provider_input_enc,    # âœ… What provider RECEIVES
            source_sample_rate=provider_input_rate, # âœ… What provider RECEIVES
            target_encoding=transport_fmt,          # âœ… What wire EXPECTS
            target_sample_rate=transport_rate,      # âœ… What wire EXPECTS
        )

        return transport_fmt, transport_rate, remediation

    async def _assign_pipeline_to_session(
        self,
        session: CallSession,
        pipeline_name: Optional[str] = None,
    ) -> Optional[PipelineResolution]:
        """Resolve modular pipeline components for a session and persist metadata."""
        if not getattr(self, "pipeline_orchestrator", None):
            return None
        if not self.pipeline_orchestrator.enabled:
            return None
        try:
            resolution = self.pipeline_orchestrator.get_pipeline(session.call_id, pipeline_name)
        except PipelineOrchestratorError as exc:
            logger.error(
                "Pipeline resolution failed",
                call_id=session.call_id,
                requested_pipeline=pipeline_name,
                error=str(exc),
                exc_info=True,
            )
            return None
        except Exception as exc:
            logger.error(
                "Pipeline resolution unexpected error",
                call_id=session.call_id,
                requested_pipeline=pipeline_name,
                error=str(exc),
                exc_info=True,
            )
            return None
 
        if not resolution:
            logger.debug(
                "Pipeline orchestrator returned no resolution",
                call_id=session.call_id,
                requested_pipeline=pipeline_name,
            )
            return None
 
        component_summary = resolution.component_summary()
        updated = False
 
        if session.pipeline_name != resolution.pipeline_name:
            session.pipeline_name = resolution.pipeline_name
            updated = True
 
        if session.pipeline_components != component_summary:
            session.pipeline_components = component_summary
            updated = True
 
        provider_override = resolution.primary_provider
        if provider_override:
            if provider_override in self.providers:
                if session.provider_name != provider_override:
                    logger.info(
                        "Pipeline overriding provider",
                        call_id=session.call_id,
                        previous_provider=session.provider_name,
                        override_provider=provider_override,
                    )
                    session.provider_name = provider_override
                    updated = True
            else:
                logger.debug(
                    "Pipeline requested provider not in monolithic providers; using pipeline adapters directly",
                    call_id=session.call_id,
                    requested_provider=provider_override,
                    current_provider=session.provider_name,
                    available_providers=list(self.providers.keys()),
                )
 
        if updated:
            await self._save_session(session)
 
        if not resolution.prepared:
            resolution.prepared = True
            logger.info(
                "Milestone7 pipeline resolved",
                call_id=session.call_id,
                pipeline=session.pipeline_name,
                components=component_summary,
                provider=session.provider_name,
            )
            options_summary = resolution.options_summary()
            if any(options_summary.values()):
                logger.debug(
                    "Milestone7 pipeline options",
                    call_id=session.call_id,
                    pipeline=session.pipeline_name,
                    options=options_summary,
                )
 
        return resolution
 
    async def _ensure_provider_session_started(self, call_id: str) -> None:
        """Single-flight wrapper around _start_provider_session (prevents duplicate concurrent starts)."""
        task = self._provider_start_tasks.get(call_id)
        if task:
            await task
            return
        task = asyncio.create_task(self._start_provider_session(call_id), name=f"provider-start-{call_id}")
        self._provider_start_tasks[call_id] = task
        try:
            await task
        finally:
            if self._provider_start_tasks.get(call_id) is task:
                self._provider_start_tasks.pop(call_id, None)

    def _kickoff_provider_session_start(self, call_id: str) -> None:
        """Fire-and-forget provider start with exception swallowing (used from audio hot paths)."""
        if call_id in self._provider_start_tasks:
            return
        bg_task = asyncio.create_task(self._ensure_provider_session_started(call_id), name=f"provider-start-bg-{call_id}")

        def _done(t: asyncio.Task, *, _call_id: str = call_id) -> None:
            try:
                t.result()
            except Exception:
                logger.debug("Background provider start failed", call_id=_call_id, exc_info=True)

        bg_task.add_done_callback(_done)

    def _apply_provider_overrides(self, provider: AIProviderInterface, session: CallSession) -> None:
        """Apply per-call overrides (greeting/prompt/target format) to a provider instance."""
        overrides = {}
        try:
            overrides = dict(getattr(session, "provider_overrides", {}) or {})
        except Exception:
            overrides = {}

        # Always align provider output target to the resolved transport for this call.
        try:
            transport = getattr(session, "transport_profile", None)
            if transport:
                overrides.setdefault("target_encoding", getattr(transport, "wire_encoding", None))
                overrides.setdefault("target_sample_rate_hz", getattr(transport, "wire_sample_rate", None))
        except Exception:
            pass

        cfg = getattr(provider, "config", None)
        if not cfg:
            return

        greeting = overrides.get("greeting")
        prompt = overrides.get("prompt")
        target_encoding = overrides.get("target_encoding")
        target_rate = overrides.get("target_sample_rate_hz")

        try:
            if isinstance(cfg, dict):
                if greeting:
                    cfg["greeting"] = greeting
                if prompt:
                    # Some providers call this "prompt", others "instructions"
                    cfg.setdefault("prompt", prompt)
                    cfg.setdefault("instructions", prompt)
                if target_encoding:
                    cfg["target_encoding"] = target_encoding
                if target_rate:
                    cfg["target_sample_rate_hz"] = target_rate
            else:
                if greeting and hasattr(cfg, "greeting"):
                    setattr(cfg, "greeting", greeting)
                if prompt:
                    if hasattr(cfg, "prompt"):
                        setattr(cfg, "prompt", prompt)
                    if hasattr(cfg, "instructions"):
                        setattr(cfg, "instructions", prompt)
                if target_encoding and hasattr(cfg, "target_encoding"):
                    setattr(cfg, "target_encoding", target_encoding)
                if target_rate and hasattr(cfg, "target_sample_rate_hz"):
                    setattr(cfg, "target_sample_rate_hz", target_rate)
        except Exception:
            logger.debug("Failed applying provider overrides", call_id=session.call_id, exc_info=True)

        # LocalProvider uses an explicit initial greeting helper.
        try:
            if greeting and hasattr(provider, "set_initial_greeting"):
                provider.set_initial_greeting(greeting)
        except Exception:
            logger.debug("Provider set_initial_greeting failed", call_id=session.call_id, exc_info=True)

    async def _start_provider_session(self, call_id: str) -> None:
        """Start the provider session for a call when media path is ready."""
        provider: Optional[AIProviderInterface] = None
        try:
            session = await self.session_store.get_by_call_id(call_id)
            if not session:
                logger.error("Start provider session called for unknown call", call_id=call_id)
                return
            # Idempotent fast-path.
            if getattr(session, "provider_session_active", False) and call_id in self._call_providers:
                return

            # Preserve any per-call override previously applied. Only assign a pipeline
            # here if one has already been selected (e.g., via AI_PROVIDER or active_pipeline)
            pipeline_resolution = None
            if getattr(self.pipeline_orchestrator, "enabled", False):
                if getattr(session, "pipeline_name", None):
                    pipeline_resolution = await self._assign_pipeline_to_session(
                        session, pipeline_name=session.pipeline_name
                    )

            # Pipeline-only mode: if a pipeline is selected for this call, do not start
            # the legacy provider session or play the provider-managed greeting.
            if pipeline_resolution:
                logger.info(
                    "Pipeline-only mode: skipping legacy provider session; greeting will be handled by pipeline",
                    call_id=call_id,
                    pipeline=pipeline_resolution.pipeline_name,
                )
                try:
                    await self._ensure_pipeline_runner(session, forced=True)
                except Exception:
                    logger.debug(
                        "Failed to ensure pipeline runner in _start_provider_session",
                        call_id=call_id,
                        exc_info=True,
                    )
                return

            provider_name = session.provider_name or self.config.default_provider
            factory = self.provider_factories.get(provider_name)

            if not factory:
                fallback_name = self.config.default_provider
                fallback_factory = self.provider_factories.get(fallback_name)
                if fallback_factory:
                    logger.warning(
                        "Milestone7 pipeline provider unavailable; falling back to default provider",
                        call_id=call_id,
                        requested_provider=provider_name,
                        fallback_provider=fallback_name,
                    )
                    provider_name = fallback_name
                    factory = fallback_factory
                    if session.provider_name != fallback_name:
                        session.provider_name = fallback_name
                        await self._save_session(session)
                else:
                    logger.error(
                        "No provider available to start session",
                        call_id=call_id,
                        requested_provider=provider_name,
                        fallback_provider=fallback_name,
                    )
                    return

            # Create a per-call provider instance (providers are NOT concurrency-safe across calls).
            provider = factory()
            # Apply per-call context/prompt/transport overrides before start_session reads config.
            self._apply_provider_overrides(provider, session)
            # Inject shared runtime helpers (latency tracking, tool context helpers).
            try:
                if hasattr(provider, "set_session_store"):
                    provider.set_session_store(self.session_store)
                elif hasattr(provider, "_session_store"):
                    provider._session_store = self.session_store
            except Exception:
                logger.debug("Provider session_store injection failed", call_id=call_id, provider=provider_name, exc_info=True)
            try:
                if hasattr(provider, "_ari_client"):
                    provider._ari_client = self.ari_client
            except Exception:
                logger.debug("Provider ari_client injection failed", call_id=call_id, provider=provider_name, exc_info=True)
            # Make provider instance discoverable during start_session (providers can emit events while starting).
            self._call_providers[call_id] = provider

            if pipeline_resolution:
                logger.info(
                    "Milestone7 pipeline starting provider session",
                    call_id=call_id,
                    pipeline=pipeline_resolution.pipeline_name,
                    components=pipeline_resolution.component_summary(),
                    provider=provider_name,
                )
            elif getattr(self.pipeline_orchestrator, "enabled", False):
                logger.debug(
                    "Milestone7 pipeline orchestrator did not return a resolution; using legacy provider flow",
                    call_id=call_id,
                    provider=provider_name,
                )
            # Set provider input mode based on transport so send_audio can convert properly
            try:
                if hasattr(provider, 'set_input_mode'):
                    if self.config.audio_transport == 'externalmedia':
                        provider.set_input_mode('pcm16_16k')
                    else:
                        # Determine input mode from AudioSocket format
                        as_fmt = None
                        try:
                            if self.config.audiosocket and hasattr(self.config.audiosocket, 'format'):
                                as_fmt = (self.config.audiosocket.format or '').lower()
                        except Exception:
                            as_fmt = None
                        if as_fmt in ('ulaw', 'mulaw', 'g711_ulaw'):
                            provider.set_input_mode('mulaw8k')
                        elif as_fmt in ('slin16', 'linear16', 'pcm16'):
                            # slin16 is 16kHz PCM16, set correct input mode
                            provider.set_input_mode('pcm16_16k')
                        else:
                            # Default to PCM16 at 8 kHz for slin (8kHz) or unspecified
                            provider.set_input_mode('pcm16_8k')
            except Exception:
                logger.debug("Provider set_input_mode failed or unsupported", exc_info=True)

            # Note: Context greeting/prompt injection now happens earlier in P1 _resolve_audio_profile()
            # to ensure config is set BEFORE provider session starts and reads it.
            
            # Build context dict for providers that need it (Google Live, OpenAI Realtime)
            provider_context = {}
            try:
                if session.context_name:
                    context_config = self.transport_orchestrator.get_context_config(session.context_name)
                    logger.debug(
                        "Building provider context",
                        call_id=call_id,
                        context_name=session.context_name,
                        has_context_config=bool(context_config),
                        config_type=type(context_config).__name__ if context_config else None,
                        has_tools_attr=hasattr(context_config, 'tools') if context_config else False,
                    )
                    if context_config:
                        # Include tools if context explicitly specifies them.
                        # - tools is None: legacy/unspecified (provider may choose defaults)
                        # - tools is []: explicitly no tools
                        if hasattr(context_config, 'tools') and context_config.tools is not None:
                            tools_enabled = True
                            try:
                                tools_enabled = bool((self.config.tools or {}).get("enabled", True))
                            except Exception:
                                tools_enabled = True
                            provider_context['tools'] = context_config.tools if tools_enabled else []
                            logger.debug(
                                "Added tools to provider context",
                                call_id=call_id,
                                tools=provider_context['tools'],
                                tools_enabled=tools_enabled,
                            )
                        else:
                            logger.debug(
                                "No tools specified in context config",
                                call_id=call_id,
                                has_tools_attr=hasattr(context_config, 'tools'),
                                tools_value=getattr(context_config, 'tools', 'NO_ATTR'),
                            )
                        # Include prompt for reference (though config.instructions should already be set)
                        if hasattr(context_config, 'prompt') and context_config.prompt:
                            provider_context['prompt'] = context_config.prompt
            except Exception as e:
                logger.warning(f"Failed to build provider context: {e}", call_id=call_id, exc_info=True)
            
            # Inject tool execution context into provider if it supports tools (Deepgram, Google Live)
            if hasattr(provider, 'tool_adapter') or hasattr(provider, '_tool_adapter'):
                try:
                    provider._caller_channel_id = session.caller_channel_id
                    provider._bridge_id = session.bridge_id
                    provider._session_store = self.session_store
                    provider._ari_client = self.ari_client
                    provider._full_config = self.config.dict()  # Convert Pydantic model to dict
                    logger.debug(
                        "Injected tool execution context into provider",
                        call_id=call_id,
                        provider=provider_name
                    )
                except Exception as e:
                    logger.warning(f"Failed to inject tool context: {e}", call_id=call_id)

            await provider.start_session(call_id, context=provider_context if provider_context else None)
            logger.info("Provider session started", call_id=call_id, provider=provider_name)
            # If provider supports an explicit greeting (e.g., LocalProvider), trigger it now
            try:
                if hasattr(provider, 'play_initial_greeting'):
                    await provider.play_initial_greeting(call_id)
            except Exception:
                logger.debug("Provider initial greeting failed or unsupported", exc_info=True)
            session.provider_session_active = True
            # Ensure upstream capture is enabled for real-time providers when not gated
            try:
                if not session.tts_playing and not session.audio_capture_enabled:
                    session.audio_capture_enabled = True
            except Exception:
                pass
            await self._save_session(session)
            # Sync gauges if coordinator is present
            if self.conversation_coordinator:
                try:
                    await self.conversation_coordinator.sync_from_session(session)
                except Exception:
                    pass
            logger.info("Provider session started", call_id=call_id, provider=provider_name)
            
            # Call metadata is persisted to Call History (SQLite); do not export per-call labels to Prometheus.
                
        except Exception as exc:
            # Best-effort cleanup if provider was partially started.
            try:
                self._call_providers.pop(call_id, None)
            except Exception:
                pass
            if provider and hasattr(provider, "stop_session"):
                try:
                    await provider.stop_session()
                except Exception:
                    pass
            logger.error("Failed to start provider session", call_id=call_id, error=str(exc), exc_info=True)

    async def _on_playback_finished(self, event: Dict[str, Any]):
        """Delegate ARI PlaybackFinished to PlaybackManager for gating and cleanup."""
        try:
            playback_id = None
            playback = event.get("playback", {}) or {}
            playback_id = playback.get("id") or event.get("playbackId")
            if not playback_id:
                logger.debug("PlaybackFinished without playback id", playback_event=event)
                return
            await self.playback_manager.on_playback_finished(playback_id)
        except Exception as exc:
            logger.error("Error in PlaybackFinished handler", error=str(exc), exc_info=True)

    def _is_request_authorized(self, request) -> bool:
        """
        Check if request is authorized for sensitive endpoints.
        
        Authorization granted if:
        - Request is from localhost (127.0.0.1, ::1, localhost)
        - OR request has valid HEALTH_API_TOKEN header
        
        Returns:
            True if authorized, False otherwise
        """
        # Check if from localhost
        peername = request.transport.get_extra_info('peername')
        if peername:
            client_ip = peername[0]
            if client_ip in ('127.0.0.1', '::1', 'localhost'):
                return True
        
        # Check for API token
        expected_token = os.getenv('HEALTH_API_TOKEN', '').strip()
        if expected_token:
            auth_header = request.headers.get('Authorization', '')
            if auth_header.startswith('Bearer '):
                provided_token = auth_header[7:]
                if provided_token == expected_token:
                    return True
        
        return False

    async def _start_health_server(self):
        """Start aiohttp health/metrics server (defaults to 127.0.0.1:15000)."""
        try:
            app = web.Application()
            app.router.add_get('/live', self._live_handler)
            app.router.add_get('/ready', self._ready_handler)
            app.router.add_get('/health', self._health_handler)
            app.router.add_get('/metrics', self._metrics_handler)
            app.router.add_post('/reload', self._reload_handler)
            app.router.add_get('/mcp/status', self._mcp_status_handler)
            app.router.add_post('/mcp/test/{server_id}', self._mcp_test_handler)
            app.router.add_get('/sessions/stats', self._sessions_stats_handler)
            runner = web.AppRunner(app)
            await runner.setup()
            # Host/port configurable via YAML health block with environment overrides (AAVA-30)
            try:
                # Precedence: env overrides > YAML health.* > defaults
                if "HEALTH_BIND_HOST" in os.environ:
                    health_host = os.getenv('HEALTH_BIND_HOST', '127.0.0.1')
                else:
                    health_host = getattr(getattr(self.config, "health", None), "host", "127.0.0.1")

                if "HEALTH_BIND_PORT" in os.environ:
                    health_port = int(os.getenv('HEALTH_BIND_PORT', '15000'))
                else:
                    health_port = int(getattr(getattr(self.config, "health", None), "port", 15000))
            except Exception:
                health_host = '127.0.0.1'
                health_port = 15000
            site = web.TCPSite(runner, health_host, health_port)
            await site.start()
            self._health_runner = runner
            logger.info("Health endpoint started", host=health_host, port=health_port)
        except Exception as exc:
            logger.error("Failed to start health endpoint", error=str(exc), exc_info=True)

    async def _sessions_stats_handler(self, request):
        """Return active session statistics for Admin UI (Milestone 21).
        
        SECURITY: Requires localhost or HEALTH_API_TOKEN.
        """
        # SECURITY: Gate sensitive endpoint to prevent operational data leak
        if not self._is_request_authorized(request):
            return web.json_response(
                {"active_calls": 0, "error": "Forbidden: requires localhost or valid HEALTH_API_TOKEN"},
                status=403
            )
        try:
            stats = await self.session_store.get_session_stats()
            return web.json_response(stats, status=200)
        except Exception as exc:
            logger.debug("Sessions stats handler failed", error=str(exc), exc_info=True)
            return web.json_response({"active_calls": 0, "error": str(exc)}, status=500)

    async def _mcp_status_handler(self, request):
        """Return MCP server/tool status for Admin UI (sanitized)."""
        try:
            if not self.mcp_manager:
                return web.json_response({"enabled": False, "servers": {}, "tool_routes": {}}, status=200)
            return web.json_response(self.mcp_manager.get_status(), status=200)
        except Exception as exc:
            logger.debug("MCP status handler failed", error=str(exc), exc_info=True)
            return web.json_response({"enabled": False, "error": str(exc)}, status=500)

    async def _mcp_test_handler(self, request):
        """Test an MCP server in the ai-engine container context.
        
        SECURITY: Requires localhost or HEALTH_API_TOKEN.
        """
        # SECURITY: Gate sensitive endpoint
        if not self._is_request_authorized(request):
            return web.json_response(
                {"ok": False, "error": "Forbidden: requires localhost or valid HEALTH_API_TOKEN"},
                status=403
            )
        
        try:
            server_id = request.match_info.get("server_id")
            if not server_id:
                return web.json_response({"ok": False, "error": "Missing server_id"}, status=400)
            if not self.mcp_manager:
                return web.json_response({"ok": False, "error": "MCP not initialized"}, status=400)
            result = await self.mcp_manager.test_server(server_id)
            return web.json_response(result, status=200 if result.get("ok") else 500)
        except Exception as exc:
            logger.debug("MCP test handler failed", error=str(exc), exc_info=True)
            return web.json_response({"ok": False, "error": str(exc)}, status=500)

    async def _execute_provider_tool(
        self,
        call_id: str,
        function_name: str,
        function_call_id: str,
        parameters: Dict[str, Any],
        session: "CallSession",
    ) -> Dict[str, Any]:
        """
        Execute a tool called by a provider (ElevenLabs, etc.) and send result back.
        
        Args:
            call_id: Call identifier
            function_name: Name of the tool to execute
            function_call_id: Provider's ID for this tool call
            parameters: Tool parameters
            session: Call session
        
        Returns:
            Tool execution result
        """
        from src.tools.context import ToolExecutionContext
        from src.tools.registry import tool_registry
        
        provider_name = getattr(session, 'provider_name', None) or self.config.default_provider
        provider = self._call_providers.get(call_id)

        result = {"status": "error", "message": f"Tool '{function_name}' not found"}
        tool_start_time = time.time()

        try:
            # Determine allowlisted tools for this call.
            # - None: legacy/unspecified => allow all (backward compatible)
            # - []: explicitly none allowed
            allowed_tools = None
            try:
                if isinstance(self.config.tools, dict) and not bool(self.config.tools.get("enabled", True)):
                    allowed_tools = []
            except Exception:
                pass

            try:
                if getattr(session, "context_name", None):
                    ctx_cfg = self.transport_orchestrator.get_context_config(session.context_name)
                    if ctx_cfg and hasattr(ctx_cfg, "tools") and ctx_cfg.tools is not None:
                        allowed_tools = list(ctx_cfg.tools or [])
            except Exception:
                logger.debug("Failed resolving context tool allowlist", call_id=call_id, exc_info=True)

            if allowed_tools is not None and function_name not in allowed_tools:
                result = {"status": "error", "message": f"Tool '{function_name}' not allowed for this call"}
            else:
                # Build tool execution context
                context = ToolExecutionContext(
                    call_id=call_id,
                    caller_channel_id=session.caller_channel_id,
                    bridge_id=session.bridge_id,
                    session_store=self.session_store,
                    ari_client=self.ari_client,
                    config=self.config.dict() if hasattr(self.config, 'dict') else {},
                    provider_name=provider_name,
                )

                # Execute tool via registry (tool_registry is a module-level singleton)
                tool = tool_registry.get(function_name) if tool_registry else None
                if tool:
                    result = await tool.execute(parameters, context)

                    # Handle special tools
                    if function_name == "hangup_call" and result.get("will_hangup"):
                        # Skip delayed hangup for local provider - ToolCall handler manages TTS and hangup
                        if provider_name == "local":
                            logger.info("Hangup requested - local provider will handle TTS and hangup", call_id=call_id)
                        else:
                            # For full agent providers like ElevenLabs, they manage their own TTS
                            # so we should hangup after a short delay for the farewell to play
                            logger.info("Hangup requested - scheduling delayed hangup", call_id=call_id)

                            # Schedule hangup after delay to let farewell audio play
                            async def delayed_hangup():
                                await asyncio.sleep(3.0)  # Wait for farewell TTS
                                try:
                                    current_session = await self.session_store.get_by_call_id(call_id)
                                    if current_session:
                                        await self.ari_client.hangup_channel(current_session.caller_channel_id)
                                        logger.info("âœ… Call hung up after farewell", call_id=call_id)
                                except Exception as e:
                                    logger.debug(f"Delayed hangup failed (may already be hung up): {e}", call_id=call_id)

                            asyncio.create_task(delayed_hangup())
                else:
                    logger.warning(
                        "Tool not found in registry",
                        call_id=call_id,
                        function_name=function_name,
                        available_tools=tool_registry.list_tools() if tool_registry else [],
                    )
        except Exception as e:
            logger.error(
                "Tool execution error",
                call_id=call_id,
                function_name=function_name,
                error=str(e),
                exc_info=True,
            )
            result = {"status": "error", "message": str(e)}
        
        # Log tool call to session for call history (Milestone 21)
        try:
            tool_duration_ms = (time.time() - tool_start_time) * 1000
            tool_record = {
                "name": function_name,
                "params": parameters,
                "result": result.get("status", "unknown"),
                "message": result.get("message", ""),
                "timestamp": datetime.now().isoformat(),
                "duration_ms": round(tool_duration_ms, 2),
            }
            if not hasattr(session, 'tool_calls') or session.tool_calls is None:
                session.tool_calls = []
            session.tool_calls.append(tool_record)
            await self.session_store.upsert_call(session)
        except Exception as e:
            logger.debug("Failed to log tool call to session", call_id=call_id, error=str(e))
        
        # Send result back to provider
        if provider and hasattr(provider, 'send_tool_result'):
            try:
                is_error = result.get("status") == "error"
                await provider.send_tool_result(function_call_id, result, is_error=is_error)
                logger.debug(
                    "Tool result sent to provider",
                    call_id=call_id,
                    function_name=function_name,
                    function_call_id=function_call_id,
                )
            except Exception as e:
                logger.error(
                    "Failed to send tool result to provider",
                    call_id=call_id,
                    function_name=function_name,
                    error=str(e),
                )
        
        return result

    async def _health_handler(self, request):
        """Return JSON with engine/provider status."""
        try:
            # Gather pipeline details
            pipelines_info = {}
            if self.config and hasattr(self.config, 'pipelines'):
                for p_name, p_cfg in self.config.pipelines.items():
                    pipelines_info[p_name] = {
                        "stt": p_cfg.stt,
                        "llm": p_cfg.llm,
                        "tts": p_cfg.tts,
                        "tools": p_cfg.tools
                    }

            # Gather provider details - only mark ready if is_ready() explicitly returns True
            providers_info = {}
            for name, prov in (self.providers or {}).items():
                ready = False  # Default to not ready
                reason = None
                try:
                    if hasattr(prov, 'is_ready'):
                        ready = bool(prov.is_ready())
                        if not ready:
                            reason = "missing_config"
                    else:
                        # Provider doesn't implement is_ready - assume not ready
                        ready = False
                        reason = "no_is_ready_method"
                except Exception as e:
                    ready = False
                    reason = f"error: {str(e)}"
                providers_info[name] = {"ready": ready, "reason": reason} if reason else {"ready": ready}

            # Compute readiness - default provider OR default pipeline must be ready.
            default_ready = False
            default_target = getattr(self.config, "default_provider", None) if self.config else None

            if default_target in (self.providers or {}):
                prov = self.providers[default_target]
                try:
                    default_ready = bool(prov.is_ready()) if hasattr(prov, "is_ready") else False
                except Exception:
                    default_ready = False
            elif self.config and hasattr(self.config, "pipelines") and default_target in (self.config.pipelines or {}):
                default_ready = bool(getattr(self, "pipeline_orchestrator", None) and self.pipeline_orchestrator.started)
            ari_connected = bool(self.ari_client and self.ari_client.running)
            audiosocket_listening = self.audio_socket_server is not None if self.config.audio_transport == 'audiosocket' else True
            is_ready = ari_connected and audiosocket_listening and default_ready

            # Get conversation coordinator metrics
            conversation_summary = await self.conversation_coordinator.get_summary()
            pending_timers = self.conversation_coordinator.get_pending_timer_count()
            active_sessions = await self.session_store.get_all_sessions()
            uptime_seconds = int(time.time() - self._start_time)

            payload = {
                "status": "healthy" if is_ready else "degraded",
                "ari_connected": ari_connected,
                "rtp_server_running": bool(getattr(self, 'rtp_server', None)),
                "audio_transport": self.config.audio_transport,
                "active_calls": len(active_sessions),
                "active_sessions": len(active_sessions),
                "pending_timers": pending_timers,
                "uptime_seconds": uptime_seconds,
                "active_playbacks": 0,
                "providers": providers_info,
                "pipelines": pipelines_info,
                "rtp_server": {},
                "audiosocket": {
                    "listening": audiosocket_listening,
                    "host": getattr(self.config.audiosocket, 'host', None) if self.config.audiosocket else None,
                    "port": getattr(self.config.audiosocket, 'port', None) if self.config.audiosocket else None,
                    "active_connections": (self.audio_socket_server.get_connection_count() if self.audio_socket_server else 0),
                },
                "audiosocket_listening": audiosocket_listening,
                "conversation": {
                    "gating_active": conversation_summary.get("gating_active", 0),
                    "capture_disabled": conversation_summary.get("capture_disabled", 0),
                    "barge_in_total": conversation_summary.get("barge_in_total", 0),
                    "pending_timers": pending_timers,
                },
                "streaming": {},
                "streaming_details": [],
            }
            return web.json_response(payload)
        except Exception as exc:
            return web.json_response({"status": "error", "error": str(exc)}, status=500)

    async def _live_handler(self, request):
        """Liveness probe: returns 200 if process is up."""
        return web.Response(text="ok", status=200)

    async def _ready_handler(self, request):
        """Readiness probe: 200 only if ARI, transport, and default provider are ready."""
        try:
            # Use is_connected property which reflects true WebSocket state (AAVA-136)
            ari_connected = bool(self.ari_client and self.ari_client.is_connected)
            transport_ok = True
            if self.config.audio_transport == 'audiosocket':
                transport_ok = self.audio_socket_server is not None
            elif self.config.audio_transport == 'externalmedia':
                transport_ok = self.rtp_server is not None
            default_target = getattr(self.config, "default_provider", None) if self.config else None
            provider_ok = False
            pipeline_ok = False

            if default_target in (self.providers or {}):
                prov = self.providers[default_target]
                try:
                    provider_ok = bool(prov.is_ready()) if hasattr(prov, "is_ready") else True
                except Exception:
                    provider_ok = True
            elif self.config and hasattr(self.config, "pipelines") and default_target in (self.config.pipelines or {}):
                pipeline_ok = bool(getattr(self, "pipeline_orchestrator", None) and self.pipeline_orchestrator.started)

            default_ok = provider_ok or pipeline_ok
            is_ready = ari_connected and transport_ok and default_ok
            status = 200 if is_ready else 503
            return web.json_response({
                "ari_connected": ari_connected,
                "transport_ok": transport_ok,
                "provider_ok": provider_ok,
                "pipeline_ok": pipeline_ok,
                "ready": is_ready,
            }, status=status)
        except Exception as exc:
            return web.json_response({"ready": False, "error": str(exc)}, status=500)

    async def _metrics_handler(self, request):
        """Expose Prometheus metrics."""
        try:
            data = generate_latest()
            # aiohttp forbids 'charset=' inside content_type arg; pass full header via headers.
            return web.Response(body=data, headers={"Content-Type": CONTENT_TYPE_LATEST})
        except Exception as exc:
            return web.Response(text=str(exc), status=500)

    async def _reload_handler(self, request):
        """Hot-reload configuration without restarting the engine.
        
        Reloads ai-agent.yaml and reinitializes providers with new settings.
        Active calls continue uninterrupted - changes apply to new calls only.
        
        POST /reload
        Returns JSON with reload status and what changed.
        
        SECURITY: Requires localhost or HEALTH_API_TOKEN.
        """
        # SECURITY: Gate sensitive endpoint
        if not self._is_request_authorized(request):
            return web.json_response(
                {"success": False, "error": "Forbidden: requires localhost or valid HEALTH_API_TOKEN"},
                status=403
            )
        
        try:
            logger.info("ðŸ”„ Configuration reload requested")
            changes = []
            errors = []
            
            # Step 1: Reload configuration from YAML
            from .config import load_config
            try:
                new_config = load_config()
                changes.append("Configuration file reloaded")
            except Exception as e:
                errors.append(f"Failed to load config: {str(e)}")
                return web.json_response({
                    "success": False,
                    "message": "Failed to reload configuration",
                    "errors": errors
                }, status=500)
            
            # Step 2: Compare and update provider configurations
            old_providers = set(self.providers.keys()) if self.providers else set()
            
            # Update config reference
            old_config = self.config
            self.config = new_config
            changes.append("Configuration updated")
            
            # Step 3: Reinitialize providers that have changed
            try:
                # Re-register providers with new config
                new_providers_config = getattr(new_config, 'providers', {})
                
                for provider_name, provider_config in new_providers_config.items():
                    if not getattr(provider_config, 'enabled', True):
                        continue
                    
                    # Check if provider exists and needs update
                    if provider_name in self.providers:
                        # Provider exists - check if config changed
                        old_prov_config = getattr(old_config, 'providers', {}).get(provider_name)
                        if old_prov_config != provider_config:
                            changes.append(f"Provider '{provider_name}' configuration updated")
                    else:
                        changes.append(f"Provider '{provider_name}' detected (restart needed to add)")
                
                # Check for removed providers
                for old_name in old_providers:
                    if old_name not in new_providers_config:
                        changes.append(f"Provider '{old_name}' removed from config (restart needed)")
                        
            except Exception as e:
                errors.append(f"Error updating providers: {str(e)}")
            
            # Step 4: Update contexts
            try:
                if hasattr(new_config, 'contexts') and new_config.contexts:
                    self.contexts = new_config.contexts
                    changes.append(f"Contexts updated ({len(new_config.contexts)} contexts)")
            except Exception as e:
                errors.append(f"Error updating contexts: {str(e)}")

            # Step 4b: Reload MCP tools (best-effort; applies to new calls)
            try:
                old_mcp = getattr(old_config, "mcp", None)
                new_mcp = getattr(new_config, "mcp", None)
                mcp_changed = old_mcp != new_mcp
                if mcp_changed:
                    active_calls = []
                    try:
                        active_calls = await self.session_store.list_active_calls()
                    except Exception:
                        active_calls = []

                    if active_calls:
                        changes.append(f"MCP config changed (reload deferred; {len(active_calls)} active call(s))")
                    else:
                        from src.tools.registry import tool_registry
                        # Stop/unregister old manager (if any)
                        if self.mcp_manager:
                            try:
                                removed = self.mcp_manager.unregister_tools(tool_registry)
                                changes.append(f"MCP tools unregistered ({removed})")
                            except Exception:
                                logger.debug("Failed unregistering MCP tools on reload", exc_info=True)
                            try:
                                await self.mcp_manager.stop()
                            except Exception:
                                logger.debug("Failed stopping MCP manager on reload", exc_info=True)
                            self.mcp_manager = None

                        # Start/register new manager if enabled
                        if new_mcp and getattr(new_mcp, "enabled", False):
                            from src.mcp.manager import MCPClientManager
                            self.mcp_manager = MCPClientManager(new_mcp)
                            await self.mcp_manager.start()
                            registered = self.mcp_manager.register_tools(tool_registry)
                            changes.append(f"MCP tools reloaded ({len(registered)})")
                        else:
                            changes.append("MCP tools disabled")
            except Exception as e:
                errors.append(f"Error reloading MCP tools: {str(e)}")
            
            # Step 5: Update prompts
            try:
                if hasattr(new_config, 'prompts') and new_config.prompts:
                    self.prompts = new_config.prompts
                    changes.append(f"Prompts updated ({len(new_config.prompts)} prompts)")
            except Exception as e:
                errors.append(f"Error updating prompts: {str(e)}")
            
            logger.info("âœ… Configuration reload completed", changes=changes, errors=errors)
            
            return web.json_response({
                "success": len(errors) == 0,
                "message": "Configuration reloaded" if not errors else "Reload completed with errors",
                "changes": changes,
                "errors": errors,
                "note": "Changes apply to new calls. Active calls use previous config."
            })
            
        except Exception as exc:
            logger.error("Configuration reload failed", error=str(exc), exc_info=True)
            return web.json_response({
                "success": False,
                "message": f"Reload failed: {str(exc)}",
                "errors": [str(exc)]
            }, status=500)


async def main():
    config = load_config()
    # Initialize structured logging according to YAML-configured level (default INFO)
    try:
        level_name = str(getattr(getattr(config, 'logging', None), 'level', 'info')).upper()
        level = getattr(logging, level_name, logging.INFO)
        configure_logging(log_level=level)
    except Exception:
        # Fallback to INFO if configuration not yet available
        configure_logging(log_level="INFO")
    
    # Validate configuration before starting engine (AAVA-21)
    from .config import validate_production_config
    errors, warnings = validate_production_config(config)
    
    if errors:
        logger.error("âŒ Configuration validation FAILED", errors=errors, warnings=warnings)
        raise RuntimeError(f"Configuration errors: {errors}")
    
    if warnings:
        logger.warning("âš ï¸  Configuration warnings", warnings=warnings)
    
    logger.info("âœ… Configuration validation passed")
    
    engine = Engine(config)

    shutdown_event = asyncio.Event()
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, shutdown_event.set)

    service_task = loop.create_task(engine.start())
    await shutdown_event.wait()

    await engine.stop()
    service_task.cancel()
    try:
        await service_task
    except asyncio.CancelledError:
        pass

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        pass
    finally:
        logger.info("AI Voice Agent has shut down.")
